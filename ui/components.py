"""
å…±ç”¨ UI å…ƒä»¶æ¨¡çµ„
åŒ…å«åœ–è¡¨ã€è¡¨æ ¼ã€åº¦é‡ç­‰å¯é‡ç”¨å…ƒä»¶
"""

import streamlit as st
import polars as pl
import numpy as np
import pandas as pd
import plotly.figure_factory as ff
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Optional, Dict, Any


def get_analysis_numeric_cols(df: pl.DataFrame) -> List[str]:
    """
    ç²å–é©åˆçµ±è¨ˆåˆ†æçš„æ•¸å€¼æ¬„ä½ï¼ˆæ’é™¤ Date/Time/timestampï¼‰
    
    Args:
        df: Polars DataFrame
        
    Returns:
        List[str]: æ•¸å€¼æ¬„ä½åç¨±åˆ—è¡¨
    """
    exclude_cols = {'Date', 'Time', 'timestamp', 'date', 'time'}
    
    numeric_cols = [
        col for col in df.columns 
        if df[col].dtype in [pl.Float32, pl.Float64, pl.Int64, pl.Int32]
        and col not in exclude_cols
    ]
    return numeric_cols


def show_file_list(selected_files: List[str]):
    """é¡¯ç¤ºæª”æ¡ˆæ¸…å–®é è¦½"""
    with st.expander("æŸ¥çœ‹æª”æ¡ˆæ¸…å–®"):
        if len(selected_files) <= 10:
            for f in selected_files:
                st.text(f"â€¢ {f}")
        else:
            st.text("å‰ 5 å€‹æª”æ¡ˆ:")
            for f in selected_files[:5]:
                st.text(f"  â€¢ {f}")
            st.text(f"  ... ({len(selected_files) - 10} å€‹æª”æ¡ˆ)")
            st.text("å¾Œ 5 å€‹æª”æ¡ˆ:")
            for f in selected_files[-5:]:
                st.text(f"  â€¢ {f}")


def show_data_metrics(df: pl.DataFrame, prefix: str = ""):
    """
    é¡¯ç¤ºè³‡æ–™åŸºæœ¬åº¦é‡
    
    Args:
        df: Polars DataFrame
        prefix: æ¬„ä½å‰ç¶´ï¼ˆç”¨æ–¼ session state keyï¼‰
    """
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç¸½åˆ—æ•¸", f"{len(df):,}")
    with col2:
        st.metric("ç¸½æ¬„ä½æ•¸", f"{len(df.columns):,}")
    with col3:
        if 'timestamp' in df.columns:
            time_range = df['timestamp'].max() - df['timestamp'].min()
            st.metric("æ™‚é–“ç¯„åœ", f"{time_range}")


def show_dataframe_preview(df: pl.DataFrame, title: str = "è³‡æ–™é è¦½", rows: int = 100):
    """é¡¯ç¤º DataFrame é è¦½"""
    st.subheader(title)
    st.dataframe(
        df.head(rows).to_pandas(),
        use_container_width=True,
        height=400
    )


def show_column_list(df: pl.DataFrame, cols_per_row: int = 4):
    """ä»¥å¤šåˆ—æ ¼å¼é¡¯ç¤ºæ¬„ä½æ¸…å–®"""
    st.subheader("æ¬„ä½æ¸…å–®")
    col_list = st.columns(cols_per_row)
    for i, col in enumerate(df.columns):
        with col_list[i % cols_per_row]:
            st.text(f"â€¢ {col}")


def show_correlation_heatmap(df: pl.DataFrame):
    """
    é¡¯ç¤ºç›¸é—œæ€§ç†±åœ–
    
    Args:
        df: Polars DataFrame
    """
    st.subheader("é¸æ“‡è®Šæ•¸é€²è¡Œç›¸é—œæ€§åˆ†æ")
    
    numeric_cols = get_analysis_numeric_cols(df)
    
    if not numeric_cols:
        st.warning("æ²’æœ‰æ•¸å€¼æ¬„ä½å¯ä¾›åˆ†æ")
        return
    
    # Let user select variables (max 15 for readability)
    max_vars = min(15, len(numeric_cols))
    selected_vars = st.multiselect(
        f"é¸æ“‡è¦åˆ†æçš„è®Šæ•¸ï¼ˆæœ€å¤š {max_vars} å€‹ï¼Œå»ºè­° 5-10 å€‹ï¼‰",
        numeric_cols,
        default=numeric_cols[:min(8, len(numeric_cols))],
        max_selections=max_vars
    )
    
    if len(selected_vars) < 2:
        st.warning("è«‹è‡³å°‘é¸æ“‡ 2 å€‹è®Šæ•¸é€²è¡Œç›¸é—œæ€§åˆ†æ")
        return
    
    try:
        # Extract data and convert to pandas
        corr_df = df.select(selected_vars).to_pandas()
        
        # Calculate correlation matrix
        corr_matrix = corr_df.corr()
        
        # Create heatmap using plotly
        fig = ff.create_annotated_heatmap(
            z=corr_matrix.values,
            x=list(corr_matrix.columns),
            y=list(corr_matrix.index),
            annotation_text=np.around(corr_matrix.values, decimals=2),
            colorscale='RdBu',
            zmid=0,
            showscale=True
        )
        
        fig.update_layout(
            title="è®Šæ•¸ç›¸é—œæ€§çŸ©é™£",
            xaxis_title="",
            yaxis_title="",
            height=600,
            xaxis={'side': 'bottom'}
        )
        
        # Rotate x-axis labels
        fig.update_xaxes(tickangle=45)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Show interpretation guide
        st.markdown("---")
        st.subheader("ğŸ“– ç›¸é—œä¿‚æ•¸è§£è®€")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("**ğŸ”´ å¼·è² ç›¸é—œ**: -1.0 ~ -0.7")
            st.caption("ä¸€å€‹è®Šæ•¸å¢åŠ æ™‚ï¼Œå¦ä¸€å€‹æ˜é¡¯æ¸›å°‘")
        with col2:
            st.markdown("**âšª ç„¡ç›¸é—œ**: -0.3 ~ 0.3")
            st.caption("å…©è®Šæ•¸ä¹‹é–“ç„¡æ˜é¡¯ç·šæ€§é—œä¿‚")
        with col3:
            st.markdown("**ğŸ”µ å¼·æ­£ç›¸é—œ**: 0.7 ~ 1.0")
            st.caption("ä¸€å€‹è®Šæ•¸å¢åŠ æ™‚ï¼Œå¦ä¸€å€‹ä¹Ÿå¢åŠ ")
        
        # Highlight strong correlations
        st.markdown("---")
        st.subheader("ğŸ¯ é¡¯è‘—ç›¸é—œæ€§ï¼ˆ|r| > 0.7ï¼‰")
        
        strong_corr = []
        for i in range(len(corr_matrix)):
            for j in range(i+1, len(corr_matrix)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:
                    var1 = corr_matrix.index[i]
                    var2 = corr_matrix.columns[j]
                    strong_corr.append({
                        'è®Šæ•¸ 1': var1,
                        'è®Šæ•¸ 2': var2,
                        'ç›¸é—œä¿‚æ•¸': f"{corr_val:.3f}",
                        'é¡å‹': 'æ­£ç›¸é—œ ğŸ”µ' if corr_val > 0 else 'è² ç›¸é—œ ğŸ”´'
                    })
        
        if strong_corr:
            st.dataframe(pd.DataFrame(strong_corr), use_container_width=True)
        else:
            st.info("æ²’æœ‰ç™¼ç¾å¼·ç›¸é—œæ€§ï¼ˆ|r| > 0.7ï¼‰çš„è®Šæ•¸å°")
    
    except Exception as e:
        st.error(f"è¨ˆç®—ç›¸é—œæ€§å¤±æ•—: {str(e)}")
        st.exception(e)


def show_time_series(df: pl.DataFrame):
    """
    é¡¯ç¤ºæ™‚é–“åºåˆ—åœ–è¡¨
    
    Args:
        df: Polars DataFrameï¼ˆéœ€åŒ…å« timestamp æ¬„ä½ï¼‰
    """
    if 'timestamp' not in df.columns:
        st.error("è³‡æ–™ä¸­æ²’æœ‰ timestamp æ¬„ä½")
        return
    
    numeric_cols = get_analysis_numeric_cols(df)
    
    if not numeric_cols:
        st.warning("æ²’æœ‰æ•¸å€¼æ¬„ä½å¯ä¾›åˆ†æ")
        return
    
    st.subheader("é¸æ“‡æ¬„ä½é€²è¡Œæ™‚é–“åºåˆ—åˆ†æ")
    
    # Multi-select for comparison
    selected_cols = st.multiselect(
        "é¸æ“‡è¦é¡¯ç¤ºçš„æ¬„ä½ï¼ˆæœ€å¤š3å€‹ï¼‰",
        numeric_cols,
        default=[numeric_cols[0]] if numeric_cols else [],
        max_selections=3
    )
    
    if selected_cols:
        # Create time series chart
        pandas_df = df.select(['timestamp'] + selected_cols).to_pandas()
        pandas_df = pandas_df.set_index('timestamp')
        
        st.line_chart(pandas_df)
        
        # Show data summary
        st.caption(f"æ™‚é–“ç¯„åœ: {df['timestamp'].min()} è‡³ {df['timestamp'].max()}")
        st.caption(f"è³‡æ–™é»æ•¸: {len(df):,}")
    else:
        st.info("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹æ¬„ä½")


def show_distribution(df: pl.DataFrame, selected_col: str):
    """
    é¡¯ç¤ºå–®ä¸€æ¬„ä½çš„åˆ†å¸ƒåœ–
    
    Args:
        df: Polars DataFrame
        selected_col: è¦åˆ†æçš„æ¬„ä½åç¨±
    """
    col_data = df[selected_col]
    col_data_clean = col_data.drop_nulls()
    
    # Show metrics
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("å¹³å‡å€¼", f"{col_data_clean.mean():.2f}")
    with col2:
        st.metric("ä¸­ä½æ•¸", f"{col_data_clean.median():.2f}")
    with col3:
        st.metric("æœ€å°å€¼", f"{col_data_clean.min():.2f}")
    with col4:
        st.metric("æœ€å¤§å€¼", f"{col_data_clean.max():.2f}")
    with col5:
        st.metric("æ¨™æº–å·®", f"{col_data_clean.std():.2f}")
    
    # Distribution visualization
    st.subheader("æ•¸å€¼åˆ†å¸ƒ")
    
    pandas_data = col_data_clean.to_pandas()
    
    if len(pandas_data) > 0:
        # Create histogram using numpy
        counts, bin_edges = np.histogram(pandas_data, bins=30)
        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2
        
        hist_df = pd.DataFrame({
            'value': bin_centers,
            'count': counts
        }).set_index('value')
        
        if hist_df['count'].sum() > 0:
            st.bar_chart(hist_df)
        else:
            st.info("è³‡æ–™ç¯„åœå¤ªå°ï¼Œç„¡æ³•ç”¢ç”Ÿåˆ†å¸ƒåœ–")
        
        # Show data range info
        data_range = col_data_clean.max() - col_data_clean.min()
        st.caption(f"è³‡æ–™ç¯„åœ: {data_range:.2f} | éç©ºå€¼æ•¸é‡: {len(pandas_data):,}")
    else:
        st.warning("æ­¤æ¬„ä½æ²’æœ‰æœ‰æ•ˆæ•¸å€¼")


def show_quality_dashboard(df: pl.DataFrame):
    """
    é¡¯ç¤ºè³‡æ–™å“è³ªå„€è¡¨æ¿
    
    Args:
        df: Polars DataFrame
    """
    st.subheader("ğŸ“ˆ æ•´é«”è³‡æ–™å“è³ª")
    
    total_rows = len(df)
    total_cols = len(df.columns)
    numeric_cols = get_analysis_numeric_cols(df)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç¸½åˆ—æ•¸", f"{total_rows:,}")
    with col2:
        st.metric("ç¸½æ¬„ä½æ•¸", f"{total_cols}")
    with col3:
        st.metric("æ•¸å€¼æ¬„ä½", f"{len(numeric_cols)}")
    with col4:
        if 'timestamp' in df.columns:
            time_span = df['timestamp'].max() - df['timestamp'].min()
            st.metric("æ™‚é–“è·¨åº¦", str(time_span))
    
    # Missing data analysis
    st.markdown("---")
    st.subheader("ğŸ” ç¼ºå¤±å€¼åˆ†æ")
    
    exclude_missing_cols = {'Date', 'Time', 'timestamp', 'date', 'time'}
    
    missing_data = []
    for col in df.columns:
        if col in exclude_missing_cols:
            continue
        null_count = df[col].null_count()
        if null_count > 0:
            null_pct = (null_count / total_rows) * 100
            missing_data.append({
                'æ¬„ä½åç¨±': col,
                'ç¼ºå¤±æ•¸é‡': null_count,
                'ç¼ºå¤±æ¯”ä¾‹': f"{null_pct:.2f}%",
                'åš´é‡ç¨‹åº¦': 'ğŸ”´ é«˜' if null_pct > 30 else ('ğŸŸ¡ ä¸­' if null_pct > 10 else 'ğŸŸ¢ ä½')
            })
    
    if missing_data:
        missing_df = pd.DataFrame(missing_data).sort_values('ç¼ºå¤±æ•¸é‡', ascending=False)
        st.dataframe(missing_df, use_container_width=True)
        
        # Visualize missing data
        fig = px.bar(
            missing_df.head(10),
            x='æ¬„ä½åç¨±',
            y='ç¼ºå¤±æ•¸é‡',
            title='å‰ 10 å€‹ç¼ºå¤±å€¼æœ€å¤šçš„æ¬„ä½',
            labels={'ç¼ºå¤±æ•¸é‡': 'ç¼ºå¤±æ•¸é‡', 'æ¬„ä½åç¨±': 'æ¬„ä½'}
        )
        fig.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.success("âœ… æ²’æœ‰ç¼ºå¤±å€¼ï¼")


def show_physics_validation_status(df: pl.DataFrame):
    """
    é¡¯ç¤ºç‰©ç†é©—è­‰ç‹€æ…‹
    
    Args:
        df: Polars DataFrame
    """
    st.subheader("ğŸ”¬ ç‰©ç†é©—è­‰ç‹€æ…‹")
    
    validation_cols = st.columns(3)
    
    with validation_cols[0]:
        st.markdown("**ğŸ“Š ç©©æ…‹æª¢æ¸¬**")
        if 'is_steady_state' in df.columns:
            steady_count = df['is_steady_state'].sum()
            total_count = len(df)
            steady_pct = (steady_count / total_count * 100) if total_count > 0 else 0
            st.metric("ç©©æ…‹è³‡æ–™", f"{steady_count:,} ({steady_pct:.1f}%)")
            
            steady_data = {'ç‹€æ…‹': ['ç©©æ…‹', 'éç©©æ…‹'], 'æ•¸é‡': [steady_count, total_count - steady_count]}
            st.bar_chart(pd.DataFrame(steady_data).set_index('ç‹€æ…‹'))
        else:
            st.caption("æœªåŸ·è¡Œç©©æ…‹æª¢æ¸¬")
    
    with validation_cols[1]:
        st.markdown("**ğŸŒ¡ï¸ ç†±å¹³è¡¡é©—è­‰**")
        if 'heat_balance_invalid' in df.columns:
            invalid_count = df['heat_balance_invalid'].sum()
            total_count = len(df)
            invalid_pct = (invalid_count / total_count * 100) if total_count > 0 else 0
            st.metric("ç•°å¸¸è³‡æ–™", f"{invalid_count:,} ({invalid_pct:.1f}%)")
            
            if invalid_pct > 20:
                st.error("ğŸ”´ ç•°å¸¸æ¯”ä¾‹éé«˜")
            elif invalid_pct > 10:
                st.warning("ğŸŸ¡ ç•°å¸¸æ¯”ä¾‹ä¸­ç­‰")
            else:
                st.success("ğŸŸ¢ ç•°å¸¸æ¯”ä¾‹æ­£å¸¸")
        else:
            st.caption("æœªåŸ·è¡Œç†±å¹³è¡¡é©—è­‰")
    
    with validation_cols[2]:
        st.markdown("**âš¡ è¦ªå’ŒåŠ›å®šå¾‹æª¢æŸ¥**")
        if 'affinity_law_invalid' in df.columns:
            invalid_count = df['affinity_law_invalid'].sum()
            total_count = len(df)
            invalid_pct = (invalid_count / total_count * 100) if total_count > 0 else 0
            st.metric("ç•°å¸¸è³‡æ–™", f"{invalid_count:,} ({invalid_pct:.1f}%)")
            
            if 'affinity_ratio' in df.columns:
                ratio_data = df['affinity_ratio'].drop_nulls()
                if len(ratio_data) > 0:
                    st.caption(f"æ¯”ç‡ç¯„åœ: {ratio_data.min():.4f} ~ {ratio_data.max():.4f}")
        else:
            st.caption("æœªåŸ·è¡Œè¦ªå’ŒåŠ›å®šå¾‹æª¢æŸ¥")


def show_frozen_data_detection(df: pl.DataFrame):
    """é¡¯ç¤ºå‡çµè³‡æ–™åµæ¸¬çµæœ"""
    st.subheader("â„ï¸ å‡çµè³‡æ–™åµæ¸¬")
    
    frozen_cols = [col for col in df.columns if '_frozen' in col]
    
    if frozen_cols:
        frozen_summary = []
        for col in frozen_cols:
            original_col = col.replace('_frozen', '')
            frozen_count = df[col].sum()
            if frozen_count > 0:
                frozen_pct = (frozen_count / len(df)) * 100
                frozen_summary.append({
                    'æ„Ÿæ¸¬å™¨': original_col,
                    'å‡çµé»æ•¸': frozen_count,
                    'å‡çµæ¯”ä¾‹': f"{frozen_pct:.2f}%",
                    'ç‹€æ…‹': 'ğŸ”´ è­¦å‘Š' if frozen_pct > 5 else 'ğŸŸ¡ æ³¨æ„'
                })
        
        if frozen_summary:
            frozen_df = pd.DataFrame(frozen_summary).sort_values('å‡çµé»æ•¸', ascending=False)
            st.dataframe(frozen_df, use_container_width=True)
            st.warning("âš ï¸ å‡çµè³‡æ–™å¯èƒ½è¡¨ç¤ºæ„Ÿæ¸¬å™¨æ•…éšœæˆ–æ•¸æ“šå‚³è¼¸å•é¡Œ")
        else:
            st.success("âœ… æ²’æœ‰åµæ¸¬åˆ°å‡çµè³‡æ–™")
    else:
        st.info("è³‡æ–™ä¸­ç„¡å‡çµæ¨™è¨˜æ¬„ä½")


def calculate_quality_score(df: pl.DataFrame) -> float:
    """
    è¨ˆç®—è³‡æ–™å“è³ªè©•åˆ†ï¼ˆ0-100ï¼‰
    
    Args:
        df: Polars DataFrame
        
    Returns:
        float: å“è³ªè©•åˆ†
    """
    quality_score = 100
    total_rows = len(df)
    
    # Calculate missing data penalty
    exclude_missing_cols = {'Date', 'Time', 'timestamp', 'date', 'time'}
    missing_count = sum(1 for col in df.columns if col not in exclude_missing_cols and df[col].null_count() > 0)
    
    if missing_count > 0:
        avg_missing_pct = sum(df[col].null_count() / total_rows * 100 for col in df.columns if col not in exclude_missing_cols) / len(df.columns)
        quality_score -= min(avg_missing_pct, 30)
    
    # Deduct points for frozen data
    frozen_cols = [col for col in df.columns if '_frozen' in col]
    if frozen_cols:
        frozen_count = sum([df[col].sum() for col in frozen_cols])
        frozen_pct = (frozen_count / (total_rows * len(frozen_cols))) * 100 if frozen_cols else 0
        quality_score -= min(frozen_pct, 20)
    
    return max(0, quality_score)


def show_quality_score(quality_score: float):
    """é¡¯ç¤ºå“è³ªè©•åˆ†å’Œå»ºè­°"""
    st.subheader("â­ æ•´é«”å“è³ªè©•åˆ†")
    
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.metric("è³‡æ–™å“è³ªè©•åˆ†", f"{quality_score:.1f}/100")
    
    with col2:
        if quality_score >= 90:
            st.success("ğŸŸ¢ å„ªç§€")
        elif quality_score >= 75:
            st.info("ğŸ”µ è‰¯å¥½")
        elif quality_score >= 60:
            st.warning("ğŸŸ¡ å°šå¯")
        else:
            st.error("ğŸ”´ éœ€æ”¹å–„")
    
    with col3:
        st.progress(quality_score / 100)
    
    # Recommendations
    if quality_score < 90:
        st.markdown("---")
        st.subheader("ğŸ’¡ æ”¹å–„å»ºè­°")
        st.markdown("- æª¢æŸ¥ç¼ºå¤±æ¯”ä¾‹ > 10% çš„æ¬„ä½ï¼Œè€ƒæ…®è£œå€¼æˆ–ç§»é™¤")
        st.markdown("- æª¢æŸ¥å‡çµè³‡æ–™çš„æ„Ÿæ¸¬å™¨ï¼Œå¯èƒ½éœ€è¦ç¶­è­·")
        st.markdown("- ç¢ºèªè³‡æ–™æ”¶é›†é »ç‡èˆ‡é æœŸä¸€è‡´")
        st.markdown("- è€ƒæ…®é€²è¡Œç•°å¸¸å€¼åµæ¸¬èˆ‡è™•ç†")


def show_export_buttons(df: pl.DataFrame, filename_prefix: str = "hvac_etl_output"):
    """
    é¡¯ç¤ºåŒ¯å‡ºæŒ‰éˆ•
    
    Args:
        df: Polars DataFrame
        filename_prefix: æª”åå‰ç¶´
    """
    from datetime import datetime
    from io import BytesIO
    
    col1, col2 = st.columns(2)
    
    with col1:
        # CSV export
        csv_data = df.write_csv()
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ CSV",
            data=csv_data,
            file_name=f"{filename_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with col2:
        # Parquet export
        buffer = BytesIO()
        df.write_parquet(buffer)
        parquet_data = buffer.getvalue()
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Parquet",
            data=parquet_data,
            file_name=f"{filename_prefix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet",
            mime="application/octet-stream"
        )
    
    st.info("ğŸ’¡ Parquet æ ¼å¼è¼ƒå°ä¸”æ•ˆèƒ½æ›´å¥½ï¼Œé©åˆå¤§å‹è³‡æ–™é›†")
