
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Batch Processor Implementation Guide v1.1</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
            background-color: #f8f9fa;
        }
        .container {
            background-color: #fff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        h1, h2, h3 { border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
        h2 { margin-top: 2em; }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #dfe2e5;
            padding: 12px;
            text-align: left;
        }
        th { background-color: #f6f8fa; font-weight: bold; }
        tr:nth-child(even) { background-color: #fdfdfd; }
        code {
            background-color: #f3f3f3;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 85%;
        }
        pre {
            background-color: #f6f8fa;
            padding: 16px;
            overflow: auto;
            border-radius: 6px;
        }
        blockquote {
            margin: 0;
            padding: 0 1em;
            color: #6a737d;
            border-left: 0.25em solid #dfe2e5;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 id="prd-v11-batchprocessor-implementation-guide">PRD v1.1: æ‰¹æ¬¡è™•ç†å™¨å¼·å¥æ€§é‡æ§‹æŒ‡å— (BatchProcessor Implementation Guide)</h1>
<p><strong>æ–‡ä»¶ç‰ˆæœ¬:</strong> v1.1 (å« Manifest æ©Ÿåˆ¶èˆ‡ Schema å¥‘ç´„é©—è­‰)<br />
<strong>æ—¥æœŸ:</strong> 2026-02-12<br />
<strong>è² è²¬äºº:</strong> Oscar Chang<br />
<strong>ç›®æ¨™æ¨¡çµ„:</strong> <code>src/etl/batch_processor_v2.py</code><br />
<strong>ç›¸ä¾æ¨¡çµ„:</strong> <code>src/etl/cleaner_v2.py</code> (v2.1+), <code>src/etl/feature_engineer.py</code> (v1.2+)<br />
<strong>é ä¼°å·¥æ™‚:</strong> 4 ~ 5 å€‹å·¥ç¨‹å¤©ï¼ˆå«æ•´åˆæ¸¬è©¦ï¼‰</p>
<hr />
<h2 id="1">1. åŸ·è¡Œç¸½ç¶±èˆ‡è¨­è¨ˆå“²å­¸</h2>
<p>ç›®å‰çš„ <code>batch_processor.py</code> å­˜åœ¨<strong>è¨˜æ†¶é«”å †ç©</strong>èˆ‡<strong>å¥‘ç´„ç ´å£</strong>çš„è‡´å‘½å‚·ã€‚æœ¬ PRD å®šç¾© <strong>V2.0 Pipeline æ¶æ§‹</strong>ï¼Œå°‡å…¶å¾ã€Œè³‡æ–™å›¤ç©è€…ã€è½‰å‹ç‚ºã€Œé«˜æ•ˆæŒ‡æ®å®˜ã€ï¼Œä¸¦ä½œç‚º Cleaner èˆ‡ Feature Engineer é–“çš„<strong>å¥‘ç´„å®ˆé–€å“¡</strong>ã€‚</p>
<p><strong>æ ¸å¿ƒè¨­è¨ˆåŸå‰‡:</strong>
1.  <strong>ä¸²æµå„ªå…ˆ (Streaming First)</strong>ï¼šåš´ç¦å°‡å¤šæª”æ¡ˆ DataFrame åŒæ™‚è¼‰å…¥è¨˜æ†¶é«”ã€‚è™•ç†å®Œä¸€å€‹ï¼Œç«‹å³é‡‹æ”¾ã€‚
2.  <strong>æ™‚é–“åˆ†å€èšåˆ (Time-Partitioned)</strong>ï¼šé¿å…ä¸€å°ä¸€ CSV è½‰ Parquet å°è‡´å°æ–‡ä»¶çˆ†ç‚¸ï¼Œæ”¹ç”¨åˆ—æ•¸/æ™‚é–“é–¾å€¼åˆä½µå¯«å…¥ã€‚
3.  <strong>å¥‘ç´„å®ˆè­· (Contract Guardian)</strong>ï¼šé©—è­‰ Cleaner è¼¸å‡ºæ˜¯å¦ç¬¦åˆ <code>Output Contract</code>ï¼Œæ””æˆªå‹åˆ¥éŒ¯èª¤ï¼ˆå¦‚ <code>quality_flags</code> è¢«èª¤è½‰ç‚º Float64ï¼‰ã€‚
4.  <strong>äº‹å‹™æ€§è¼¸å‡º (Transactional Output)</strong>ï¼šStaging + Atomic Moveï¼Œæ‰¹æ¬¡å¤±æ•—æ™‚è‡ªå‹•å›æ»¾ï¼Œä¸æ±¡æŸ“ä¸‹æ¸¸ã€‚
5.  <strong>å¯è¿½æº¯æ€§ (Traceability)</strong>ï¼šé€é <strong>Manifestï¼ˆæ¸…å–®ï¼‰æ©Ÿåˆ¶</strong>è¨˜éŒ„æ‰¹æ¬¡è¡€ç·£ï¼Œä¾› Feature Engineer ç²¾æº–è®€å–ã€‚</p>
<hr />
<h2 id="2-pipeline-manifest">2. ç³»çµ±æ¶æ§‹ï¼šPipeline æ¨¡å¼ï¼ˆå« Manifestï¼‰</h2>
<h3 id="21">2.1 è³‡æ–™æµèˆ‡é—œéµè®Šæ›´</h3>
<pre><code class="language-mermaid">graph TD
    A[Source CSVs] --&gt;|Iterate| B(Parser)
    B --&gt;|Raw DF| C[Cleaner v2.1]
    C --&gt;|Clean DF| D{Schema Validator&lt;br/&gt;æª¢æŸ¥ quality_flags ç­‰}
    D --&gt;|Pass| E[Buffer Accumulator&lt;br/&gt;æ™‚é–“åˆ†å€ç·©è¡]
    D --&gt;|Fail| F[Error Log&lt;br/&gt;è¨˜éŒ„å¤±æ•—æª”æ¡ˆ]
    E --&gt;|é”é–¾å€¼| G[Staging Writer&lt;br/&gt;.staging/{batch_id}]
    G --&gt;|æ‰¹æ¬¡å®Œæˆ| H{Atomic Move&lt;br/&gt;åŸå­æ€§ç§»å‹•}
    H --&gt;|æˆåŠŸ| I[Final Dataset&lt;br/&gt;processed/{site}/year=2026/...]
    H --&gt;|æˆåŠŸ| J[manifest.json&lt;br/&gt;æ¸…å–®èˆ‡çµ±è¨ˆ]
    H --&gt;|å¤±æ•—| K[Rollback&lt;br/&gt;æ¸…ç† Staging]
    I --&gt;|è®€å–| L[Feature Engineer&lt;br/&gt;é€é manifest è€Œé glob]
</code></pre>
<h3 id="22-vs-legacy">2.2 é—œéµè®Šæ›´å°ç…§ï¼ˆvs Legacyï¼‰</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">åŠŸèƒ½æ¨¡çµ„</th>
<th style="text-align: left;">èˆŠç‰ˆå¯¦ä½œ (Legacy)</th>
<th style="text-align: left;">æ–°ç‰ˆå¯¦ä½œ (Pipeline v1.1)</th>
<th style="text-align: left;">é¢¨éšª/å„ªå‹¢</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>è¨˜æ†¶é«”ç®¡ç†</strong></td>
<td style="text-align: left;"><code>List[DataFrame]</code> ç´¯ç©</td>
<td style="text-align: left;"><strong>Process-and-Dump</strong> + ç·©è¡å€</td>
<td style="text-align: left;">OOM é¢¨éšªæ­¸é›¶</td>
</tr>
<tr>
<td style="text-align: left;"><strong>è¼¸å‡ºæª”æ¡ˆç­–ç•¥</strong></td>
<td style="text-align: left;">ä¸€å°ä¸€ CSVâ†’Parquet</td>
<td style="text-align: left;"><strong>æ™‚é–“åˆ†å€åˆä½µ</strong>ï¼ˆ100MB/é–¾å€¼ï¼‰</td>
<td style="text-align: left;">é¿å…å°æ–‡ä»¶çˆ†ç‚¸ï¼ˆ50è¬æª”æ¡ˆå•é¡Œï¼‰</td>
</tr>
<tr>
<td style="text-align: left;"><strong>å‹åˆ¥è™•ç†</strong></td>
<td style="text-align: left;">å¼·åˆ¶å…¨è½‰ Float64</td>
<td style="text-align: left;"><strong>Schema å¥‘ç´„é©—è­‰</strong>ï¼ˆä¿ç•™ List[str]ï¼‰</td>
<td style="text-align: left;">ä¸æœƒæŠ¹é™¤ <code>quality_flags</code></td>
</tr>
<tr>
<td style="text-align: left;"><strong>è¼¸å‡ºäº‹å‹™æ€§</strong></td>
<td style="text-align: left;">ç›´æ¥å¯«å…¥æ­£å¼ç›®éŒ„</td>
<td style="text-align: left;"><strong>Staging + Atomic Move</strong></td>
<td style="text-align: left;">å¤±æ•—æ™‚ç„¡é«’è³‡æ–™ï¼Œæ”¯æ´å†ªç­‰é‡è·‘</td>
</tr>
<tr>
<td style="text-align: left;"><strong>ä¸‹æ¸¸éŠœæ¥</strong></td>
<td style="text-align: left;">Feature Engineer glob æœå°‹</td>
<td style="text-align: left;"><strong>Manifest æ¸…å–®æ©Ÿåˆ¶</strong></td>
<td style="text-align: left;">ç²¾æº–è®€å–ã€æ”¯æ´è¡€ç·£è¿½è¹¤ã€å»é‡</td>
</tr>
<tr>
<td style="text-align: left;"><strong>æ™‚é–“é€£çºŒæ€§</strong></td>
<td style="text-align: left;">ç„¡ä¿è­‰</td>
<td style="text-align: left;"><strong>å¼·åˆ¶æ’åº + è·¨æª”å»é‡</strong></td>
<td style="text-align: left;">Feature Engineer Lag è¨ˆç®—æ­£ç¢º</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="3-interface-contracts">3. è¼¸å…¥è¼¸å‡ºå¥‘ç´„ï¼ˆInterface Contractsï¼‰</h2>
<h3 id="31-from-cleaner-v21">3.1 ä¸Šæ¸¸è¼¸å…¥ï¼ˆFrom Cleaner v2.1ï¼‰</h3>
<p>BatchProcessor <strong>åš´æ ¼é©—è­‰</strong> Cleaner è¼¸å‡ºï¼Œç¢ºä¿ç¬¦åˆ Feature Engineer é æœŸï¼š</p>
<table>
<thead>
<tr>
<th style="text-align: left;">æ¬„ä½</th>
<th style="text-align: left;">é æœŸå‹åˆ¥</th>
<th style="text-align: left;">é©—è­‰é‚è¼¯</th>
<th style="text-align: left;">å¤±æ•—è™•ç†</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><code>timestamp</code></td>
<td style="text-align: left;"><code>pl.Datetime(time_zone="UTC")</code></td>
<td style="text-align: left;">å¿…é ˆå­˜åœ¨ã€ç„¡é‡è¤‡ã€åš´æ ¼éå¢</td>
<td style="text-align: left;">æ‹‹å‡º <code>ContractViolationError</code></td>
</tr>
<tr>
<td style="text-align: left;"><code>quality_flags</code></td>
<td style="text-align: left;"><code>pl.List(pl.Utf8)</code></td>
<td style="text-align: left;">ä¸å¯ç‚º Nullã€ä¸å¯è¢«è½‰ç‚º Float64</td>
<td style="text-align: left;">æ‹‹å‡º <code>TypeError</code>ï¼Œè¨˜éŒ„éŒ¯èª¤æª”æ¡ˆ</td>
</tr>
<tr>
<td style="text-align: left;">è³‡æ–™æ¬„ä½</td>
<td style="text-align: left;"><code>pl.Float64</code>ï¼ˆSI åˆ¶å–®ä½ï¼‰</td>
<td style="text-align: left;">ç„¡æ¥µç«¯ç•°å¸¸å€¼ï¼ˆå¦‚ 1e20ï¼‰</td>
<td style="text-align: left;">æ¨™è¨˜è­¦å‘Šä½†ç¹¼çºŒè™•ç†</td>
</tr>
<tr>
<td style="text-align: left;">æ™‚é–“é€£çºŒæ€§</td>
<td style="text-align: left;">é–“éš”æ†å®š</td>
<td style="text-align: left;">æª¢æŸ¥èˆ‡ <code>resample_interval</code> ä¸€è‡´</td>
<td style="text-align: left;">è¨˜éŒ„ <code>INSUFFICIENT_DATA</code> æ¨™è¨˜</td>
</tr>
</tbody>
</table>
<h3 id="32-to-feature-engineer">3.2 ä¸‹æ¸¸è¼¸å‡ºï¼ˆTo Feature Engineerï¼‰</h3>
<p>BatchProcessor è¼¸å‡º<strong>ä¿è­‰</strong>ä»¥ä¸‹è¦æ ¼ï¼š</p>
<pre><code class="language-yaml">è¼¸å‡ºç›®éŒ„çµæ§‹:
data/processed/
â”œâ”€â”€ {site_id}/
â”‚   â”œâ”€â”€ year=2026/
â”‚   â”‚   â”œâ”€â”€ month=02/
â”‚   â”‚   â”‚   â”œâ”€â”€ part-0001.parquet  (100MB ~ 1GB)
â”‚   â”‚   â”‚   â””â”€â”€ part-0002.parquet
â”‚   â”‚   â””â”€â”€ month=03/
â”‚   â”‚       â””â”€â”€ ...
â””â”€â”€ manifests/
    â””â”€â”€ manifest-{batch_id}-{timestamp}.json
</code></pre>
<p><strong>Parquet Schema è¦ç¯„</strong>ï¼š
- <code>timestamp</code>: <code>INT64 (nanoseconds)</code> + UTC æ™‚å€è³‡è¨Šï¼ˆæˆ– <code>INT96</code>ï¼‰
- <code>quality_flags</code>: Parquet Logical Type <code>LIST&lt;STRING&gt;</code>ï¼Œå°æ‡‰ Polars <code>List[Utf8]</code>
- å…¶ä»–æ¬„ä½: <code>FLOAT64</code></p>
<p><strong>Manifest æª”æ¡ˆæ ¼å¼</strong>ï¼š</p>
<pre><code class="language-json">{
  &quot;manifest_version&quot;: &quot;1.0&quot;,
  &quot;batch_id&quot;: &quot;550e8400-e29b-41d4-a716-446655440000&quot;,
  &quot;site_id&quot;: &quot;CGMH-TY&quot;,
  &quot;created_at&quot;: &quot;2026-02-12T14:30:00Z&quot;,
  &quot;input_files_count&quot;: 150,
  &quot;output_files&quot;: [
    &quot;year=2026/month=02/part-0001.parquet&quot;,
    &quot;year=2026/month=02/part-0002.parquet&quot;
  ],
  &quot;statistics&quot;: {
    &quot;total_rows&quot;: 1500000,
    &quot;time_range&quot;: [&quot;2026-02-01T00:00:00Z&quot;, &quot;2026-02-28T23:55:00Z&quot;],
    &quot;quality_flags_distribution&quot;: {
      &quot;FROZEN&quot;: 150,
      &quot;HEAT_IMBALANCE&quot;: 2300,
      &quot;INSUFFICIENT_DATA&quot;: 45
    }
  },
  &quot;schema_hash&quot;: &quot;sha256:a1b2c3d4...&quot;,  // ç”¨æ–¼å¿«å–å¤±æ•ˆæª¢æ¸¬
  &quot;checksum&quot;: &quot;sha256:e5f6g7h8...&quot;      // å®Œæ•´æ€§é©—è­‰
}
</code></pre>
<hr />
<h2 id="4">4. åˆ†éšæ®µå¯¦ä½œè¨ˆç•«</h2>
<h3 id="phase-1-1">Phase 1: åŸºç¤æ¶æ§‹èˆ‡é…ç½® (é ä¼° 1 å¤©)</h3>
<h4 id="step-11-etlconfig">Step 1.1: çµ±ä¸€é…ç½®æ¨¡å‹ï¼ˆETLConfigï¼‰</h4>
<p><strong>æª”æ¡ˆ</strong>: <code>src/etl/config_models.py</code></p>
<pre><code class="language-python">from pydantic import BaseModel, validator, root_validator
from typing import Literal, Optional
import psutil

class BatchConfig(BaseModel):
    input_pattern: str = &quot;*.csv&quot;
    output_base_dir: str = &quot;data/processed/&quot;
    staging_dir: str = &quot;data/.staging/&quot;  # æš«å­˜å€ï¼ˆäº‹å‹™æ€§ï¼‰

    # ã€é—œéµã€‘è¼¸å‡ºæ§åˆ¶ï¼ˆé¿å…å°æ–‡ä»¶çˆ†ç‚¸ï¼‰
    max_rows_per_file: int = 100_000      # å–®ä¸€ Parquet æª”æ¡ˆæœ€å¤§åˆ—æ•¸
    max_time_span_per_file: str = &quot;1d&quot;    # å–®ä¸€æª”æ¡ˆæœ€å¤§æ™‚é–“è·¨åº¦
    output_format: Literal[&quot;parquet&quot;] = &quot;parquet&quot;
    compression: str = &quot;snappy&quot;

    # è¨˜æ†¶é«”é˜²è­·
    memory_limit_mb: int = 4096
    memory_action: Literal[&quot;warn&quot;, &quot;throttle&quot;, &quot;stop&quot;] = &quot;throttle&quot;

    # éŒ¯èª¤è™•ç†
    stop_on_error: bool = False
    max_retry_per_file: int = 3

    # ã€é—œéµã€‘Manifest æ©Ÿåˆ¶
    manifest_enabled: bool = True
    manifest_dir: str = &quot;data/manifests/&quot;

class ETLConfig(BaseModel):
    &quot;&quot;&quot;çµ±ä¸€é…ç½®ï¼Œç¢ºä¿ Cleaner èˆ‡ BatchProcessor ç›¸å®¹&quot;&quot;&quot;
    cleaner: CleaningConfig      # è¦‹ Cleaner PRD v2.1
    batch: BatchConfig

    @root_validator
    def check_compatibility(cls, values):
        &quot;&quot;&quot;é©—è­‰ Batch è¼¸å‡ºèˆ‡ Cleaner è¨­å®šç›¸å®¹&quot;&quot;&quot;
        cleaner = values.get('cleaner')
        batch = values.get('batch')
        # ç¢ºä¿æ™‚é–“è§£æåº¦ä¸€è‡´ï¼ˆé¿å… Cleaner è¼¸å‡º 5m ä½† Batch ä»¥ç‚ºæ˜¯ 1hï¼‰
        if hasattr(batch, 'time_resolution') and batch.time_resolution != cleaner.resample_interval:
            raise ValueError(f&quot;Batch time_resolution ({batch.time_resolution}) &quot;
                           f&quot;must match Cleaner resample_interval ({cleaner.resample_interval})&quot;)
        return values
</code></pre>
<h4 id="step-12-orchestrator">Step 1.2: å»ºç«‹ Orchestrator éª¨æ¶ï¼ˆå«è¨˜æ†¶é«”ç›£æ§ï¼‰</h4>
<p><strong>æª”æ¡ˆ</strong>: <code>src/etl/batch_processor_v2.py</code></p>
<pre><code class="language-python">import psutil
import time
from pathlib import Path
from typing import List, Set, Dict
import polars as pl
from uuid import uuid4

class BatchOrchestrator:
    def __init__(self, config: ETLConfig):
        self.config = config
        self.parser = ReportParser()
        self.cleaner = DataCleaner(config.cleaner)
        self.batch_config = config.batch

        # ç·©è¡å€ï¼ˆç´¯ç©å°æª”æ¡ˆï¼Œé”é–¾å€¼å¾Œå¯«å…¥ï¼‰
        self.buffer: List[pl.DataFrame] = []
        self.buffer_rows = 0
        self.current_batch_id = str(uuid4())

        # æ™‚é–“è¿½è¹¤ï¼ˆç”¨æ–¼æª”æ¡ˆå‘½åèˆ‡å»é‡ï¼‰
        self.seen_timestamps: Set[str] = set()  # å¯é¸ï¼šè·¨æª”å»é‡

        # çµ±è¨ˆ
        self.stats = {
            &quot;processed_files&quot;: 0,
            &quot;failed_files&quot;: [],
            &quot;total_rows&quot;: 0,
            &quot;quality_flags_dist&quot;: {}
        }

    def _check_memory(self):
        &quot;&quot;&quot;è¨˜æ†¶é«”ç›£æ§èˆ‡é˜²è­·&quot;&quot;&quot;
        mem_mb = psutil.Process().memory_info().rss / 1024 / 1024
        if mem_mb &gt; self.batch_config.memory_limit_mb:
            if self.batch_config.memory_action == &quot;stop&quot;:
                raise MemoryError(f&quot;Memory limit exceeded: {mem_mb:.0f}MB&quot;)
            elif self.batch_config.memory_action == &quot;throttle&quot;:
                self.logger.warning(f&quot;High memory usage: {mem_mb:.0f}MB, throttling...&quot;)
                time.sleep(1)
</code></pre>
<h3 id="phase-2-schema-2">Phase 2: æ ¸å¿ƒç®¡ç·šå¯¦ä½œï¼ˆSchema é©—è­‰èˆ‡äº‹å‹™æ€§ï¼‰(é ä¼° 2 å¤©)</h3>
<h4 id="step-21-schema">Step 2.1: Schema å¥‘ç´„é©—è­‰å™¨</h4>
<p><strong>æª”æ¡ˆ</strong>: <code>src/etl/contract_validator.py</code></p>
<pre><code class="language-python">class OutputContractValidator:
    &quot;&quot;&quot;é©—è­‰ Cleaner è¼¸å‡ºç¬¦åˆ Feature Engineer é æœŸ&quot;&quot;&quot;

    REQUIRED_COLUMNS = [&quot;timestamp&quot;, &quot;quality_flags&quot;]
    ALLOWED_FLAG_TYPES = [&quot;FROZEN&quot;, &quot;HEAT_IMBALANCE&quot;, &quot;AFFINITY_VIOLATION&quot;, 
                          &quot;OUTLIER&quot;, &quot;INSUFFICIENT_DATA&quot;]

    @classmethod
    def validate(cls, df: pl.DataFrame) -&gt; None:
        # 1. æª¢æŸ¥å¿…è¦æ¬„ä½
        missing = set(cls.REQUIRED_COLUMNS) - set(df.columns)
        if missing:
            raise ContractViolationError(f&quot;Missing required columns: {missing}&quot;)

        # 2. ã€é—œéµã€‘é©—è­‰ quality_flags å‹åˆ¥ï¼ˆé˜²æ­¢è¢«è½‰ç‚º Float64ï¼‰
        qf_dtype = df[&quot;quality_flags&quot;].dtype
        if qf_dtype != pl.List(pl.Utf8):
            raise TypeError(
                f&quot;Column 'quality_flags' must be List[str] (Polars: List[Utf8]), &quot;
                f&quot;got {qf_dtype}. This usually means accidental casting to numeric.&quot;
            )

        # 3. é©—è­‰æ™‚é–“æˆ³
        if df[&quot;timestamp&quot;].dtype != pl.Datetime:
            raise TypeError(f&quot;timestamp must be Datetime, got {df['timestamp'].dtype}&quot;)

        # 4. é©—è­‰ç„¡æ¥µç«¯æœªä¾†è³‡æ–™ï¼ˆé˜² Data Leakageï¼‰
        if df[&quot;timestamp&quot;].max() &gt; datetime.now(timezone.utc) + timedelta(minutes=5):
            raise ValueError(&quot;Data contains future timestamps &gt; 5 minutes from now&quot;)
</code></pre>
<h4 id="step-22">Step 2.2: å–®æª”è™•ç†åŸå­å‡½æ•¸ï¼ˆå«ç·©è¡ç´¯ç©ï¼‰</h4>
<pre><code class="language-python">def process_single_file(self, file_path: Path) -&gt; BatchResult:
    &quot;&quot;&quot;
    è™•ç†å–®ä¸€æª”æ¡ˆï¼Œå¯«å…¥ç·©è¡å€ï¼Œé”é–¾å€¼æ™‚è§¸ç™¼å¯«å…¥ Staging
    &quot;&quot;&quot;
    try:
        # 1. è§£æ
        raw_df = self.parser.parse_file(str(file_path))

        # 2. æ¸…æ´—
        clean_df = self.cleaner.clean(raw_df)

        # 3. ã€é—œéµã€‘Schema å¥‘ç´„é©—è­‰ï¼ˆæ””æˆªå‹åˆ¥éŒ¯èª¤ï¼‰
        OutputContractValidator.validate(clean_df)

        # 4. æ™‚é–“æ’åºèˆ‡å»é‡ï¼ˆç¢ºä¿ Feature Engineer Lag è¨ˆç®—æ­£ç¢ºï¼‰
        clean_df = clean_df.sort(&quot;timestamp&quot;)
        if self.batch_config.deduplicate_timestamps:
            clean_df = clean_df.unique(subset=[&quot;timestamp&quot;], keep=&quot;first&quot;)

        # 5. ç´¯ç©åˆ°ç·©è¡å€ï¼ˆæ§åˆ¶è¼¸å‡ºæª”æ¡ˆå¤§å°ï¼‰
        self._accumulate_to_buffer(clean_df, file_path.stem)

        self.stats[&quot;processed_files&quot;] += 1
        return BatchResult(status=&quot;success&quot;, rows=len(clean_df))

    except ContractViolationError as e:
        self.logger.error(f&quot;Contract violation in {file_path}: {e}&quot;)
        self.stats[&quot;failed_files&quot;].append({&quot;file&quot;: str(file_path), &quot;error&quot;: str(e)})
        return BatchResult(status=&quot;contract_failed&quot;, error=str(e))
    except Exception as e:
        self.logger.error(f&quot;Processing failed {file_path}: {e}&quot;)
        if self.batch_config.stop_on_error:
            raise
        self.stats[&quot;failed_files&quot;].append({&quot;file&quot;: str(file_path), &quot;error&quot;: str(e)})
        return BatchResult(status=&quot;failed&quot;, error=str(e))

def _accumulate_to_buffer(self, df: pl.DataFrame, source_name: str):
    &quot;&quot;&quot;
    ç´¯ç©è³‡æ–™åˆ°ç·©è¡å€ï¼Œé”åˆ°åˆ—æ•¸æˆ–æ™‚é–“é–¾å€¼æ™‚å¯«å…¥ Staging
    &quot;&quot;&quot;
    self.buffer.append(df)
    self.buffer_rows += len(df)

    # æª¢æŸ¥æ˜¯å¦é”å¯«å…¥é–¾å€¼
    if self.buffer_rows &gt;= self.batch_config.max_rows_per_file:
        self._flush_buffer_to_staging()

    # è¨˜æ†¶é«”æª¢æŸ¥
    self._check_memory()
</code></pre>
<h4 id="step-23-staging-atomic-move">Step 2.3: Staging å¯«å…¥èˆ‡äº‹å‹™æ€§ï¼ˆAtomic Moveï¼‰</h4>
<pre><code class="language-python">def _flush_buffer_to_staging(self):
    &quot;&quot;&quot;å°‡ç·©è¡å€å¯«å…¥ Staging ç›®éŒ„&quot;&quot;&quot;
    if not self.buffer:
        return

    # åˆä½µç·©è¡å€
    combined = pl.concat(self.buffer)

    # æ™‚é–“åˆ†å€è·¯å¾‘ï¼šyear=2026/month=02/part-{uuid}.parquet
    min_ts = combined[&quot;timestamp&quot;].min()
    year, month = min_ts.year, min_ts.month
    part_file = f&quot;part-{uuid4().hex[:8]}.parquet&quot;

    staging_path = Path(self.batch_config.staging_dir) / self.current_batch_id / f&quot;year={year}&quot; / f&quot;month={month:02d}&quot;
    staging_path.mkdir(parents=True, exist_ok=True)

    file_path = staging_path / part_file

    # å¯«å…¥ Parquetï¼ˆä¿ç•™ List[str] å‹åˆ¥ï¼‰
    combined.write_parquet(
        file_path,
        compression=self.batch_config.compression,
        use_pyarrow=True  # ç¢ºä¿ List å‹åˆ¥æ­£ç¢º
    )

    self.logger.info(f&quot;Flushed {len(combined)} rows to {file_path}&quot;)

    # æ¸…ç©ºç·©è¡å€
    self.buffer = []
    self.buffer_rows = 0

def finalize_batch(self) -&gt; Manifest:
    &quot;&quot;&quot;
    æ‰¹æ¬¡å®Œæˆï¼šåŸå­æ€§ç§»å‹• Staging â†’ Finalï¼Œç”¢ç”Ÿ Manifest
    &quot;&quot;&quot;
    try:
        # 1. æ¸…ç©ºæœ€å¾Œç·©è¡å€
        self._flush_buffer_to_staging()

        # 2. ç”¢ç”Ÿ Manifest
        manifest = self._generate_manifest()

        # 3. ã€é—œéµã€‘åŸå­æ€§ç§»å‹•ï¼šStaging â†’ Final
        staging_base = Path(self.batch_config.staging_dir) / self.current_batch_id
        final_base = Path(self.batch_config.output_base_dir)

        if staging_base.exists():
            # ç§»å‹•æ‰€æœ‰æª”æ¡ˆåˆ°æ­£å¼ç›®éŒ„
            for src_file in staging_base.rglob(&quot;*.parquet&quot;):
                rel_path = src_file.relative_to(staging_base)
                dst_file = final_base / rel_path
                dst_file.parent.mkdir(parents=True, exist_ok=True)
                src_file.replace(dst_file)  # åŸå­æ€§ç§»å‹•ï¼ˆåŒæª”æ¡ˆç³»çµ±å…§ï¼‰

            # å¯«å…¥ Manifest
            manifest_path = Path(self.batch_config.manifest_dir) / f&quot;manifest-{self.current_batch_id}.json&quot;
            manifest_path.parent.mkdir(parents=True, exist_ok=True)
            manifest_path.write_text(manifest.json(), encoding='utf-8')

            # 4. æ¸…ç† Staging
            import shutil
            shutil.rmtree(staging_base)

            self.logger.info(f&quot;Batch {self.current_batch_id} committed successfully&quot;)
            return manifest

    except Exception as e:
        self.logger.error(f&quot;Batch finalization failed: {e}&quot;)
        self._rollback_staging()
        raise

def _rollback_staging(self):
    &quot;&quot;&quot;å¤±æ•—æ™‚å›æ»¾ï¼šæ¸…ç† Staging ç›®éŒ„&quot;&quot;&quot;
    staging_path = Path(self.batch_config.staging_dir) / self.current_batch_id
    if staging_path.exists():
        import shutil
        shutil.rmtree(staging_path)
        self.logger.info(f&quot;Rolled back staging: {staging_path}&quot;)
</code></pre>
<h3 id="phase-3-manifest-15">Phase 3: Manifest æ©Ÿåˆ¶èˆ‡ä¸‹æ¸¸éŠœæ¥ (é ä¼° 1.5 å¤©)</h3>
<h4 id="step-31-manifest">Step 3.1: Manifest æ¨¡å‹èˆ‡ç”¢ç”Ÿ</h4>
<pre><code class="language-python">from pydantic import BaseModel
from datetime import datetime
from typing import List, Dict

class Manifest(BaseModel):
    manifest_version: str = &quot;1.0&quot;
    batch_id: str
    site_id: str
    created_at: datetime
    input_files_count: int
    output_files: List[str]
    statistics: Dict
    schema_hash: str
    checksum: str

    def save(self, path: Path):
        path.write_text(self.json(indent=2), encoding='utf-8')

def _generate_manifest(self) -&gt; Manifest:
    &quot;&quot;&quot;ç”¢ç”Ÿæ‰¹æ¬¡æ¸…å–®&quot;&quot;&quot;
    staging_base = Path(self.batch_config.staging_dir) / self.current_batch_id
    output_files = [
        str(f.relative_to(staging_base)) 
        for f in staging_base.rglob(&quot;*.parquet&quot;)
    ]

    # è¨ˆç®— Schema é›œæ¹Šï¼ˆç”¨æ–¼å¿«å–å¤±æ•ˆï¼‰
    schema_str = str(sorted([(c, str(t)) for c, t in self.buffer[0].schema.items()])) if self.buffer else &quot;&quot;
    schema_hash = hashlib.sha256(schema_str.encode()).hexdigest()[:16]

    return Manifest(
        batch_id=self.current_batch_id,
        site_id=self.config.cleaner.site_id,  # å‡è¨­ CleanerConfig æœ‰ site_id
        created_at=datetime.now(timezone.utc),
        input_files_count=self.stats[&quot;processed_files&quot;],
        output_files=output_files,
        statistics={
            &quot;total_rows&quot;: self.stats[&quot;total_rows&quot;],
            &quot;quality_flags_distribution&quot;: self.stats[&quot;quality_flags_dist&quot;]
        },
        schema_hash=schema_hash,
        checksum=&quot;sha256:...&quot;  # å¯¦éš›è¨ˆç®—æª”æ¡ˆé›œæ¹Š
    )
</code></pre>
<h4 id="step-32-feature-engineer">Step 3.2: æä¾› Feature Engineer è®€å–ç¯„ä¾‹</h4>
<p><strong>æ–‡ä»¶</strong>: <code>docs/batch_to_feature_engineer_interface.md</code></p>
<pre><code class="language-python"># Feature Engineer è®€å–ç¯„ä¾‹ï¼ˆé€é Manifestï¼‰
def load_from_manifest(manifest_path: Path) -&gt; pl.LazyFrame:
    &quot;&quot;&quot;é€é Manifest ç²¾æº–è®€å–ï¼Œé¿å… glob å°æ–‡ä»¶çˆ†ç‚¸&quot;&quot;&quot;
    import json
    manifest = json.loads(manifest_path.read_text())

    base_dir = manifest_path.parent.parent / &quot;processed&quot;  # èª¿æ•´è·¯å¾‘
    files = [base_dir / f for f in manifest[&quot;output_files&quot;]]

    # ä½¿ç”¨ scan_parquet æƒ°æ€§è®€å–ï¼ˆè¨˜æ†¶é«”å‹å¥½ï¼‰
    return pl.scan_parquet(files)

# é©—è­‰ Schema ä¸€è‡´æ€§
def validate_schema(df: pl.LazyFrame, expected_manifest: dict):
    actual_schema = df.schema
    # é©—è­‰ quality_flags ç‚º List[str]
    assert actual_schema[&quot;quality_flags&quot;] == pl.List(pl.Utf8), \
        &quot;Schema mismatch: quality_flags must be List[str]&quot;
</code></pre>
<h3 id="phase-4-05">Phase 4: é©—è­‰èˆ‡ç›£æ§ (é ä¼° 0.5 å¤©)</h3>
<h4 id="step-41">Step 4.1: è¨˜æ†¶é«”ç©©å®šæ€§æ¸¬è©¦</h4>
<pre><code class="language-python">def test_memory_stability():
    &quot;&quot;&quot;é©—è­‰è™•ç† 1000 å€‹æª”æ¡ˆæ™‚è¨˜æ†¶é«”æŒå¹³&quot;&quot;&quot;
    initial_mem = psutil.Process().memory_info().rss

    for i in range(1000):
        orchestrator.process_single_file(mock_file)
        if i % 100 == 0:
            current_mem = psutil.Process().memory_info().rss
            assert current_mem &lt; initial_mem * 1.5, &quot;Memory leak detected&quot;
</code></pre>
<h4 id="step-42-quality_flags">Step 4.2: å¥‘ç´„é©—è­‰æ¸¬è©¦ï¼ˆé˜² quality_flags è¢«æŠ¹é™¤ï¼‰</h4>
<pre><code class="language-python">def test_quality_flags_preserved():
    &quot;&quot;&quot;é©—è­‰è¼¸å‡º Parquet ä¿ç•™ List[str] å‹åˆ¥&quot;&quot;&quot;
    # åŸ·è¡Œæ‰¹æ¬¡è™•ç†
    orchestrator.run()

    # è®€å–è¼¸å‡ºçš„ Parquet
    output_file = list(Path(&quot;data/processed&quot;).rglob(&quot;*.parquet&quot;))[0]
    df = pl.read_parquet(output_file)

    # é—œéµé©—è­‰ï¼šquality_flags å¿…é ˆæ˜¯ List[str]ï¼Œè€Œé Null æˆ– Float64
    assert df[&quot;quality_flags&quot;].dtype == pl.List(pl.Utf8)
    assert df[&quot;quality_flags&quot;].null_count() == 0  # å¯ç‚ºç©ºåˆ—è¡¨ï¼Œä¸å¯ç‚º Null
</code></pre>
<hr />
<h2 id="5">5. é¢¨éšªè©•ä¼°èˆ‡ç·©è§£ï¼ˆæ›´æ–°ï¼‰</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">é¢¨éšª</th>
<th style="text-align: center;">åš´é‡åº¦</th>
<th style="text-align: left;">ç·©è§£æªæ–½ï¼ˆv1.1 è¨­è¨ˆï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>å°æ–‡ä»¶çˆ†ç‚¸</strong></td>
<td style="text-align: center;">ğŸ”´ Critical</td>
<td style="text-align: left;"><strong>æ™‚é–“åˆ†å€åˆä½µ</strong>ï¼ˆ<code>max_rows_per_file: 100000</code>ï¼‰ï¼Œé¿å…ä¸€å°ä¸€ CSVâ†’Parquet</td>
</tr>
<tr>
<td style="text-align: left;"><strong>quality_flags è¢«æŠ¹é™¤</strong></td>
<td style="text-align: center;">ğŸ”´ Critical</td>
<td style="text-align: left;"><strong>Schema å¥‘ç´„é©—è­‰</strong>ï¼ˆ<code>OutputContractValidator</code>ï¼‰ï¼Œå‹åˆ¥éŒ¯èª¤ç«‹å³æ‹‹å‡º</td>
</tr>
<tr>
<td style="text-align: left;"><strong>æ‰¹æ¬¡å¤±æ•—æ®˜ç•™é«’è³‡æ–™</strong></td>
<td style="text-align: center;">ğŸ”´ High</td>
<td style="text-align: left;"><strong>Staging + Atomic Move</strong> äº‹å‹™æ©Ÿåˆ¶ï¼Œå¤±æ•—è‡ªå‹• Rollback</td>
</tr>
<tr>
<td style="text-align: left;"><strong>è¨˜æ†¶é«” OOM</strong></td>
<td style="text-align: center;">ğŸ”´ High</td>
<td style="text-align: left;"><strong>Process-and-Dump</strong> + è¨˜æ†¶é«”ç›£æ§ï¼ˆ<code>memory_limit_mb</code>ï¼‰</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Feature Engineer è®€å–éŒ¯èª¤</strong></td>
<td style="text-align: center;">ğŸŸ  High</td>
<td style="text-align: left;"><strong>Manifest æ©Ÿåˆ¶</strong>æ›¿ä»£ globï¼Œç²¾æº–è¿½è¹¤è¼¸å‡ºæª”æ¡ˆèˆ‡ Schema é›œæ¹Š</td>
</tr>
<tr>
<td style="text-align: left;"><strong>æ™‚é–“é †åºéŒ¯äº‚</strong></td>
<td style="text-align: center;">ğŸŸ  Medium</td>
<td style="text-align: left;"><strong>å¼·åˆ¶æ’åº</strong>ï¼ˆ<code>sort("timestamp")</code>ï¼‰+ è·¨æª”å»é‡ï¼ˆé¸é…ï¼‰</td>
</tr>
<tr>
<td style="text-align: left;"><strong>é…ç½®ä¸ä¸€è‡´</strong></td>
<td style="text-align: center;">ğŸŸ¡ Medium</td>
<td style="text-align: left;"><strong>ETLConfig çµ±ä¸€é©—è­‰</strong>ï¼Œç¢ºä¿ Cleaner èˆ‡ Batch æ™‚é–“è§£æåº¦ç›¸å®¹</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="6">6. äº¤ä»˜ç”¢ç‰©æ¸…å–®</h2>
<ol>
<li><code>src/etl/batch_processor_v2.py</code>: å…¨æ–° Orchestratorï¼ˆå« Stagingã€Manifestã€è¨˜æ†¶é«”ç›£æ§ï¼‰</li>
<li><code>src/etl/contract_validator.py</code>: Schema å¥‘ç´„é©—è­‰å™¨ï¼ˆé˜² quality_flags å‹åˆ¥éŒ¯èª¤ï¼‰</li>
<li><code>src/etl/config_models.py</code>: æ›´æ–° <code>BatchConfig</code>, <code>ETLConfig</code>ï¼ˆçµ±ä¸€é©—è­‰ï¼‰</li>
<li><code>src/etl/manifest.py</code>: Manifest è³‡æ–™æ¨¡å‹èˆ‡ç®¡ç†</li>
<li><code>tests/test_batch_processor_v2.py</code>: </li>
<li>è¨˜æ†¶é«”ç©©å®šæ€§æ¸¬è©¦ï¼ˆ1000 æª”æ¡ˆè¿´åœˆï¼‰</li>
<li>Schema å¥‘ç´„é©—è­‰æ¸¬è©¦ï¼ˆé˜² Float64 è½‰å‹ï¼‰</li>
<li>äº‹å‹™æ€§æ¸¬è©¦ï¼ˆStaging â†’ Atomic Move â†’ Rollbackï¼‰</li>
<li><code>tests/integration/test_cleaner_to_batch.py</code>: Cleaner è¼¸å‡º â†’ Batch è¼¸å…¥æ•´åˆæ¸¬è©¦</li>
<li><code>docs/batch_to_feature_engineer_interface.md</code>: çµ¦ Feature Engineer åœ˜éšŠçš„è®€å–ç¯„ä¾‹ï¼ˆå« Manifest ä½¿ç”¨ï¼‰</li>
<li><code>scripts/run_batch_pipeline.py</code>: CLI å…¥å£è…³æœ¬ï¼ˆå« argparseï¼‰</li>
</ol>
<hr />
<h2 id="7">7. èˆ‡ä¸Šä¸‹æ¸¸å”ä½œæª¢æŸ¥æ¸…å–®</h2>
<p>åœ¨éƒ¨ç½²å‰ï¼Œè«‹èˆ‡ç›¸é—œè² è²¬äººç¢ºèªï¼š</p>
<h3 id="cleaner-v21">èˆ‡ Cleaner v2.1 åœ˜éšŠï¼š</h3>
<ul>
<li>[ ] <code>quality_flags</code> è¼¸å‡ºæ˜¯å¦ä¿è­‰ç‚º <code>List[str]</code>ï¼ˆPolars <code>List[Utf8]</code>ï¼‰ï¼Ÿ</li>
<li>[ ] æ™‚é–“æˆ³æ˜¯å¦å·²æ’åºï¼Ÿï¼ˆBatchProcessor æœƒäºŒæ¬¡æ’åºï¼Œä½†é æ’åºå¯æå‡æ•ˆèƒ½ï¼‰</li>
<li>[ ] <code>resample_interval</code> è¨­å®šå€¼ï¼ˆç”¨æ–¼é©—è­‰æ™‚é–“é€£çºŒæ€§ï¼‰</li>
</ul>
<h3 id="feature-engineer">èˆ‡ Feature Engineer åœ˜éšŠï¼š</h3>
<ul>
<li>[ ] æ˜¯å¦æ¥å—é€é <code>manifest.json</code> è®€å–æª”æ¡ˆæ¸…å–®ï¼ˆè€Œé <code>glob("*.parquet")</code>ï¼‰ï¼Ÿ</li>
<li>[ ] Parquet æ™‚é–“æˆ³æ ¼å¼åå¥½ï¼ˆ<code>INT64 (nanoseconds)</code> vs <code>INT96</code>ï¼‰ï¼Ÿ</li>
<li>[ ] å–®ä¸€ Parquet æª”æ¡ˆå¤§å°åå¥½ï¼ˆå»ºè­° 100MB ~ 1GBï¼‰ï¼Ÿ</li>
<li>[ ] æ˜¯å¦éœ€è¦ <code>schema_hash</code> ç”¨æ–¼ç‰¹å¾µå¿«å–å¤±æ•ˆæª¢æ¸¬ï¼Ÿ</li>
</ul>
<h3 id="_1">èˆ‡ç¶­é‹åœ˜éšŠï¼š</h3>
<ul>
<li>[ ] æª”æ¡ˆç³»çµ±æ˜¯å¦æ”¯æ´ Atomic Moveï¼ˆåŒåˆ†å‰²å€å…§ <code>mv</code> ç‚ºåŸå­æ€§ï¼‰ï¼Ÿ</li>
<li>[ ] Staging ç›®éŒ„ï¼ˆ<code>data/.staging/</code>ï¼‰æ˜¯å¦æœ‰è¶³å¤ ç£ç¢Ÿç©ºé–“ï¼ˆé ä¼°ç‚ºè¼¸å‡ºè³‡æ–™çš„ 2 å€ï¼‰ï¼Ÿ</li>
<li>[ ] æ˜¯å¦éœ€è¦æ•´åˆ Prometheus/Grafana ç›£æ§ï¼ˆè¼¸å‡º <code>batch_rows_processed</code> ç­‰æŒ‡æ¨™ï¼‰ï¼Ÿ</li>
</ul>
<hr />
<p><strong>é—œéµä¿®æ”¹ç¸½çµ</strong>ï¼š
1. <strong>Schema å¥‘ç´„é©—è­‰</strong>ï¼šæ””æˆª <code>quality_flags</code> è¢«èª¤è½‰ç‚º Float64 çš„é¢¨éšªï¼ˆCriticalï¼‰
2. <strong>æ™‚é–“åˆ†å€åˆä½µ</strong>ï¼šé¿å… 50 è¬å°æ–‡ä»¶å•é¡Œï¼ˆCriticalï¼‰
3. <strong>Staging + Atomic Move</strong>ï¼šäº‹å‹™æ€§è¼¸å‡ºï¼Œæ”¯æ´å†ªç­‰é‡è·‘ï¼ˆHighï¼‰
4. <strong>Manifest æ©Ÿåˆ¶</strong>ï¼šæ›¿ä»£ globï¼Œæä¾›è¡€ç·£è¿½è¹¤èˆ‡ç²¾æº–è®€å–ï¼ˆHighï¼‰
5. <strong>çµ±ä¸€ ETLConfig</strong>ï¼šç¢ºä¿ Cleaner èˆ‡ BatchProcessor é…ç½®ç›¸å®¹ï¼ˆMediumï¼‰
```</p>
    </div>
</body>
</html>
