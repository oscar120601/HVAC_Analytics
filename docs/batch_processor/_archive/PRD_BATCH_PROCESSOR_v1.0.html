<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PRD_BATCH_PROCESSOR_v1.0</title>

<style>
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
    font-size: 16px;
    line-height: 1.5;
    word-wrap: break-word;
    color: #24292e;
    background-color: #fff;
    max-width: 900px;
    margin: 0 auto;
    padding: 2rem;
}
h1, h2, h3, h4, h5, h6 {
    margin-top: 24px;
    margin-bottom: 16px;
    font-weight: 600;
    line-height: 1.25;
}
h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
h3 { font-size: 1.25em; }
code {
    padding: 0.2em 0.4em;
    margin: 0;
    font-size: 85%;
    background-color: #f6f8fa;
    border-radius: 6px;
    font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, monospace;
}
pre {
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f6f8fa;
    border-radius: 6px;
}
pre code {
    display: inline;
    padding: 0;
    margin: 0;
    overflow: visible;
    line-height: inherit;
    word-wrap: normal;
    background-color: initial;
    border: 0;
}
blockquote {
    padding: 0 1em;
    color: #6a737d;
    border-left: 0.25em solid #dfe2e5;
    margin: 0;
}
table {
    display: block;
    width: 100%;
    margin-top: 0;
    margin-bottom: 16px;
    overflow: auto;
    border-spacing: 0;
    border-collapse: collapse;
}
table th, table td {
    padding: 6px 13px;
    border: 1px solid #dfe2e5;
}
table tr {
    background-color: #fff;
    border-top: 1px solid #c6cbd1;
}
table tr:nth-child(2n) {
    background-color: #f6f8fa;
}
a { color: #0366d6; text-decoration: none; }
a:hover { text-decoration: underline; }
hr {
    height: 0.25em;
    padding: 0;
    margin: 24px 0;
    background-color: #e1e4e8;
    border: 0;
}
</style>

</head>
<body>
<h1 id="prd-v10-batchprocessor-implementation-guide">PRD v1.0: 批次處理器重構指南 (BatchProcessor Implementation Guide)</h1>
<p><strong>文件版本:</strong> v1.0 (Pipeline Architecture)<br />
<strong>日期:</strong> 2026-02-12<br />
<strong>負責人:</strong> Oscar Chang<br />
<strong>目標模組:</strong> <code>src/etl/batch_processor_v2.py</code><br />
<strong>相依模組:</strong> <code>src/etl/cleaner_v2.py</code>, <code>src/etl/parser.py</code>, <code>src/etl/config_models.py</code></p>
<hr />
<h2 id="1">1. 執行總綱與設計哲學</h2>
<p>目前的 <code>batch_processor.py</code> 存在記憶體堆積與契約破壞的致命傷。本 PRD 定義了 <strong>V2.0 Pipeline 架構</strong>，將其從「資料囤積者」轉型為「高效指揮官」。</p>
<p><strong>核心設計原則:</strong><br />
1.  <strong>串流優先 (Streaming First)</strong>：嚴格禁止將多個檔案的 DataFrame 同時載入記憶體。處理完一個，立即釋放。<br />
2.  <strong>管線化 (Pipelined)</strong>：<code>Read -&gt; Parse -&gt; Clean -&gt; Validate -&gt; Write</code> 為不可分割原子操作。<br />
3.  <strong>契約守護 (Contract Guardian)</strong>：負責驗證 Cleaner 的輸出是否符合 Output Contract，在此攔截異常。<br />
4.  <strong>容錯韌性 (Resilience)</strong>：單一檔案失敗不應導致整個批次作業中斷（Circuit Breaker 除外）。</p>
<hr />
<h2 id="2-pipeline">2. 系統架構：Pipeline 模式</h2>
<h3 id="21-data-flow">2.1 資料流 (Data Flow)</h3>
<pre><code class="language-mermaid">graph LR
    A[Source CSVs] --&gt;|Iterate| B[Parser]
    B --&gt;|Raw DF| C[Cleaner v2.1]
    C --&gt;|Clean DF| D{Validator}
    D --&gt;|Pass| E[Parquet Writer]
    D --&gt;|Fail| F[Error Log]
    E --&gt;|Append| G[(Final Dataset)]
</code></pre>
<h3 id="22">2.2 關鍵變更對照</h3>
<table>
<thead>
<tr>
<th style="text-align: left;">功能模組</th>
<th style="text-align: left;">舊版實作 (Legacy)</th>
<th style="text-align: left;">新版實作 (Pipeline)</th>
<th style="text-align: left;">優勢</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>記憶體管理</strong></td>
<td style="text-align: left;"><code>List[DataFrame]</code> (Accumulate)</td>
<td style="text-align: left;"><strong>Process-and-Dump</strong> (Immediate Write)</td>
<td style="text-align: left;">OOM 風險歸零</td>
</tr>
<tr>
<td style="text-align: left;"><strong>型別處理</strong></td>
<td style="text-align: left;">強制全轉 Float64</td>
<td style="text-align: left;">尊重 Config 定義 Schema</td>
<td style="text-align: left;">保留 <code>quality_flags</code></td>
</tr>
<tr>
<td style="text-align: left;"><strong>輸出格式</strong></td>
<td style="text-align: left;">CSV/DataFrame</td>
<td style="text-align: left;"><strong>Parquet (Snappy)</strong></td>
<td style="text-align: left;">讀寫快 10x，保留型別</td>
</tr>
<tr>
<td style="text-align: left;"><strong>錯誤處理</strong></td>
<td style="text-align: left;">簡單 Try-Catch</td>
<td style="text-align: left;">詳細錯誤報告 + 略過機制</td>
<td style="text-align: left;">穩定性高</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="3">3. 分階段實作計畫</h2>
<h3 id="phase-1-05">Phase 1: 基礎架構與配置 (預估 0.5 天)</h3>
<h4 id="step-11">Step 1.1: 定義批次配置模型</h4>
<p><strong>檔案</strong>: <code>src/etl/config_models.py</code> (新增)</p>
<pre><code class="language-python">class BatchConfig(BaseModel):
    input_pattern: str = &quot;*.csv&quot;
    output_format: Literal[&quot;parquet&quot;, &quot;csv&quot;] = &quot;parquet&quot;
    output_path: str = &quot;data/processed/&quot;
    write_mode: Literal[&quot;overwrite&quot;, &quot;append&quot;] = &quot;overwrite&quot;
    stop_on_error: bool = False  # 若 False，遇到壞檔僅記錄不中斷
</code></pre>
<h4 id="step-12-orchestrator">Step 1.2: 建立 Orchestrator 骨架</h4>
<p><strong>檔案</strong>: <code>src/etl/batch_processor_v2.py</code></p>
<pre><code class="language-python">class BatchOrchestrator:
    def __init__(self, config: ETLConfig):
        self.config = config
        self.parser = ReportParser()
        self.cleaner = DataCleaner(config.cleaner)
        # 初始化 Writer (由 output_format 決定)
</code></pre>
<hr />
<h3 id="phase-2-critical-15">Phase 2: 核心管線實作 (Critical) (預估 1.5 天)</h3>
<h4 id="step-21">Step 2.1: 實作單檔處理原子函數</h4>
<p><strong>重點</strong>: 這是記憶體控制的關鍵，必須確保執行完立即釋放變數。</p>
<pre><code class="language-python">def process_single_file(self, file_path: Path) -&gt; BatchResult:
    try:
        # 1. Parsing
        raw_df = self.parser.parse_file(str(file_path))

        # 2. Cleaning (含 Output Contract 驗證)
        clean_df = self.cleaner.clean(raw_df)

        # 3. Writing (立即寫入磁碟)
        self._write_to_sink(clean_df)

        return BatchResult(status=&quot;success&quot;, rows=len(clean_df))

    except Exception as e:
        logger.error(f&quot;Failed processing {file_path}: {e}&quot;)
        return BatchResult(status=&quot;failed&quot;, error=str(e))
</code></pre>
<h4 id="step-22-parquet-sink">Step 2.2: 實作 Parquet Sink (寫入器)</h4>
<p><strong>重點</strong>: 支援 Append 模式。對於 Parquet，通常建議寫入 partition 或多個檔案，最後由 Feature Engineer 透過 glob 讀取。<br />
- <strong>策略</strong>: 每個輸入 CSV 對應一個輸出 Parquet 檔案（一對一），保持源頭追溯性。<br />
- <strong>好處</strong>: 避免並發寫入鎖定問題，且天然支援增量更新。</p>
<pre><code class="language-python">def _write_to_sink(self, df: pl.DataFrame, source_name: str):
    target_path = self.output_dir / f&quot;{source_name}.parquet&quot;
    df.write_parquet(target_path, compression=&quot;snappy&quot;)
</code></pre>
<hr />
<h3 id="phase-3-1">Phase 3: 執行緒與錯誤報告 (預估 1 天)</h3>
<h4 id="step-31">Step 3.1: 批次迴圈與進度條</h4>
<ul>
<li>使用 <code>tqdm</code> 顯示進度。</li>
<li>整合 <code>process_single_file</code> 到主迴圈。</li>
</ul>
<h4 id="step-32-execution-report">Step 3.2: 產生執行報告 (Execution Report)</h4>
<ul>
<li>處理結束後，產生 <code>batch_report_YYYYMMDD.json</code></li>
<li>內容包含：</li>
<li>成功/失敗檔案列表</li>
<li>總處理行數</li>
<li>異常檔案的 Error Stack Trace</li>
</ul>
<hr />
<h2 id="4">4. 防呆與驗證機制</h2>
<h3 id="41-leak-check">4.1 記憶體洩漏檢查 (Leak Check)</h3>
<ul>
<li>在處理大檔案 (e.g. 100MB+) 時，監控 <code>psutil.Process().memory_info().rss</code>。</li>
<li>確保處理第 1 個檔案與第 100 個檔案時，記憶體佔用量應持平（不隨檔案數增加）。</li>
</ul>
<h3 id="42-integration-verification">4.2 介面契約驗證 (Integration Verification)</h3>
<ul>
<li><strong>Input</strong>: 準備一個包含 <code>quality_flags</code> 的 Mock DataFrame。</li>
<li><strong>Action</strong>: 執行 BatchProcessor 流程。</li>
<li><strong>Verify</strong>: 檢查輸出的 Parquet 檔案 schema，確認 <code>quality_flags</code> 仍為 <code>List[Utf8]</code> 且內容未遺失。</li>
</ul>
<hr />
<h2 id="5">5. 交付產物清單</h2>
<ol>
<li><code>src/etl/batch_processor_v2.py</code>: 全新 Orchestrator</li>
<li><code>src/etl/config_models.py</code>: 更新加入 BatchConfig</li>
<li><code>tests/test_batch_processor_v2.py</code>: <ul>
<li>測試記憶體穩定性 (Mock 迴圈)</li>
<li>測試錯誤隔離 (壞檔不影響好檔)</li>
</ul>
</li>
<li><code>main.py</code>: 專案入口點 (Entry Point)，整合 argparse</li>
</ol>
<hr />
<h2 id="6">6. 下一步指令</h2>
<p>此文件確認後，我們將按順序執行：<br />
1.  <strong>Cleaner v2.1 Phase 1-2</strong> (先有 Cleaner 才能被呼叫)<br />
2.  <strong>BatchProcessor v1.0 Phase 1-2</strong> (建立管線)<br />
3.  <strong>整合測試</strong></p>
<p>請問是否同意此執行路徑？</p>
</body>
</html>