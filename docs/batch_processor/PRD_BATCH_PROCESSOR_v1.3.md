# PRD v1.3-Contract-Aligned: æ‰¹æ¬¡å¤„ç†å™¨å¼ºå¥æ€§é‡æ„æŒ‡å— (BatchProcessor Implementation Guide)
# æ•´åˆ Feature Annotation v1.2ã€Equipment Validation Sync ä¸ Interface Contract v1.1

**æ–‡ä»¶ç‰ˆæœ¬:** v1.3-Contract-Aligned (Interface Contract v1.1 Compliance & Temporal Consistency)  
**æ—¥æœŸ:** 2026-02-14  
**è´Ÿè´£äºº:** Oscar Chang  
**ç›®æ ‡æ¨¡å—:** `src/etl/batch_processor.py` (v1.3+)  
**ä¸Šæ¸¸å¥‘çº¦:** `src/etl/cleaner.py` (v2.2+, æ£€æŸ¥ç‚¹ #2)  
**ä¸‹æ¸¸å¥‘çº¦:** `src/etl/feature_engineer.py` (v1.3+, æ£€æŸ¥ç‚¹ #3)  
**å…³é”®ç›¸ä¾:** 
- `src/features/annotation_manager.py` (v1.2+, æä¾›ç»§æ‰¿é“¾ä¸ç‰ˆæœ¬ä¿¡æ¯)
- `src/core/temporal_baseline.py` (PipelineContext, æ—¶é—´åŸºå‡†)
- `src/equipment/equipment_validator.py` (Equipment Validation Audit ä¼ é€’)
**é¢„ä¼°å·¥æ—¶:** 5 ~ 6 ä¸ªå·¥ç¨‹å¤©ï¼ˆå« Annotation ç¨½æ ¸è½¨è¿¹ã€Equipment Validation Syncã€Temporal Baseline æ•´åˆï¼‰

---

## 1. æ‰§è¡Œæ€»çº²ä¸è®¾è®¡å“²å­¦

### 1.1 ç‰ˆæœ¬å˜æ›´æ€»è§ˆ (v1.2 â†’ v1.3-Contract-Aligned)

| å˜æ›´ç±»åˆ« | v1.2 çŠ¶æ€ | v1.3-Contract-Aligned ä¿®æ­£ | å½±å“å±‚çº§ |
|:---|:---|:---|:---:|
| **Interface Contract å¯¹é½** | åŸºç¡€å¥‘çº¦æ£€æŸ¥ | **å®Œå…¨å¯¹é½ v1.1 æ£€æŸ¥ç‚¹ #3**ï¼šæ–°å¢è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹ä¼ é€’ã€æ—¶é—´åŸºå‡†å¼ºåˆ¶åŒæ­¥ | ğŸ”´ Critical |
| **Equipment Validation Sync** | æ—  | **æ–°å¢è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹**ï¼ˆE351ï¼‰ï¼Œä¸ Cleaner v2.2 å’Œ Optimization é™åˆ¶æ¡ä»¶ä¿æŒä¸€è‡´ | ğŸ”´ Critical |
| **Temporal Baseline** | æåŠä½†æœªå¼ºåˆ¶ | **å¼ºåˆ¶ä½¿ç”¨** `pipeline_origin_timestamp` è¿›è¡Œæœªæ¥æ•°æ®æ£€æŸ¥ï¼ˆE205ï¼‰ï¼Œå¹¶ä¼ é€’è‡³ä¸‹æ¸¸ | ğŸ”´ Critical |
| **Header Standardization** | æ—  | **å¯¹æ¥ Parser v2.1**ï¼šæ¥æ”¶å·²æ­£è§„åŒ–æ ‡å¤´ï¼ŒéªŒè¯ä¸ Annotation åŒ¹é…ï¼ˆE409ï¼‰ | ğŸŸ¡ Medium |
| **SSOT ç‰ˆæœ¬æ£€æŸ¥** | æ—  | **æ–°å¢ E408**ï¼šæ£€æŸ¥ Manifest ä¸­çš„ `quality_flags_schema` ä¸ä»£ç  SSOT ä¸€è‡´æ€§ | ğŸ”´ Critical |
| **E406 å¤„ç†æµç¨‹** | åŸºç¡€æ£€æŸ¥ | **å¼ºåŒ–**ï¼šè¯¦ç»†è¯´æ˜åŒæ­¥æ£€æŸ¥å¤±è´¥å¤„ç†ã€æ–‡ä»¶é”æ•´åˆã€æ¢å¤æŒ‡å¼• | ğŸŸ¡ Medium |
| **Foundation First Policy** | æ—  | **æ–°å¢**ï¼šæ˜ç¡®å£°æ˜åŸºç¡€æ¨¡å—å®æ–½ä¼˜å…ˆé¡ºåºï¼Œé˜²æ­¢ Dependency Deadlock | ğŸ”´ Critical |

### 1.2 æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼ˆContract-Aligned ç‰ˆï¼‰

1. **Metadata é›¶é—å¤±ï¼ŒèŒè´£æ¸…æ™°**ï¼šæ¥æ”¶ Cleaner ä¼ é€’çš„ `column_metadata`ï¼ˆä»…å« physical_type/unitï¼Œä¸å« device_roleï¼‰ï¼Œå®Œæ•´å†™å…¥ Manifestï¼›åŒæ—¶æ¥æ”¶å¹¶ä¼ é€’ `equipment_validation_audit` ä¾›ä¸‹æ¸¸ Optimization ä½¿ç”¨
2. **Temporal Baseline å¼ºåˆ¶ä¼ é€’**ï¼šæ‰€æœ‰æ—¶é—´ç›¸å…³éªŒè¯å¿…é¡»ä½¿ç”¨ä¸Šæ¸¸ä¼ å…¥çš„ `pipeline_origin_timestamp`ï¼Œç¦æ­¢åœ¨æ¨¡å—å†…è°ƒç”¨ `datetime.now()`ï¼Œé˜²æ­¢é•¿æ—¶é—´æ‰§è¡Œæµç¨‹ä¸­çš„æ—¶é—´æ¼‚ç§»
3. **SSOT ä¸¥æ ¼å¼•ç”¨**ï¼šæ‰€æœ‰éªŒè¯é€»è¾‘å¼•ç”¨ `src/etl/config_models.py` ä¸­çš„ `VALID_QUALITY_FLAGS`ã€`TIMESTAMP_CONFIG`ã€`FEATURE_ANNOTATION_CONSTANTS`
4. **è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹ä¼ é€’**ï¼šä½œä¸º Cleaner ä¸ Optimization ä¹‹é—´çš„ä¸­ä»‹ï¼Œå¿…é¡»å‡†ç¡®ä¼ é€’è®¾å¤‡é€»è¾‘é¢„æ£€ç»“æœï¼ˆEquipment Validation Auditï¼‰
5. **Foundation First Policy**ï¼šæœ¬æ¨¡å—ä¸º **Sprint 2 å®æ–½é¡¹ç›®**ï¼Œå¿…é¡»åœ¨ `FeatureAnnotationManager`ã€`TemporalContext`ã€`DataCleaner v2.2` å°±ç»ªåæ‰èƒ½å®æ–½ï¼Œä»¥é¿å… Dependency Deadlock

### 1.3 Foundation First Policyï¼ˆåŸºç¡€å®æ–½ä¼˜å…ˆå£°æ˜ï¼‰

> âš ï¸ **åŸºç¡€è®¾æ–½ä¼˜å…ˆå£°æ˜ï¼ˆFoundation First Policyï¼‰**  
> æ ¹æ®é¡¹ç›®æ‰§è¡Œè¯„ä¼°æŠ¥å‘Šï¼ˆProject Execution Evaluation Reportï¼‰ä¸ Interface Contract v1.1ï¼Œæœ¬æ¨¡å—ä¸º **Sprint 2 å®æ–½é¡¹ç›®ï¼ˆIntegration Sprintï¼‰**ã€‚  
> åœ¨ä»¥ä¸‹åŸºç¡€æ¨¡å—æœªå°±ç»ªå‰ï¼Œç¦æ­¢å¼€å‘ BatchProcessor v1.3 çš„ä¸šåŠ¡é€»è¾‘ï¼Œä»¥é¿å… **Dependency Deadlock** ä¸ **Temporal Inconsistency** é£é™©ï¼š
> 
> **å¼ºåˆ¶å‰ç½®ä¾èµ–ï¼ˆHard Dependenciesï¼‰ï¼š**
> 1. `FeatureAnnotationManager v1.2`ï¼ˆæ£€æŸ¥ç‚¹ #5ã€#6 éªŒè¯ï¼‰
> 2. `TemporalContext / PipelineContext v1.2`ï¼ˆæ—¶é—´åŸºå‡†ä¼ é€’ï¼‰
> 3. `DataCleaner v2.2-Contract-Aligned`ï¼ˆä¸Šæ¸¸å¥‘çº¦ï¼Œå« Equipment Validation Precheckï¼‰
> 
> **åˆå§‹åŒ–é¡ºåºï¼ˆContainer Initialization Orderï¼‰ï¼š**
> ```
> Step 1: PipelineContext (æ—¶é—´åŸºå‡†é”å®š)
> Step 2: E406 åŒæ­¥éªŒè¯ä¸æ–‡ä»¶é”å–å¾—
> Step 3: FeatureAnnotationManager (åŠ è½½å¹¶åˆå¹¶ç»§æ‰¿é“¾)
> Step 4: DataCleaner v2.2 (åˆå§‹åŒ–)
> Step 5: BatchProcessor v1.3 (æœ¬æ¨¡å—)
> ```
> 
> è¿åä¸Šè¿°é¡ºåºå°†è§¦å‘ **E901ï¼ˆINIT_ORDER_VIOLATIONï¼‰** é”™è¯¯ã€‚

---

## 2. æ¥å£å¥‘çº¦è§„èŒƒ (Interface Contracts)

### 2.1 è¾“å…¥å¥‘çº¦ (Input Contract from Cleaner v2.2)

**æ£€æŸ¥ç‚¹ #2: Cleaner â†’ BatchProcessor (Clean Data Contract)**

| æ£€æŸ¥é¡¹ | è§„æ ¼ | å®¹é”™å¤„ç† | é”™è¯¯ä»£ç  |
|:---|:---|:---|:---:|
| `timestamp` | `Datetime(time_unit='ns', time_zone='UTC')` | è‹¥ä¸ç¬¦ï¼Œå°è¯•è½¬æ¢æˆ–æ‹’ç» | E201 |
| `pipeline_origin_timestamp` | **å¿…é¡»å­˜åœ¨äº metadata** (ISO 8601 UTC) | é—å¤±åˆ™æŠ›å‡º E000 | **E000** |
| `quality_flags` | `List(Utf8)`ï¼Œå€¼ âŠ† `VALID_QUALITY_FLAGS` | æ‹’ç»å†™å…¥ï¼Œæç¤ºæ›´æ–° SSOT | E202 |
| `column_metadata` | `Dict[str, ColumnMeta]` (ç‰©ç†å±æ€§) | è‹¥ç¼ºå¤±ï¼Œä½¿ç”¨ä¿å®ˆé¢„è®¾ | E203 (Warning) |
| **device_role å­—æ®µ** | **ç¦æ­¢å­˜åœ¨äº DataFrame** | è‹¥å‘ç°ï¼ŒæŠ›å‡º E500 (å¥‘çº¦è¿å) | **E500** |
| **equipment_validation_audit** | `Dict` (è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹) | è‹¥å¯ç”¨åŒæ­¥ä½†æœªæä¾›ï¼Œè®°å½• E351 Warning | **E351** |
| æ—¶é—´è¿ç»­æ€§ | `temporal_continuity` æ ‡è®° | è®°å½•äº Manifestï¼Œä¸é˜»æ–­å¤„ç† | - |
| **æ ‡å¤´æ­£è§„åŒ–** | å­—æ®µåç§°å¿…é¡»ä¸º snake_case (Parser å¤„ç†) | è‹¥æ”¶åˆ°éæ­£è§„åŒ–æ ‡å¤´ï¼Œè®°å½•è­¦å‘Š | **E105-W** |

**å…³é”®æ—¶é—´åŸºå‡†æ£€æŸ¥**:
- **E000 (TEMPORAL_BASELINE_MISSING)**: è‹¥è¾“å…¥ metadata ä¸å« `pipeline_origin_timestamp`ï¼Œç«‹å³ç»ˆæ­¢æµç¨‹
- **æ—¶é—´ä¸€è‡´æ€§**: ä½¿ç”¨ä¼ å…¥çš„ `pipeline_origin_timestamp` è¿›è¡Œæ‰€æœ‰æœªæ¥æ•°æ®æ£€æŸ¥ï¼Œ**ç¦æ­¢**è°ƒç”¨ `datetime.now()`

### 2.2 è¾“å‡ºå¥‘çº¦ (Output Contract to Feature Engineer v1.3)

**æ£€æŸ¥ç‚¹ #3: BatchProcessor â†’ Feature Engineer (Storage Contract)**

**Manifest ç»“æ„ (v1.3-Contract-Aligned å…³é”®æ‰©å……)**:

```python
class Manifest(BaseModel):
    """BatchProcessor v1.3-Contract-Aligned Manifest ç»“æ„ (Interface Contract v1.1 #3)"""
    
    # åŸºç¡€ä¿¡æ¯
    manifest_version: str = "1.3-CA"  # Contract-Aligned
    batch_id: str                    # UUID v4
    site_id: str                     # æ¡ˆåœºè¯†åˆ« (å¦‚ "cgmh_ty")
    created_at: datetime             # ISO 8601 UTC
    
    # ã€å…³é”®ã€‘æ—¶é—´åŸºå‡†ä¼ é€’ (æ–°å¢å¼ºåˆ¶è¦æ±‚)
    temporal_baseline: Dict = {
        "pipeline_origin_timestamp": str,  # ISO 8601 UTCï¼Œä¸è¾“å…¥ç›¸åŒ
        "timezone": "UTC",
        "baseline_version": "1.0"
    }
    
    # ã€å…³é”®ã€‘Feature Metadata ä¼ é€’ (æ¥è‡ª Cleanerï¼Œä¸å« device_role)
    feature_metadata: Dict[str, FeatureMetadata]
    # ç¤ºä¾‹: {"chiller_1_load": {"physical_type": "chiller_load", "unit": "RT"}}
    # âŒ ç¦æ­¢åŒ…å«: device_role, ignore_warnings (è¿™äº›ç”± FE ç›´æ¥è¯»å– Annotation)
    
    # ã€æ–°å¢ã€‘Annotation ç¨½æ ¸è½¨è¿¹ (ä¾›å›æº¯ä¸ç‰ˆæœ¬éªŒè¯)
    annotation_audit_trail: Dict = {
        "schema_version": "1.2",
        "template_version": "1.2",
        "yaml_checksum": "sha256:abc123...",      # Excel æ¥æºæ–‡ä»¶æ‚å‡‘
        "inheritance_chain": "base -> cgmh_ty",   # ç»§æ‰¿é“¾ä¿¡æ¯
        "last_updated": "2026-02-13T10:00:00",
        "editor": "ç‹å·¥ç¨‹å¸ˆ"
    }
    
    # ã€æ–°å¢ã€‘è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹ (Equipment Validation Sync)
    equipment_validation_audit: Dict = {
        "validation_enabled": bool,               # æ˜¯å¦å¯ç”¨é¢„æ£€
        "constraints_applied": List[str],         # å¥—ç”¨çš„é™åˆ¶æ¡ä»¶ ID åˆ—è¡¨
        "violations_detected": int,               # è¿è§„ç¬”æ•°
        "violation_details": List[Dict],          # è¿è§„è¯¦æƒ…ï¼ˆæ—¶é—´ç‚¹ã€è®¾å¤‡ã€é™åˆ¶ç±»å‹ï¼‰
        "precheck_timestamp": str                 # é¢„æ£€æ‰§è¡Œæ—¶é—´æˆ³
    }
    
    # SSOT å¿«ç…§ (ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥)
    quality_flags_schema: List[str]    # å½“ä¸‹ä½¿ç”¨çš„ VALID_QUALITY_FLAGS å‰¯æœ¬
    timestamp_schema: Dict = {          # æ—¶é—´æˆ³è§„æ ¼å¿«ç…§
        "format": "INT64",
        "unit": "nanoseconds", 
        "timezone": "UTC"
    }
    
    # è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
    output_files: List[str]            # ç›¸å¯¹è·¯å¾„åˆ—è¡¨
    output_format: str = "parquet"
    compression: str = "snappy"
    
    # æ•°æ®å®Œæ•´æ€§éªŒè¯
    checksum: str                      # Manifest æœ¬èº« checksum (SHA256)
    file_checksums: Dict[str, str]    # filename â†’ SHA256
```

**Parquet è¾“å‡ºè§„èŒƒ**:

| å­—æ®µ | ç‰©ç†å‹åˆ« | é€»è¾‘å‹åˆ« | é™åˆ¶ |
|:---|:---|:---|:---|
| `timestamp` | `INT64` | `Timestamp(nanoseconds, UTC)` | ç¦æ­¢ INT96 |
| `quality_flags` | `BYTE_ARRAY` (JSON) | `List(Utf8)` | ä»¥ JSON string å­˜å‚¨ï¼ŒPolars è¯»å–æ—¶è§£æ |
| æ•°å€¼å­—æ®µ | `DOUBLE` | `Float64` | - |
| **device_role** | **ç¦æ­¢å­˜åœ¨** | - | **ä¸å¾—å†™å…¥ Parquet metadata æˆ– DataFrame** |

| éªŒè¯é¡¹ç›® | è§„æ ¼ | å¤±è´¥ä»£ç  | ä¸¥é‡åº¦ |
|:---|:---|:---:|:---:|
| **æ—¶é—´åŸºå‡†ä¼ é€’** | è¾“å‡º metadata å¿…é¡»åŒ…å« `pipeline_origin_timestamp` | **E000** | Critical |
| **æœªä¾†è³‡æ–™æª¢æŸ¥** | æ‰¹æ¬¡è³‡æ–™æ™‚é–“ â‰¤ `pipeline_origin_timestamp + 5min` | **E205** | High |
| **è®¾å¤‡é€»è¾‘ç¨½æ ¸** | è‹¥å¯ç”¨ `equipment_validation_sync`ï¼Œå¿…é¡»åŒ…å«ç¨½æ ¸è½¨è¿¹ | **E351** | High |
| **device_role ä¸å­˜åœ¨** | DataFrame ä¸ metadata çš†ä¸å¯å«æ­¤å­—æ®µ | **E500** | Critical |
| **Metadata çº¯å‡€æ€§** | ä»…å…è®¸ `physical_type`, `unit`, `description` | **E500** | Critical |
| **SSOT ä¸€è‡´æ€§** | `quality_flags_schema` å¿…é¡»ä¸å½“å‰ SSOT ç›¸å®¹ | **E408** | Critical |
| **æ ‡å¤´å¯¹åº”æ£€æŸ¥** | CSV æ ‡å¤´ï¼ˆæ­£è§„åŒ–åï¼‰ä¸ Annotation `column_name` åŒ¹é… | **E409** | High |

---

## 3. åˆ†é˜¶æ®µå®æ–½è®¡åˆ’ (Phase-Based Implementation)

### Phase 0: Annotation ç¨½æ ¸è½¨è¿¹ä¸ Temporal Baseline åŸºç¡€å»ºè®¾ (Day 1, æ–°å¢/å¼ºåŒ–)

#### Step 0.1: SSOT ä¸¥æ ¼å¼•ç”¨ä¸ Temporal Context æ³¨å…¥

**æ–‡ä»¶**: `src/etl/batch_processor.py` (é¡¶éƒ¨)

**å®æ–½å†…å®¹**:
```python
from typing import Final, Dict, List, Optional, Tuple
from pathlib import Path
import hashlib
import json
import shutil
from datetime import datetime, timezone, timedelta

import polars as pl
import pyarrow.parquet as pq
from pydantic import BaseModel, validator

# ã€å…³é”®ã€‘SSOT ä¸¥æ ¼å¼•ç”¨
from src.etl.config_models import (
    VALID_QUALITY_FLAGS,      # SSOT: 6ä¸ªæ ‡å‡†å“è´¨æ ‡è®°
    TIMESTAMP_CONFIG,         # SSOT: UTC, ns, INT64
    FeatureMetadata,          # SSOT: å­—æ®µå…ƒæ•°æ®ç»“æ„ (å·²ç§»é™¤ device_role)
    BatchConfig,             
    ETLConfig,
    FEATURE_ANNOTATION_CONSTANTS,  # SSOT: Annotation å¸¸æ•°
    EQUIPMENT_VALIDATION_CONSTRAINTS  # ã€æ–°å¢ã€‘SSOT: è®¾å¤‡é™åˆ¶æ¡ä»¶
)

# ã€æ–°å¢ã€‘Temporal Baseline æ•´åˆ
from src.core.temporal_baseline import TemporalContext, get_temporal_context

# ã€æ–°å¢ã€‘Annotation ç¨½æ ¸è½¨è¿¹
from src.features.annotation_manager import FeatureAnnotationManager

# é”™è¯¯ä»£ç å¸¸æ•° (Interface Contract v1.1)
ERROR_CODES: Final[Dict[str, str]] = {
    "E201": "INPUT_SCHEMA_MISMATCH",
    "E202": "UNKNOWN_QUALITY_FLAG", 
    "E203": "METADATA_LOSS",
    "E205": "FUTURE_DATA_IN_BATCH",      # ã€æ–°å¢ã€‘
    "E206": "PARQUET_FORMAT_VIOLATION",  # ã€æ–°å¢ã€‘
    "E301": "MANIFEST_INTEGRITY_FAILED",
    "E302": "SCHEMA_MISMATCH",
    "E303": "SSOT_QUALITY_FLAGS_MISMATCH",  # ã€ä¿®æ­£ã€‘åŸ E303ï¼Œç°å¯¹åº” E408
    "E304": "METADATA_MISSING",
    "E351": "EQUIPMENT_VALIDATION_AUDIT_MISSING",  # ã€æ–°å¢ã€‘
    "E406": "EXCEL_YAML_OUT_OF_SYNC",
    "E408": "SSOT_QUALITY_FLAGS_MISMATCH",  # ã€æ–°å¢ã€‘Manifest flags ä¸ä»£ç  SSOT ä¸ç¬¦
    "E409": "HEADER_ANNOTATION_MISMATCH",   # ã€æ–°å¢ã€‘æ ‡å¤´ä¸ Annotation ä¸åŒ¹é…
    "E500": "DEVICE_ROLE_LEAKAGE"
}
```

#### Step 0.2: E406 åŒæ­¥éªŒè¯ä¸æ–‡ä»¶é”æ•´åˆï¼ˆå¼ºåŒ–ç‰ˆï¼‰

**æ–‡ä»¶**: `src/etl/batch_processor.py` (`BatchOrchestrator.__init__`)

**è¯¦ç»†é€»è¾‘**:
```python
class BatchOrchestrator:
    """
    BatchProcessor v1.3-Contract-Aligned - æ•´åˆ Feature Annotation ç¨½æ ¸è½¨è¿¹ä¸ Temporal Baseline
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. æ¥æ”¶ Cleaner è¾“å‡ºï¼ˆä¸å« device_role çš„ DataFrame + column_metadata + equipment_validation_auditï¼‰
    2. å°† Annotation ç¨½æ ¸ä¿¡æ¯ï¼ˆç‰ˆæœ¬ã€checksumã€ç»§æ‰¿é“¾ï¼‰å†™å…¥ Manifest
    3. ä¼ é€’ Temporal Baseline è‡³ä¸‹æ¸¸ï¼ˆé˜²æ­¢æ—¶é—´æ¼‚ç§»ï¼‰
    4. æ‰§è¡Œ E406 åŒæ­¥æ£€æŸ¥ï¼ˆè‹¥ enforce_annotation_sync=Trueï¼‰
    5. ç¡®ä¿è¾“å‡º Parquet ä¸å« device_role å­—æ®µæˆ– metadata
    """
    
    def __init__(
        self,
        config: ETLConfig,
        parser: ReportParser,
        cleaner: DataCleaner,
        annotation_metadata: Optional[Dict] = None,  # æ¥è‡ª Container çš„ Annotation ä¿¡æ¯
        temporal_context: Optional[TemporalContext] = None  # ã€æ–°å¢ã€‘æ—¶é—´åŸºå‡†
    ):
        self.config = config
        self.parser = parser
        self.cleaner = cleaner
        self.annotation_metadata = annotation_metadata or {}
        self.logger = get_logger("BatchOrchestrator")
        self.batch_id = str(uuid.uuid4())
        self.site_id = config.site_id
        
        # ã€æ–°å¢ã€‘æ—¶é—´åŸºå‡†å¼ºåˆ¶æ£€æŸ¥
        if temporal_context is None:
            raise TemporalBaselineError(
                "E000: BatchProcessor å¿…é¡»æ¥æ”¶ TemporalContextï¼Œç¦æ­¢è‡ªè¡Œäº§ç”Ÿæ—¶é—´æˆ³ã€‚ "
                "è¯·ç¡®ä¿ Container æ­£ç¡®ä¼ é€’ pipeline_origin_timestampã€‚"
            )
        self.temporal_context = temporal_context
        self.pipeline_origin_timestamp = temporal_context.get_baseline()
        
        # ã€å¼ºåŒ–ã€‘E406 æ£€æŸ¥ï¼šè‹¥å¯ç”¨ä¸¥æ ¼åŒæ­¥ï¼Œæ£€æŸ¥ Excel/YAML çŠ¶æ€å¹¶æ•´åˆæ–‡ä»¶é”
        if config.feature_annotation.enabled and config.batch.enforce_annotation_sync:
            self._validate_annotation_sync_with_lock()
    
    def _validate_annotation_sync_with_lock(self):
        """
        E406 æ£€æŸ¥ï¼šç¡®ä¿ä½¿ç”¨çš„ YAML ä¸ Excel åŒæ­¥ï¼ˆæ•´åˆæ–‡ä»¶é”æœºåˆ¶ï¼‰
        
        æµç¨‹ï¼š
        1. å°è¯•å–å¾—æ–‡ä»¶é”ï¼ˆé˜²æ­¢ Wizard å¹¶å‘ä¿®æ”¹ï¼‰
        2. æ‰§è¡ŒåŒæ­¥éªŒè¯
        3. è‹¥ä¸åŒæ­¥ï¼Œæä¾›è¯¦ç»†æ¢å¤æŒ‡å¼•
        """
        from src.utils.config_loader import ConfigLoader, FileLockError
        
        fa_config = self.config.feature_annotation
        
        try:
            # ä½¿ç”¨æ–‡ä»¶é”ç¡®ä¿éªŒè¯æœŸé—´ YAML ä¸ä¼šè¢«ä¿®æ”¹
            with ConfigLoader.acquire_yaml_lock(
                self.site_id, 
                fa_config.lock_file_dir, 
                fa_config.file_lock_timeout
            ):
                self.logger.info("ğŸ” æ£€æŸ¥ç‚¹ #5: éªŒè¯ Excel/YAML åŒæ­¥çŠ¶æ€...")
                sync_status = ConfigLoader.validate_annotation_sync(
                    self.site_id,
                    fa_config.excel_base_dir,
                    fa_config.yaml_base_dir
                )
                
                if not sync_status['synced']:
                    error_msg = (
                        f"E406: {sync_status['reason']}\n"
                        f"Excel ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(sync_status.get('excel_mtime', 0))}\n"
                        f"YAML ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(sync_status.get('yaml_mtime', 0))}\n\n"
                        f"æ¢å¤æ­¥éª¤ï¼š\n"
                        f"1. ç¡®è®¤ Excel æ ‡æ³¨é‡é‡å·²å®Œæˆå¹¶ä¿å­˜\n"
                        f"2. æ‰§è¡Œè½¬æ¢: python tools/features/excel_to_yaml.py "
                        f"--input {fa_config.excel_base_dir}/{self.site_id}/{self.site_id}.xlsx "
                        f"--output {fa_config.yaml_base_dir}/{self.site_id}.yaml\n"
                        f"3. é‡æ–°æ‰§è¡Œ Pipeline"
                    )
                    
                    if fa_config.strict_sync_check:
                        raise AnnotationSyncError(error_msg)
                    else:
                        self.logger.warning(f"âš ï¸ Annotation åŒæ­¥è­¦å‘Š: {sync_status['reason']}")
                else:
                    self.logger.info("âœ… æ£€æŸ¥ç‚¹ #5: Excel/YAML åŒæ­¥ - é€šè¿‡")
                    
        except FileLockError as e:
            raise RuntimeError(f"E003: æ— æ³•å–å¾— Annotation æ–‡ä»¶é”: {e}") from e
```

---

### Phase 1: è¾“å…¥å¥‘çº¦éªŒè¯ä¸ Temporal Baseline åº”ç”¨ (Day 1-2, æ›´æ–°)

#### Step 1.1: è¾“å…¥å¥‘çº¦éªŒè¯ï¼ˆå« device_role æ³„æ¼æ£€æŸ¥ä¸ E409ï¼‰

**æ–¹æ³•**: `_validate_input_contract(df: pl.DataFrame, input_metadata: Dict) -> None`

**è¯¦ç»†é€»è¾‘**:
```python
def _validate_input_contract(self, df: pl.DataFrame, input_metadata: Dict) -> None:
    """
    éªŒè¯ Cleaner v2.2 è¾“å…¥å¥‘çº¦ (Interface Contract #2)
    
    éªŒè¯é¡¹ç›®:
    1. quality_flags å‹åˆ«ä¸å€¼åŸŸ
    2. pipeline_origin_timestamp å­˜åœ¨æ€§ (E000)
    3. ã€å…³é”®ã€‘ç¦æ­¢ device_role å­—æ®µå­˜åœ¨ (E500)
    4. ã€æ–°å¢ã€‘è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹æ£€æŸ¥ (E351)
    5. ã€æ–°å¢ã€‘æ ‡å¤´æ­£è§„åŒ–éªŒè¯ (E409)
    6. æœªæ¥æ•°æ®æ£€æŸ¥ (E205) - ä½¿ç”¨ Temporal Baseline
    """
    errors = []
    
    # 1. æ—¶é—´åŸºå‡†æ£€æŸ¥ (E000)
    if 'pipeline_origin_timestamp' not in input_metadata:
        errors.append("E000: è¾“å…¥ metadata é—å¤± pipeline_origin_timestamp")
    else:
        # éªŒè¯æ—¶é—´æˆ³æ ¼å¼
        try:
            baseline = datetime.fromisoformat(input_metadata['pipeline_origin_timestamp'])
            self.logger.debug(f"æ¥æ”¶æ—¶é—´åŸºå‡†: {baseline.isoformat()}")
        except ValueError:
            errors.append("E000: pipeline_origin_timestamp æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä¸º ISO 8601")
    
    # 2. quality_flags éªŒè¯ (E202)
    if "quality_flags" in df.columns:
        qf_dtype = df["quality_flags"].dtype
        if not isinstance(qf_dtype, pl.List):
            errors.append(f"quality_flags å¿…é¡»ä¸º List å‹åˆ«ï¼Œå¾—åˆ° {qf_dtype}")
        else:
            actual_flags = set()
            for flags in df["quality_flags"]:
                if flags:
                    actual_flags.update(flags)
            
            invalid_flags = actual_flags - set(VALID_QUALITY_FLAGS)
            if invalid_flags:
                errors.append(f"E202: è¾“å…¥åŒ…å«æœªå®šä¹‰çš„å“è´¨æ ‡è®°: {invalid_flags}")
    
    # 3. ã€å…³é”®ã€‘èŒè´£åˆ†ç¦»æ£€æŸ¥ï¼šç¦æ­¢ device_role å­—æ®µ (E500)
    forbidden_columns = ["device_role", "ignore_warnings", "is_target", "role", 
                        "device_type", "annotation_role"]
    for col in forbidden_columns:
        if col in df.columns:
            errors.append(
                f"E500: å‘ç°ç¦æ­¢å­—æ®µ '{col}'ã€‚Cleaner v2.2 ä¸åº”å°† Annotation å…ƒæ•°æ®"
                f"å†™å…¥ DataFrameï¼Œè¿™äº›èµ„è®¯åº”ç”± Feature Engineer ç›´æ¥è¯»å– YAML SSOTã€‚"
            )
    
    # 4. ã€æ–°å¢ã€‘è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹æ£€æŸ¥ (E351)
    if self.config.cleaner.enforce_equipment_validation_sync:
        if 'equipment_validation_audit' not in input_metadata:
            errors.append(
                "E351: å¯ç”¨è®¾å¤‡é€»è¾‘åŒæ­¥ä½†æœªæ¥æ”¶ equipment_validation_auditã€‚ "
                "è¯·ç¡®è®¤ Cleaner v2.2 å·²æ­£ç¡®å®æ–½ Equipment Validation Precheckã€‚"
            )
        else:
            audit = input_metadata['equipment_validation_audit']
            if audit.get('validation_enabled') and not audit.get('constraints_applied'):
                self.logger.warning("E351-Warning: è®¾å¤‡éªŒè¯å¯ç”¨ä½†æœªå¥—ç”¨ä»»ä½•é™åˆ¶æ¡ä»¶")
    
    # 5. ã€æ–°å¢ã€‘æ ‡å¤´æ­£è§„åŒ–éªŒè¯ (E409)
    if self.annotation_metadata:
        expected_cols = set(self.annotation_metadata.get('columns', {}).keys())
        actual_cols = set(df.columns) - {'timestamp', 'quality_flags'}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ­£è§„åŒ–çš„å­—æ®µï¼ˆåº”å·²è¢« Parser å¤„ç†ï¼Œæ­¤å¤„ä¸ºäºŒæ¬¡ç¡®è®¤ï¼‰
        non_standardized = [c for c in actual_cols if not self._is_snake_case(c)]
        if non_standardized:
            self.logger.warning(f"E409-Warning: ä»¥ä¸‹å­—æ®µæœªä½¿ç”¨ snake_case: {non_standardized}")
        
        # æ£€æŸ¥æœªæ ‡æ³¨å­—æ®µï¼ˆE402 å‰ç½®æ£€æŸ¥ï¼‰
        unannotated = actual_cols - expected_cols
        if unannotated:
            self.logger.warning(f"E409: ä»¥ä¸‹å­—æ®µæœªåœ¨ Annotation ä¸­å®šä¹‰: {unannotated}")
    
    # 6. æœªæ¥æ•°æ®æ£€æŸ¥ (E205) - ä½¿ç”¨ Temporal Baseline è€Œé now()
    if hasattr(self, 'pipeline_origin_timestamp'):
        self._check_future_data_with_baseline(df)
    
    if errors:
        raise ContractViolationError(f"è¾“å…¥å¥‘çº¦éªŒè¯å¤±è´¥: {errors}")
    
    self.logger.debug("è¾“å…¥å¥‘çº¦éªŒè¯é€šè¿‡ï¼šæœªå‘ç° device_role ç­‰ç¦æ­¢å­—æ®µ")

def _is_snake_case(self, s: str) -> bool:
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ç¬¦åˆ snake_case è§„èŒƒ"""
    import re
    return bool(re.match(r'^[a-z][a-z0-9_]*$', s))

def _check_future_data_with_baseline(self, df: pl.DataFrame) -> None:
    """
    æœªæ¥æ•°æ®æ£€æŸ¥ (E205) - ä½¿ç”¨ Temporal Baseline
    ã€å…³é”®ã€‘ç¦æ­¢ä½¿ç”¨ datetime.now()ï¼Œå¿…é¡»ä½¿ç”¨ self.pipeline_origin_timestamp
    """
    threshold = self.pipeline_origin_timestamp + timedelta(minutes=5)
    
    future_mask = df["timestamp"] > threshold
    future_count = future_mask.sum()
    
    if future_count > 0:
        future_samples = df.filter(future_mask)["timestamp"].head(3).to_list()
        raise FutureDataError(
            message=f"E205: æ£€æµ‹åˆ° {future_count} ç¬”æœªæ¥èµ„æ–™ï¼ˆ>{threshold.isoformat()}ï¼‰ã€‚",
            detected_timestamp=future_samples[0] if future_samples else None,
            pipeline_timestamp=self.pipeline_origin_timestamp,
            file_path=None  # å¯åœ¨ä¸Šå±‚è¡¥å……
        )
    
    self.logger.debug(f"æœªæ¥æ•°æ®æ£€æŸ¥é€šè¿‡ï¼ˆåŸºå‡†: {self.pipeline_origin_timestamp.isoformat()}ï¼‰")
```

---

### Phase 2: äº‹åŠ¡æ€§è¾“å‡ºä¸ Parquet å†™å…¥ (Day 2-3)

#### Step 2.1: Parquet å†™å…¥ä¸ Schema éªŒè¯ï¼ˆå¼ºåŒ–ç‰ˆï¼‰

**å…³é”®æ›´æ–°**ï¼šåœ¨ `_verify_parquet_schema` ä¸­æ–°å¢å¯¹ **temporal baseline** å’Œ **device_role** çš„æ£€æŸ¥

```python
def _verify_parquet_schema(self, file_path: Path) -> None:
    """
    éªŒè¯ Parquet æ–‡ä»¶ç¬¦åˆ INT64/UTC è§„èŒƒï¼Œä¸”ä¸å« device_role (E206/E500)
    ã€æ–°å¢ã€‘éªŒè¯æ—¶é—´æˆ³ç‰©ç†å‹åˆ«æ­£ç¡®æ€§
    """
    pf = pq.ParquetFile(file_path)
    schema = pf.schema
    
    # 1. éªŒè¯ timestamp å­—æ®µ (INT64/UTC/NANOS)
    ts_field = schema.field_by_name("timestamp")
    
    if ts_field.physical_type == "INT96":
        file_path.unlink()
        raise TypeError(f"E206: Parquet ä½¿ç”¨å·²å¼ƒç”¨çš„ INT96 æ ¼å¼")
    
    if ts_field.physical_type != "INT64":
        file_path.unlink()
        raise TypeError(f"E206: æ—¶é—´æˆ³ç‰©ç†å‹åˆ«å¿…é¡»ä¸º INT64")
    
    lt = ts_field.logical_type
    if lt.type != "TIMESTAMP" or lt.unit != "NANOS" or not lt.is_adjusted_to_utc:
        file_path.unlink()
        raise TypeError(f"E206: æ—¶é—´æˆ³å¿…é¡»ä¸º UTC Nanoseconds")
    
    # 2. ã€æ–°å¢ã€‘éªŒè¯æ—  device_role å­—æ®µ (E500)
    column_names = [schema.field(i).name for i in range(schema.num_columns)]
    if "device_role" in column_names:
        file_path.unlink()
        raise ContractViolationError(
            f"E500: Parquet æ–‡ä»¶åŒ…å«ç¦æ­¢å­—æ®µ 'device_role'ã€‚ "
            f"BatchProcessor ä¸åº”å°† device_role å†™å…¥è¾“å‡ºæ–‡ä»¶ã€‚"
        )
    
    # 3. ã€æ–°å¢ã€‘éªŒè¯ quality_flags å­˜å‚¨æ ¼å¼ (JSON string)
    if "quality_flags" in column_names:
        qf_field = schema.field_by_name("quality_flags")
        if qf_field.physical_type != "BYTE_ARRAY":
            self.logger.warning("quality_flags å»ºè®®å­˜å‚¨ä¸º JSON string (BYTE_ARRAY)")
    
    self.logger.info(f"Schema éªŒè¯é€šè¿‡: INT64/UTC/NANOSï¼Œæ—  device_role")
```

---

### Phase 3: Manifest ç”Ÿæˆä¸ Audit Trail å®Œæ•´æ€§ (Day 3-4, å…³é”®æ›´æ–°)

#### Step 3.1: Manifest ç”Ÿæˆï¼ˆå« Temporal Baseline ä¸ Equipment Validation Auditï¼‰

**æ–¹æ³•**: `_generate_manifest(df: pl.DataFrame, column_metadata: Dict, equipment_audit: Dict, output_files: List[str]) -> Manifest`

**è¯¦ç»†é€»è¾‘**:
```python
def _generate_manifest(
    self, 
    df: pl.DataFrame, 
    column_metadata: Optional[Dict[str, FeatureMetadata]] = None,
    equipment_audit: Optional[Dict] = None,  # ã€æ–°å¢ã€‘æ¥è‡ª Cleaner
    output_files: List[str] = None
) -> Manifest:
    """
    ç”Ÿæˆ Manifest (Interface Contract #3)
    
    ã€å…³é”®ã€‘æ•´åˆï¼š
    1. Annotation ç¨½æ ¸è½¨è¿¹
    2. Temporal Baseline ä¼ é€’
    3. Equipment Validation Audit ä¼ é€’
    4. SSOT ç‰ˆæœ¬æ£€æŸ¥ (E408)
    """
    # è‹¥ä¸Šæ¸¸æœªæä¾› metadataï¼Œä½¿ç”¨ä¿å®ˆé¢„è®¾ (E203 Warning)
    if not column_metadata:
        self.logger.warning(
            "E203: æœªæ¥æ”¶åˆ° column_metadataï¼Œä½¿ç”¨ä¿å®ˆé¢„è®¾ (physical_type='gauge')ã€‚ "
            "å»ºè®®å‡çº§è‡³ Cleaner v2.2+ ä»¥ä¼ é€’å®Œæ•´ metadataã€‚"
        )
        column_metadata = self._infer_metadata_conservative(df)
    
    # ã€å…³é”®ã€‘ç¡®ä¿ column_metadata ä¸å« device_roleï¼ˆäºŒæ¬¡é˜²æŠ¤ï¼‰
    for col_name, meta in column_metadata.items():
        if isinstance(meta, dict) and 'device_role' in meta:
            raise ContractViolationError(
                f"E500: column_metadata åŒ…å« device_roleã€‚ "
                f"Cleaner ä¸åº”ä¼ é€’ device_role è‡³ BatchProcessorã€‚"
            )
        if hasattr(meta, 'device_role'):
            raise ContractViolationError(f"E500: column_metadata å¯¹è±¡åŒ…å« device_role å±æ€§")
    
    # ã€æ–°å¢ã€‘SSOT ç‰ˆæœ¬æ£€æŸ¥ (E408)
    current_flags = set(VALID_QUALITY_FLAGS)
    # è®°å½•å½“å‰ä½¿ç”¨çš„ flags ä¾›ä¸‹æ¸¸æ£€æŸ¥
    quality_flags_snapshot = list(VALID_QUALITY_FLAGS)
    
    # è®¡ç®—ç»Ÿè®¡èµ„è®¯
    stats = {
        "total_rows": len(df),
        "total_cols": len(df.columns),
        "time_range": {
            "start": df["timestamp"].min().isoformat(),
            "end": df["timestamp"].max().isoformat()
        },
        "null_percent": df.null_count().sum() / (len(df) * len(df.columns)),
        "files_count": len(output_files)
    }
    
    # ã€æ–°å¢ã€‘æ„å»º Annotation ç¨½æ ¸è½¨è¿¹
    audit_trail = {}
    if self.annotation_metadata:
        audit_trail = {
            "schema_version": self.annotation_metadata.get('schema_version', 'unknown'),
            "template_version": self.annotation_metadata.get('template_version', 'unknown'),
            "yaml_checksum": self.annotation_metadata.get('yaml_checksum', ''),
            "inheritance_chain": self.annotation_metadata.get('inheritance_chain', 'none'),
            "last_updated": self.annotation_metadata.get('last_updated', ''),
            "editor": self.annotation_metadata.get('editor', 'unknown')
        }
    else:
        self.logger.warning("æœªæä¾› Annotation Metadataï¼ŒManifest å°†ç¼ºå°‘ç¨½æ ¸è½¨è¿¹")
    
    # ã€æ–°å¢ã€‘è®¾å¤‡é€»è¾‘ç¨½æ ¸è½¨è¿¹ï¼ˆæ¥è‡ª Cleaner v2.2ï¼‰
    if equipment_audit is None:
        equipment_audit = {
            "validation_enabled": False,
            "constraints_applied": [],
            "violations_detected": 0,
            "violation_details": []
        }
    
    # ã€å…³é”®ã€‘æ„å»º Temporal Baseline
    temporal_baseline = {
        "pipeline_origin_timestamp": self.pipeline_origin_timestamp.isoformat(),
        "timezone": "UTC",
        "baseline_version": "1.0"
    }
    
    # å»ºç«‹ Manifest
    manifest = Manifest(
        batch_id=self.batch_id,
        site_id=self.site_id,
        created_at=datetime.now(timezone.utc),
        temporal_baseline=temporal_baseline,  # ã€æ–°å¢ã€‘
        feature_metadata=column_metadata,     # ä»…å«ç‰©ç†å±æ€§ï¼Œä¸å« device_role
        annotation_audit_trail=audit_trail,   # ã€æ–°å¢ã€‘ç¨½æ ¸è½¨è¿¹
        equipment_validation_audit=equipment_audit,  # ã€æ–°å¢ã€‘è®¾å¤‡ç¨½æ ¸
        quality_flags_schema=quality_flags_snapshot,  # SSOT å¿«ç…§ä¾› E408 æ£€æŸ¥
        timestamp_schema={
            "format": "INT64",
            "unit": "nanoseconds",
            "timezone": "UTC"
        },
        output_files=output_files or [],
        statistics=stats,
        file_checksums=self._compute_file_checksums(output_files or [])
    )
    
    # è®¡ç®— Manifest è‡ªèº« checksum
    manifest.checksum = manifest.compute_checksum()
    
    self.logger.info(
        f"Manifest ç”Ÿæˆå®Œæˆ: {self.batch_id}, "
        f"Temporal Baseline: {temporal_baseline['pipeline_origin_timestamp']}, "
        f"Annotation: {audit_trail.get('schema_version', 'N/A')}, "
        f"Equipment Audit: {equipment_audit.get('violations_detected', 0)} violations, "
        f"ç»§æ‰¿é“¾: {audit_trail.get('inheritance_chain', 'N/A')}"
    )
    
    return manifest
```

#### Step 3.2: ä¸‹æ¸¸è¡”æ¥è§„èŒƒï¼ˆFeature Engineer è¯»å–æ–¹å¼ï¼‰

**æ–‡ä»¶è§„èŒƒ**: Feature Engineer å¿…é¡»é€è¿‡ Manifest è¯»å–ï¼Œå¹¶ç›´æ¥æŸ¥è¯¢ Annotation SSOT å–å¾— device_role

```python
# Feature Engineer v1.3 çš„æ ‡å‡†è¯»å–æ–¹å¼
def load_from_batch_processor(manifest_path: Path) -> Tuple[pl.LazyFrame, Dict, Dict, TemporalContext]:
    """
    ä» BatchProcessor v1.3-CA è¾“å‡ºè¯»å–èµ„æ–™ã€Metadataã€ç¨½æ ¸è½¨è¿¹ä¸æ—¶é—´åŸºå‡†
    
    Returns:
        df: LazyFrame (Parquet èµ„æ–™ï¼Œä¸å« device_role)
        feature_metadata: Dict (ç‰©ç†å±æ€§)
        annotation_audit_trail: Dict (ç‰ˆæœ¬ä¸ç»§æ‰¿èµ„è®¯)
        temporal_context: TemporalContext (æ—¶é—´åŸºå‡†ä¾›æœªæ¥æ•°æ®æ£€æŸ¥)
    """
    manifest = Manifest.parse_file(manifest_path)
    
    # 1. éªŒè¯ Manifest å®Œæ•´æ€§
    if not manifest.validate_checksum():
        raise DataValidationError("E301: Manifest æŸæ¯æˆ–é­ç¯¡æ”¹")
    
    # 2. ã€æ–°å¢ã€‘éªŒè¯æ—¶é—´åŸºå‡†å­˜åœ¨æ€§
    if not hasattr(manifest, 'temporal_baseline') or not manifest.temporal_baseline:
        raise ContractViolationError("E000: Manifest é—å¤± temporal_baseline")
    
    temporal_context = TemporalContext(
        pipeline_timestamp=datetime.fromisoformat(manifest.temporal_baseline['pipeline_origin_timestamp']),
        site_id=manifest.site_id
    )
    
    # 3. ã€æ–°å¢ã€‘éªŒè¯ SSOT ç‰ˆæœ¬ç›¸å®¹æ€§ (E408)
    if set(manifest.quality_flags_schema) != set(VALID_QUALITY_FLAGS):
        raise ConfigurationError(
            f"E408: Manifest çš„ quality_flags_schema ä¸ä»£ç  SSOT ä¸ç¬¦ã€‚ "
            f"Manifest: {manifest.quality_flags_schema}, "
            f"SSOT: {VALID_QUALITY_FLAGS}ã€‚ "
            f"è¯·é‡æ–°æ‰§è¡Œ Pipeline ä»¥ç¡®ä¿ç‰ˆæœ¬ä¸€è‡´ã€‚"
        )
    
    # 4. ã€æ–°å¢ã€‘éªŒè¯ Annotation ç‰ˆæœ¬
    audit = manifest.annotation_audit_trail
    if audit:
        expected_ver = FEATURE_ANNOTATION_CONSTANTS['expected_schema_version']
        if audit.get('schema_version') != expected_ver:
            raise ConfigurationError(
                f"E400: Manifest çš„ Annotation ç‰ˆæœ¬è¿‡æ—§ "
                f"({audit.get('schema_version')} vs {expected_ver})"
            )
    
    # 5. è¯»å–èµ„æ–™
    files = [manifest_path.parent / f for f in manifest.output_files]
    df = pl.scan_parquet(files)
    
    # 6. ã€å…³é”®ã€‘Feature Engineer ç›´æ¥è¯»å– Annotation YAML å–å¾— device_role
    # è€Œéä» manifest.feature_metadataï¼ˆè¯¥å¤„ä¸å« device_roleï¼‰
    from src.features.annotation_manager import FeatureAnnotationManager
    annotation_manager = FeatureAnnotationManager(
        site_id=manifest.site_id,
        yaml_base_dir="config/features/sites"
    )
    
    # 7. ã€æ–°å¢ã€‘ä¼ é€’ Equipment Validation Audit è‡³ Optimizationï¼ˆå¦‚éœ€è¦ï¼‰
    equipment_audit = manifest.equipment_validation_audit
    
    return df, manifest.feature_metadata, audit, temporal_context, annotation_manager, equipment_audit
```

---

### Phase 4: æ‰¹æ¬¡å¤„ç†æµç¨‹æ•´åˆ (Day 5)

#### Step 4.1: ä¸»å¤„ç†æµç¨‹ï¼ˆæ›´æ–°ç‰ˆï¼‰

**æ–¹æ³•**: `process_single_file(file_path: Path) -> BatchResult`

**è¯¦ç»†é€»è¾‘**:
```python
@dataclass
class BatchResult:
    status: str  # "success", "failed", "future_data_rejected", "schema_invalid", "sync_error"
    file_path: Optional[Path] = None
    manifest_path: Optional[Path] = None
    error: Optional[str] = None
    annotation_audit_trail: Optional[Dict] = None  # ã€æ–°å¢ã€‘å›ä¼ ç¨½æ ¸èµ„è®¯
    temporal_baseline: Optional[Dict] = None       # ã€æ–°å¢ã€‘å›ä¼ æ—¶é—´åŸºå‡†

def process_single_file(self, file_path: Path) -> BatchResult:
    """
    å¤„ç†å•ä¸€æ–‡ä»¶çš„å®Œæ•´æµç¨‹ (å« Annotation ç¨½æ ¸è½¨è¿¹ä¸ Temporal Baseline)
    """
    try:
        # 1. è§£æ (Parser v2.1)
        raw_df = self.parser.parse_file(str(file_path))
        
        # 2. æ¸…æ´— (Cleaner v2.2) - å›ä¼ ä¸å« device_role çš„ metadata ä¸ equipment_audit
        clean_df, column_metadata, equipment_audit = self.cleaner.clean(raw_df)
        # æ³¨æ„ï¼šcleaner.clean() åº”å›ä¼  (df, metadata, equipment_validation_audit)
        
        # 3. è¾“å…¥å¥‘çº¦éªŒè¯ï¼ˆæ£€æŸ¥ç‚¹ #2ï¼Œå« E500 device_role æ£€æŸ¥ã€E205 æœªæ¥æ•°æ®ã€E351 è®¾å¤‡ç¨½æ ¸ï¼‰
        input_metadata = {
            'pipeline_origin_timestamp': self.pipeline_origin_timestamp.isoformat(),
            'equipment_validation_audit': equipment_audit
        }
        self._validate_input_contract(clean_df, input_metadata)
        
        # 4. Data Leakage æ£€æŸ¥ (E205 - å·²åœ¨ _validate_input_contract ä¸­æ‰§è¡Œ)
        
        # 5. è®¾å®š Staging
        staging_path = self._setup_staging()
        
        # 6. å†™å…¥ Parquet (å¼ºåˆ¶ INT64/UTCï¼Œæ—  device_role)
        parquet_file = self._write_parquet_atomic(clean_df, staging_path)
        
        # 7. ç”Ÿæˆ Manifestï¼ˆå« annotation_audit_trailã€temporal_baselineã€equipment_validation_auditï¼‰
        manifest = self._generate_manifest(
            clean_df, 
            column_metadata=column_metadata,
            equipment_audit=equipment_audit,  # ã€æ–°å¢ã€‘ä¼ é€’è®¾å¤‡ç¨½æ ¸
            output_files=["data.parquet"]
        )
        
        # 8. å†™å…¥ Manifest
        manifest_path = staging_path / "manifest.json"
        manifest_path.write_text(manifest.json(indent=2))
        
        # 9. è®¡ç®—æ¡£æ¡ˆ checksums
        manifest.file_checksums = {
            "data.parquet": self._compute_file_hash(parquet_file)
        }
        manifest_path.write_text(manifest.json(indent=2))
        
        # 10. åŸå­ç§»åŠ¨è‡³è¾“å‡ºç›®å½•
        final_path = self._atomic_move_to_output(staging_path)
        
        return BatchResult(
            status="success",
            file_path=file_path,
            manifest_path=final_path / "manifest.json",
            annotation_audit_trail=manifest.annotation_audit_trail,
            temporal_baseline=manifest.temporal_baseline  # ã€æ–°å¢ã€‘
        )
        
    except AnnotationSyncError as e:  # ã€æ–°å¢ã€‘E406
        return BatchResult(
            status="sync_error",
            file_path=file_path,
            error=str(e)
        )
        
    except FutureDataError as e:
        return BatchResult(
            status="future_data_rejected",
            file_path=file_path,
            error=str(e),
            temporal_baseline={"pipeline_origin_timestamp": self.pipeline_origin_timestamp.isoformat()}
        )
        
    except ContractViolationError as e:  # E202, E206, E500, E408, E409
        self.logger.error(f"å¥‘çº¦è¿å {file_path}: {e}")
        self._cleanup_staging()
        return BatchResult(
            status="schema_invalid",
            file_path=file_path,
            error=str(e)
        )
        
    except Exception as e:
        self.logger.exception(f"å¤„ç†å¤±è´¥ {file_path}: {e}")
        self._cleanup_staging()
        return BatchResult(
            status="failed",
            file_path=file_path,
            error=str(e)
        )
```

---

## 4. é”™è¯¯ä»£ç å¯¹ç…§è¡¨ (Error Codes - Updated)

| é”™è¯¯ä»£ç  | åç§° | å‘ç”Ÿé˜¶æ®µ | è¯´æ˜ | å¤„ç†å»ºè®® | ä¸¥é‡åº¦ |
|:---|:---|:---:|:---|:---|:---:|
| **E000** | `TEMPORAL_BASELINE_MISSING` | Step 1.1 | æœªæ¥æ”¶ pipeline_origin_timestamp | æ£€æŸ¥ Container ä¼ é€’é€»è¾‘ | ğŸ”´ Critical |
| **E201** | `INPUT_SCHEMA_MISMATCH` | Step 1.1 | è¾“å…¥ DataFrame Schema ä¸ç¬¦ | æ£€æŸ¥ Cleaner è¾“å‡ºè®¾å®š | ğŸŸ¡ Medium |
| **E202** | `UNKNOWN_QUALITY_FLAG` | Step 1.1 | è¾“å…¥å«æœªå®šä¹‰çš„ quality_flags | åŒæ­¥æ›´æ–° SSOT | ğŸ”´ Critical |
| **E203** | `METADATA_LOSS` | Step 3.1 | æœªæ¥æ”¶åˆ° column_metadata | å‡çº§è‡³ Cleaner v2.2+ | ğŸŸ¡ Medium |
| **E205** | `FUTURE_DATA_IN_BATCH` | Step 1.1 | èµ„æ–™æ—¶é—´è¶…è¿‡ pipeline_origin_timestamp + 5min | æ£€æŸ¥èµ„æ–™æ¥æºæ—¶é’Ÿ | ğŸ”´ Critical |
| **E206** | `PARQUET_FORMAT_VIOLATION` | Step 2.1 | Parquet æ ¼å¼é INT64/UTC | æ£€æŸ¥ use_pyarrow=False | ğŸ”´ Critical |
| **E301** | `MANIFEST_INTEGRITY_FAILED` | Step 3.1 | Manifest checksum éªŒè¯å¤±è´¥ | é‡æ–°æ‰§è¡Œ BatchProcessor | ğŸ”´ Critical |
| **E302** | `SCHEMA_MISMATCH` | Step 3.2 | Timestamp ç‰©ç†å‹åˆ«é INT64 | æ£€æŸ¥ Parquet å†™å…¥é€»è¾‘ | ğŸ”´ Critical |
| **E351** | `EQUIPMENT_VALIDATION_AUDIT_MISSING` | Step 1.1 | å¯ç”¨è®¾å¤‡é€»è¾‘åŒæ­¥ä½†æœªæ¥æ”¶ç¨½æ ¸è½¨è¿¹ | æ£€æŸ¥ Cleaner v2.2 è®¾å®š | ğŸŸ¡ Medium |
| **E406** | `EXCEL_YAML_OUT_OF_SYNC` | Step 0.2 | Excel ä¸ YAML ä¸åŒæ­¥ | æ‰§è¡Œ validate-annotation | ğŸ”´ Critical |
| **E408** | `SSOT_QUALITY_FLAGS_MISMATCH` | Step 3.1 | Manifest ä¸­çš„ flags ä¸ä»£ç  SSOT ä¸ç¬¦ | é‡æ–°æ‰§è¡Œ Pipeline | ğŸ”´ Critical |
| **E409** | `HEADER_ANNOTATION_MISMATCH` | Step 1.1 | CSV æ ‡å¤´ï¼ˆæ­£è§„åŒ–åï¼‰ä¸ Annotation å­—æ®µåç§°ä¸åŒ¹é… | æ£€æŸ¥ Excel æ ‡æ³¨æˆ– Parser è®¾å®š | ğŸŸ¡ Medium |
| **E500** | `DEVICE_ROLE_LEAKAGE` | Step 1.1/2.1 | DataFrame æˆ– Metadata å« device_role | æ£€æŸ¥ Cleaner èŒè´£åˆ†ç¦»é€»è¾‘ | ğŸ”´ Critical |

---

## 5. æµ‹è¯•ä¸éªŒè¯è®¡åˆ’ (Test Plan - Updated)

### 5.1 å•å…ƒæµ‹è¯• (Unit Tests)

| æµ‹è¯•æ¡ˆä¾‹ ID | æè¿° | è¾“å…¥ | é¢„æœŸç»“æœ | å¯¹åº” Step |
|:---|:---|:---|:---|:---:|
| BP13-CA-01 | Temporal Baseline é—å¤± | æ—  temporal_context | æŠ›å‡º E000 | 0.2 |
| BP13-CA-02 | æœªæ¥æ•°æ®æ£€æŸ¥ï¼ˆä½¿ç”¨åŸºå‡†ï¼‰ | èµ„æ–™æ—¶é—´ > åŸºå‡†+5min | æŠ›å‡º E205 | 1.1 |
| BP13-CA-03 | E408 SSOT ç‰ˆæœ¬æ£€æŸ¥ | VALID_QUALITY_FLAGS å˜æ›´å | Manifest è®°å½•æ—§ç‰ˆæœ¬ï¼Œè§¦å‘ E408 | 3.1 |
| BP13-CA-04 | Equipment Audit ä¼ é€’ | Cleaner å›ä¼  audit | Manifest æ­£ç¡®åŒ…å« violations_detected | 3.1 |
| BP13-CA-05 | E409 æ ‡å¤´æ£€æŸ¥ | é snake_case å­—æ®µ | è®°å½•è­¦å‘Š | 1.1 |
| **BP13-CA-06** | é•¿æ—¶é—´æ‰§è¡Œæ—¶é—´ä¸€è‡´æ€§ | Pipeline æ‰§è¡Œ 10 åˆ†é’Ÿå | ä»ä½¿ç”¨åˆå§‹æ—¶é—´åŸºå‡†ï¼Œä¸æ¼‚ç§» | 1.1 |
| BP13-FA-01 | E406 åŒæ­¥æ£€æŸ¥ | Excel è¾ƒæ–° | æŠ›å‡º AnnotationSyncError | 0.2 |
| BP13-FA-02 | device_role æ‹¦æˆª | DataFrame å« device_role å­—æ®µ | æŠ›å‡º E500 | 1.1 |
| BP13-FA-03 | Metadata ä¸å« device_role | column_metadata å« device_role | æŠ›å‡º E500 | 3.1 |
| BP13-FA-04 | ç¨½æ ¸è½¨è¿¹å®Œæ•´æ€§ | æ­£å¸¸å¤„ç† | Manifest å« inheritance_chain | 3.1 |
| BP13-001 | INT64 å¼ºåˆ¶éªŒè¯ | æ¨¡æ‹Ÿ INT96 å†™å…¥ | æ‹¦æˆªå¹¶æŠ›å‡º E206 | 2.1 |
| BP13-002 | æœªæ¥æ•°æ®æ‹¦æˆª | æ—¶é—´æˆ³ä¸ºæ˜å¤© | æŠ›å‡º E205 | 1.1 |

### 5.2 æ•´åˆæµ‹è¯• (Integration Tests)

| æµ‹è¯•æ¡ˆä¾‹ ID | æè¿° | ä¸Šæ¸¸ | ä¸‹æ¸¸ | éªŒè¯ç›®æ ‡ |
|:---|:---|:---:|:---:|:---|
| **INT-BP-CA-01** | æ—¶é—´åŸºå‡†ä¼ é€’é“¾ | Parser (å¸¦åŸºå‡†) â†’ Cleaner â†’ BP | FE v1.3 | å…¨ç¨‹ä½¿ç”¨ç›¸åŒ pipeline_origin_timestamp |
| **INT-BP-CA-02** | Equipment Validation Sync | Cleaner v2.2 (å«é¢„æ£€) â†’ BP | Optimization v1.1 | Manifest åŒ…å« equipment_validation_auditï¼Œä¸ Optimization é™åˆ¶æ¡ä»¶ä¸€è‡´ |
| **INT-BP-CA-03** | SSOT ç‰ˆæœ¬æ£€æŸ¥ | BP v1.3 (æ—§ flags) â†’ FE | FE v1.3 | FE æ­£ç¡®æŠ›å‡º E408 |
| INT-BP-FA-01 | E406 æ£€æŸ¥ç‚¹ | Excel ä¿®æ”¹æœªç”Ÿæˆ YAML | BP v1.3 | æ­£ç¡®æŠ›å‡º E406ï¼Œé˜»æŒ¡å¤„ç† |
| INT-BP-FA-02 | Cleaner èŒè´£åˆ†ç¦» | Cleaner v2.2 (æ—  device_role) | BP v1.3 | æ­£ç¡®æ¥æ”¶ï¼ŒManifest æ—  device_role |
| INT-BP-FA-03 | ç¨½æ ¸è½¨è¿¹ä¼ é€’ | BP v1.3 (å« inheritance_chain) | FE v1.3 | FE æ­£ç¡®è¯»å–ç‰ˆæœ¬ä¸ç»§æ‰¿èµ„è®¯ |
| INT-B01 | Cleaner v2.2 â†’ BP v1.3 | Cleaner v2.2 (UTC, metadata) | BP v1.3 | æ­£ç¡®æ¥æ”¶ metadataï¼Œæ—  E203 |
| INT-B02 | BP v1.3 â†’ Feature Engineer v1.3 | BP v1.3 (Manifest) | FE v1.3 | FE æ­£ç¡®è¯»å– audit_trail ä¸ temporal_baseline |

---

## 6. ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µ (Version Compatibility Matrix - Updated)

| Cleaner | BatchProcessor | Feature Engineer | Feature Annotation | Interface Contract | å…¼å®¹æ€§ | è¯´æ˜ |
|:---:|:---:|:---:|:---:|:---:|:---:|:---|
| v2.2 (æ—  device_role, å« Equipment Audit) | **v1.3-CA** | v1.3+ | v1.2 | v1.1 | âœ… **å®Œå…¨ç›¸å®¹** | æ¨èé…ç½®ï¼Œæ”¯æ´ Temporal Baseline ä¸ Equipment Validation Sync |
| v2.2 | **v1.3-CA** | v1.2 | v1.2 | v1.1 | âš ï¸ **éƒ¨åˆ†ç›¸å®¹** | FE v1.2 æ— æ³•è¯»å– temporal_baselineï¼Œä½†åŠŸèƒ½æ­£å¸¸ |
| v2.1 (æœ‰ device_role) | **v1.3-CA** | ä»»æ„ | ä»»æ„ | v1.1 | âŒ **ä¸ç›¸å®¹** | è§¦å‘ E500ï¼Œéœ€å‡çº§ Cleaner |
| ä»»æ„ | v1.2 | ä»»æ„ | ä»»æ„ | v1.1 | âŒ **ä¸ç›¸å®¹** | v1.2 æ— æ³•ä¼ é€’ temporal_baseline ä¸ equipment_validation_audit |
| v2.2 | **v1.3-CA** | v1.3+ | v1.1 | v1.1 | âš ï¸ **é™ç´šç›¸å®¹** | ç¼ºå°‘éƒ¨åˆ† device_role åŠŸèƒ½ï¼Œä½†åŸºç¡€åŠŸèƒ½æ­£å¸¸ |

---

## 7. é£é™©è¯„ä¼°ä¸ç¼“è§£ (Risk Assessment - Updated)

| é£é™© | ä¸¥é‡åº¦ | å¯èƒ½æ€§ | ç¼“è§£æªæ–½ | çŠ¶æ€ |
|:---|:---:|:---:|:---|:---:|
| **æ—¶é—´æ¼‚ç§»** (ä½¿ç”¨ now() è€ŒéåŸºå‡†) | ğŸ”´ High | Medium | å»ºæ„å­å¼ºåˆ¶æ£€æŸ¥ temporal_contextï¼Œè¿åæŠ›å‡º E000 | å·²å¼ºåŒ– |
| **è®¾å¤‡é€»è¾‘è„±é’©** (æ¸…æ´—ä¸ä¼˜åŒ–ä¸ä¸€è‡´) | ğŸ”´ High | Medium | å¼ºåˆ¶ä¼ é€’ equipment_validation_auditï¼Œå…±ç”¨ SSOT é™åˆ¶æ¡ä»¶ | å·²æ–°å¢ |
| **SSOT ç‰ˆæœ¬æ¼‚ç§»** (E408) | ğŸ”´ High | Medium | Manifest è®°å½• quality_flags_schemaï¼Œä¸‹æ¸¸å¼ºåˆ¶æ£€æŸ¥ | å·²æ–°å¢ |
| **èŒè´£è¾¹ç•Œæ··æ·†** | ğŸ”´ High | Medium | ä¸‰å±‚é˜²æŠ¤ï¼šç™½åå•+Schemaå‡€åŒ–+CI Gate | ç»´æŒ |
| **æ ‡å¤´ä¸åŒ¹é…** (Parser-Cleaner-Annotation) | ğŸŸ¡ Medium | Medium | E409 æ£€æŸ¥ï¼ŒéªŒè¯ snake_case ä¸ Annotation åŒ¹é… | å·²æ–°å¢ |
| **åˆå§‹åŒ–é¡ºåºé”™è¯¯** | ğŸ”´ High | Low | Foundation First Policy æ˜ç¡®å£°æ˜ä¾èµ–é¡ºåº | å·²æ–°å¢ |

---

## 8. äº¤ä»˜ç‰©æ¸…å• (Deliverables - Updated)

### 8.1 ä»£ç æ–‡ä»¶
1. `src/etl/batch_processor.py` - ä¸»è¦å®æ–½ (v1.3-Contract-Alignedï¼Œå« E406/E500/E408 æ£€æŸ¥ã€Temporal Baselineã€Equipment Validation Audit)
2. `src/etl/manifest.py` - Manifest æ¨¡å‹æ›´æ–° (æ–°å¢ temporal_baseline, equipment_validation_audit, annotation_audit_trail)
3. `src/etl/contract_validator.py` - å¥‘çº¦éªŒè¯é€»è¾‘ (å¯å¤ç”¨æ¨¡å—)

### 8.2 æµ‹è¯•æ–‡ä»¶
4. `tests/test_batch_processor_v13_contract_aligned.py` - v1.3-CA ä¸“å±æµ‹è¯•ï¼ˆå« Temporal Baselineã€E408ã€Equipment Audit éªŒè¯ï¼‰
5. `tests/test_manifest_audit_trail.py` - ç¨½æ ¸è½¨è¿¹å®Œæ•´æ€§æµ‹è¯•ï¼ˆå« Equipment Validation Auditï¼‰
6. `tests/test_integration_temporal_baseline.py` - æ—¶é—´åŸºå‡†ä¼ é€’æ•´åˆæµ‹è¯•
7. `tests/test_integration_equipment_validation_sync.py` - è®¾å¤‡é€»è¾‘åŒæ­¥æ•´åˆæµ‹è¯•

### 8.3 æ–‡ä»¶æ–‡ä»¶
8. `docs/batch_processor/PRD_BATCH_PROCESSOR_v1.3-Contract-Aligned.md` - **æœ¬æ–‡ä»¶**
9. `docs/batch_processor/MANIFEST_SPEC_v1.3-CA.md` - Manifest JSON Schema è§„èŒƒ (ä¾› Feature Engineer ä¸ Optimization å‚è€ƒ)
10. `docs/batch_processor/EQUIPMENT_VALIDATION_SYNC.md` - è®¾å¤‡é€»è¾‘åŒæ­¥å®æ–½æŒ‡å—

---

## 9. éªŒæ”¶ç­¾æ ¸ (Sign-off Checklist)

- [ ] **Temporal Baseline å¼ºåˆ¶ä½¿ç”¨ (E000)**ï¼šæœªæ¥æ”¶ temporal_context æ—¶æ­£ç¡®æŠ›å‡º E000
- [ ] **æœªæ¥æ•°æ®æ£€æŸ¥ (E205)**ï¼šä½¿ç”¨ pipeline_origin_timestamp è€Œé now()ï¼Œé•¿æ—¶é—´æ‰§è¡Œæµ‹è¯•é€šè¿‡
- [ ] **è®¾å¤‡é€»è¾‘ç¨½æ ¸ä¼ é€’ (E351)**ï¼šæ­£ç¡®æ¥æ”¶å¹¶ä¼ é€’ equipment_validation_audit è‡³ Manifest
- [ ] **SSOT ç‰ˆæœ¬æ£€æŸ¥ (E408)**ï¼šå½“ Manifest ä¸­çš„ quality_flags_schema ä¸ä»£ç  SSOT ä¸ç¬¦æ—¶æ­£ç¡®æŠ›å‡º E408
- [ ] **æ ‡å¤´å¯¹åº” (E409)**ï¼šéªŒè¯ Parser æ­£è§„åŒ–åçš„æ ‡å¤´ä¸ Annotation åŒ¹é…
- [ ] **E406 å¼ºåŒ–å¤„ç†**ï¼šæä¾›è¯¦ç»†çš„æ¢å¤æ­¥éª¤æŒ‡å¼•ï¼Œæ•´åˆæ–‡ä»¶é”æœºåˆ¶
- [ ] **èŒè´£åˆ†ç¦» (E500)**ï¼šè¾“å‡ºç»å¯¹ä¸å« device_roleï¼Œä¸‰å±‚é˜²æŠ¤æœºåˆ¶è¿ä½œæ­£å¸¸
- [ ] **æ—¶é—´åŸºå‡†ä¼ é€’**ï¼šManifest æ­£ç¡®åŒ…å« temporal_baselineï¼Œä¸‹æ¸¸ Feature Engineer å¯æ­£ç¡®è¯»å–
- [ ] **Interface Contract v1.1 å¯¹é½**ï¼šæ£€æŸ¥ç‚¹ #3 æ‰€æœ‰é¡¹ç›®é€šè¿‡éªŒè¯
- [ ] **Foundation First Policy**ï¼šç¡®è®¤å®æ–½é¡ºåºç¬¦åˆå£°æ˜ï¼ˆAnnotationManager â†’ TemporalContext â†’ Cleaner â†’ BatchProcessorï¼‰

---

**å…³é”®è®¾è®¡ç¡®è®¤**ï¼š
1. BatchProcessor **ä¸å¤„ç†** device_role é€»è¾‘ï¼ˆä»…ä¼ é€’ç‰ˆæœ¬èµ„è®¯ï¼‰
2. Manifest çš„ `feature_metadata` **ä»…å«** physical_type/unitï¼ˆæ¥è‡ª Cleanerï¼‰
3. Manifest çš„ `equipment_validation_audit` **å¿…é¡»ä¼ é€’**è‡³ä¸‹æ¸¸ Optimizationï¼ˆè§£å†³ Physics Logic Decouplingï¼‰
4. `temporal_baseline` **å¿…é¡»ä¼ é€’**è‡³ä¸‹æ¸¸ï¼ˆè§£å†³ Spatio-Temporal Inconsistencyï¼‰
5. **E408 æ£€æŸ¥**ç¡®ä¿ SSOT ç‰ˆæœ¬ä¸€è‡´æ€§ï¼Œé˜²æ­¢ Silent Failure
```