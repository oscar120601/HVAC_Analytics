# PRD v1.3-Complete: ç‰¹å¾µæ¨™è¨»ç³»çµ±è¦ç¯„ (HVAC å®Œæ•´å¯¦ä½œç‰ˆ)

**æ–‡ä»¶ç‰ˆæœ¬:** v1.3-Complete (Aligned with Interface Contract v1.1)  
**æ—¥æœŸ:** 2026-02-14  
**è² è²¬äºº:** Oscar Chang / HVAC ç³»çµ±å·¥ç¨‹åœ˜éšŠ  
**ç›®æ¨™:** å»ºç«‹ HVAC å†°æ°´ä¸»æ©Ÿæˆ¿èˆ‡ç©ºèª¿ç³»çµ±çš„çµ±ä¸€ç‰¹å¾µæ¨™è¨»è¦ç¯„ï¼Œå¼·åŒ–å–®å‘æµç¨‹ç®¡æ§ã€è¨­å‚™é‚è¼¯ä¸€è‡´æ€§ã€æ™‚é–“åŸºæº–é˜²è­·èˆ‡ç‰¹å¾µå°é½Šæ©Ÿåˆ¶  
**ç›¸ä¾æ–‡ä»¶:** 
- Interface Contract v1.1 (PRD_Interface_Contract_v1.1.md)
- Cleaner v2.2+, Feature Engineer v1.3+, Optimization v1.1+
- Parser v2.1+ (å« Header Standardization)

---

## 1. åŸ·è¡Œç¸½ç¶±èˆ‡è¨­è¨ˆå“²å­¸

### 1.1 æ ¸å¿ƒç›®æ¨™è²æ˜

æœ¬è¦ç¯„æ—¨åœ¨å»ºç«‹**å·¥æ¥­ç´š HVAC è³‡æ–™æ²»ç†åŸºç¤è¨­æ–½**ï¼Œè§£æ±ºä»¥ä¸‹é—œéµç—›é»ï¼š

1. **è¨­å‚™èªæ„ä¸€è‡´æ€§**: çµ±ä¸€å†°æ°´ä¸»æ©Ÿã€æ°´æ³µã€å†·å»æ°´å¡”ã€ç©ºèª¿ç®±ç­‰è¨­å‚™çš„å‘½åèˆ‡åˆ†é¡é‚è¼¯
2. **ç‰©ç†é‚è¼¯é˜²å‘†**: é€éè¨­å‚™äº’é–æª¢æŸ¥ï¼ˆInterlock Validationï¼‰é˜²æ­¢ã€Œä¸»æ©Ÿé–‹å•Ÿä½†æ°´æ³µæœªé‹è½‰ã€ç­‰ç‰©ç†ä¸å¯èƒ½æƒ…å¢ƒ
3. **å–®å‘æµç¨‹ç®¡æ§**: æœçµ•ã€ŒExcel â†” YAML é›™å‘ä¿®æ”¹ã€å°è‡´çš„ç«¶æ…‹æ¢ä»¶èˆ‡è¨­å®šéºå¤±
4. **æ™‚é–“ä¸€è‡´æ€§é˜²è­·**: å»ºç«‹å…¨åŸŸæ™‚é–“åŸºæº–ï¼ˆTemporal Baselineï¼‰ï¼Œé˜²æ­¢é•·æ™‚é–“åŸ·è¡Œæµç¨‹ä¸­çš„æ™‚é–“æ¼‚ç§»å°è‡´æœªä¾†è³‡æ–™èª¤åˆ¤
5. **ç‰¹å¾µå°é½Šä¿è­‰**: ç¢ºä¿ Training èˆ‡ Optimization éšæ®µçš„ç‰¹å¾µå‘é‡ã€ç¸®æ”¾åƒæ•¸ã€è¨­å‚™é™åˆ¶å®Œå…¨ä¸€è‡´ï¼Œé˜²æ­¢ Silent Failure

### 1.2 åš´æ ¼æµç¨‹æ¶æ§‹ï¼ˆå–®å‘åŒæ­¥åŸå‰‡ï¼‰

```mermaid
graph TD
    subgraph "ç·¨è¼¯å±¤ - å”¯ä¸€å…¥å£"
        A[Excel Template v1.3] -->|æ‰‹å‹•ç·¨è¼¯| B[è¨­å‚™å·¥ç¨‹å¸«]
        C[Wizard CLI] -->|åµæ¸¬ CSV æ–°æ¬„ä½| A
        D[migrate_excel.py] -->|ç¯„æœ¬å‡ç´š| A
    end

    subgraph "é©—è­‰èˆ‡è½‰æ›å±¤"
        A -->|æ‰‹å‹•è§¸ç™¼| E[excel_to_yaml.py]
        E -->|Schema é©—è­‰| F{é©—è­‰é€šé?}
        F -->|å¦| G[è¿”å› Excel ä¿®æ­£]
        F -->|æ˜¯| H[ç”Ÿæˆ YAML]
        H -->|è¨ˆç®— Checksum| I[åŒæ­¥æª¢æŸ¥æ¨™è¨˜]
    end

    subgraph "çœŸç›¸æºå±¤ - SSOT"
        H -->|Git Commit| J[Git Repository]
        J -->|CI/CD é©—è­‰| K[Schema + é‚è¼¯æª¢æŸ¥]
        K -->|ç”¢å‡º| L[Config Server]
    end

    subgraph "é‹è¡Œæ™‚å±¤ - å¥‘ç´„é©—è­‰"
        L -->|è¼‰å…¥| M[FeatureAnnotationManager]
        M -->|æŸ¥è©¢èªæ„| N[Cleaner v2.2]
        M -->|æŸ¥è©¢ç‰¹å¾µè¦å‰‡| O[Feature Engineer v1.3]
        M -->|æŸ¥è©¢è¨­å‚™é™åˆ¶| P[Optimization v1.1]
        M -->|HVAC å°ˆç”¨æª¢æŸ¥| Q[HVAC Validator]
        
        R[TemporalContext] -->|æ™‚é–“åŸºæº–| N
        R -->|æ™‚é–“åŸºæº–| O
        R -->|æ™‚é–“åŸºæº–| P
    end

    subgraph "ç‰¹å¾µå°é½Šå±¤"
        O -->|è¼¸å‡º| S[Feature Manifest v2.0]
        S -->|é©—è­‰| P
        P -->|E901-E903 æª¢æŸ¥| T[ç‰¹å¾µå°é½Šé©—è­‰å™¨]
    end

    subgraph "ç½é›£æ¢å¾©å±¤"
        U[yaml_to_excel.py] -->|Git å›é€€å¾Œé‡å»º| A
        V[.backups/ ç›®éŒ„] -->|æœ¬åœ°å‚™ä»½é‚„åŸ| A
        W[git checkout] -->|æ­·å²é‚„åŸ| J
    end
```

**é—œéµç´„æŸï¼ˆå¼·åˆ¶åŸ·è¡Œï¼‰**:
- ğŸ”´ **ç¦æ­¢ç›´æ¥ä¿®æ”¹ YAML**: ä»»ä½•å° `config/features/sites/*.yaml` çš„æ‰‹å‹•ä¿®æ”¹å°‡è¢« Import Guard æ””æˆªï¼ˆE501 éŒ¯èª¤ï¼‰
- ğŸ”´ **Wizard åƒ…å¯« Excel**: Wizard CLI ç¦æ­¢ç›´æ¥å¯«å…¥ YAMLï¼Œåƒ…å…è¨±æ›´æ–° `.xlsx` æª”æ¡ˆ
- ğŸ”´ **æ™‚é–“åŸºæº–å¼·åˆ¶**: æ‰€æœ‰æ¨¡çµ„å¿…é ˆé€é `TemporalContext` å–å¾— `pipeline_origin_timestamp`ï¼Œç¦æ­¢ç›´æ¥ä½¿ç”¨ `datetime.now()`
- ğŸŸ¢ **Git ç‚ºæœ€çµ‚ SSOT**: æ‰€æœ‰ YAML å¿…é ˆé€² Gitï¼ŒExcel æª”æ¡ˆå¿…é ˆåœ¨ `.gitignore` ä¸­æ’é™¤
- ğŸŸ¡ **é€†å‘åŒæ­¥åƒ…é™ç½é›£æ¢å¾©**: `yaml_to_excel --mode recovery` åƒ…åœ¨ Git å›é€€æˆ–æª”æ¡ˆææ¯€æ™‚ä½¿ç”¨

---

## 2. æ–‡ä»¶æ¶æ§‹èˆ‡ç‰ˆæœ¬æ§åˆ¶ï¼ˆè©³ç´°è¦æ ¼ï¼‰

### 2.1 ç›®éŒ„çµæ§‹ï¼ˆå®Œæ•´ç‰ˆï¼‰

```
config/features/                    # SSOT ç›®éŒ„ï¼ˆå”¯è®€ï¼ŒGit ç®¡æ§ï¼‰
â”œâ”€â”€ schema.json                     # JSON Schema v1.3ï¼ˆå« HVAC æ“´å……ï¼‰
â”œâ”€â”€ base.yaml                       # åŸºç¤ç¹¼æ‰¿å®šç¾©
â”œâ”€â”€ physical_types.yaml             # ç‰©ç†é¡å‹å®Œæ•´å®šç¾©ï¼ˆ18+ é¡å‹ï¼‰
â”œâ”€â”€ equipment_taxonomy.yaml         # è¨­å‚™åˆ†é¡æ³•ï¼ˆHVAC å°ˆç”¨ï¼‰
â”œâ”€â”€ header_standardization_rules.yaml # æ¨™é ­æ­£è¦åŒ–è¦å‰‡ï¼ˆå°é½Š Interface Contract ç¬¬10ç« ï¼‰
â””â”€â”€ sites/                          # æ¡ˆå ´å®šç¾©ï¼ˆåƒ…ç”± Excel ç”Ÿæˆï¼‰
    â”œâ”€â”€ cgmh_ty.yaml
    â”œâ”€â”€ kmuh.yaml
    â””â”€â”€ template_factory.yaml       # å·¥å» ç¯„æœ¬

tools/features/                     # ç·¨è¼¯å·¥å…·éˆ
â”œâ”€â”€ templates/                      
â”‚   â”œâ”€â”€ Feature_Template_v1.3.xlsx  # ç•¶å‰ç‰ˆæœ¬ï¼ˆå« HVAC æ¬„ä½ï¼‰
â”‚   â””â”€â”€ Feature_Template_v1.2.xlsx  # èˆŠç‰ˆï¼ˆä¾›é·ç§»ï¼‰
â”œâ”€â”€ wizard.py                       # Wizard CLIï¼ˆè‡ªå‹•å‚™ä»½æ©Ÿåˆ¶ï¼‰
â”œâ”€â”€ excel_to_yaml.py                # è½‰æ›å™¨ï¼ˆå« HVAC é‚è¼¯é©—è­‰ï¼‰
â”œâ”€â”€ yaml_to_excel.py                # é€†å‘è½‰æ›ï¼ˆinit/recovery æ¨¡å¼ï¼‰
â”œâ”€â”€ migrate_excel.py                # ç¯„æœ¬å‡ç´šå·¥å…·ï¼ˆv1.1â†’v1.2â†’v1.3ï¼‰
â””â”€â”€ validators/
    â”œâ”€â”€ hvac_validator.py           # HVAC å°ˆç”¨é©—è­‰å™¨
    â”œâ”€â”€ sync_checker.py             # Excel/YAML åŒæ­¥æª¢æŸ¥ï¼ˆå« Checksum è¨ˆç®—ï¼‰
    â””â”€â”€ header_standardizer.py      # æ¨™é ­æ­£è¦åŒ–å¯¦ä½œï¼ˆå°é½Š Interface Contractï¼‰

src/features/                       # Python APIï¼ˆRuntimeï¼‰
â”œâ”€â”€ __init__.py                     # å®‰è£ YAML Write Guard èˆ‡ TemporalContext
â”œâ”€â”€ annotation_manager.py           # FeatureAnnotationManagerï¼ˆå”¯è®€ï¼‰
â”œâ”€â”€ yaml_write_guard.py             # Import Hook é˜²è­·ï¼ˆE501ï¼‰
â”œâ”€â”€ backup_manager.py               # å‚™ä»½ç­–ç•¥ç®¡ç†
â”œâ”€â”€ models.py                       # Pydantic æ¨¡å‹ï¼ˆColumnAnnotation, EquipmentConstraintï¼‰
â”œâ”€â”€ temporal_context.py             # å…¨åŸŸæ™‚é–“åŸºæº–å–®ä¾‹ï¼ˆæ–°å¢ï¼‰
â””â”€â”€ feature_manifest.py             # Feature Manifest ç”Ÿæˆèˆ‡é©—è­‰ï¼ˆæ–°å¢ï¼‰

src/etl/                            # ETL æ•´åˆå±¤
â”œâ”€â”€ config_models.py                # SSOT å¸¸æ•¸å®šç¾©ï¼ˆVALID_QUALITY_FLAGS, HEADER_STANDARDIZATION_RULESï¼‰
â””â”€â”€ header_standardizer.py          # CSV æ¨™é ­æ­£è¦åŒ–å¯¦ä½œï¼ˆParser ä½¿ç”¨ï¼‰
```

### 2.2 Git ç®¡ç†ç­–ç•¥ï¼ˆå¼·åˆ¶è¦ç¯„ï¼‰

**.gitignore ç¯„ä¾‹**ï¼ˆå¿…é ˆæ”¾ç½®æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰ï¼š
```gitignore
# ç‰¹å¾µæ¨™è¨»å·¥ä½œæª”æ¡ˆï¼ˆç¦æ­¢é€² Gitï¼‰
data/features/**/*.xlsx
data/features/**/*.xlsx.backup.*
data/features/**/.backups/
*.xlsx~*.tmp

# è‡¨æ™‚ YAMLï¼ˆç”Ÿæˆéç¨‹ï¼‰
*.yaml.tmp
__pycache__/
```

**åˆ†æ”¯ç­–ç•¥**:
- `main`: åƒ…åŒ…å«é€šé HVAC é©—è­‰çš„ YAMLï¼Œä»£è¡¨ç”Ÿç”¢ç’°å¢ƒé…ç½®
- `feature/hvac-{site_id}`: æ–°å¢æ¡ˆå ´æˆ–ä¿®æ”¹ HVAC é‚è¼¯æ™‚çš„å·¥ä½œåˆ†æ”¯
- **Pre-commit Hook æª¢æŸ¥**: ç¦æ­¢æäº¤ `.xlsx` äºŒé€²ä½æª”æ¡ˆï¼Œé©—è­‰ YAML Schema ç‰ˆæœ¬

---

## 3. Excel ç¯„æœ¬çµæ§‹ï¼ˆv1.3 å®Œæ•´ç‰ˆï¼‰

### 3.1 Sheet 1: Columnsï¼ˆä¸»è¦ç·¨è¼¯å€ï¼‰

**æ¬„ä½å®šç¾©ï¼ˆå¼·åŒ–ç‰ˆï¼‰**:

| æ¬„ä½åç¨± (A) | ç‰©ç†é¡å‹ (B) | å–®ä½ (C) | è¨­å‚™è§’è‰² (D) | æ˜¯å¦ç›®æ¨™ (E) | å•Ÿç”¨ Lag (F) | Lag é–“éš” (G) | å¿½ç•¥è­¦å‘Š (H) | è¨­å‚™ ID (I) | æè¿° (J) | ç‹€æ…‹ (K) |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| chiller_01_chwst | temperature | Â°C | primary | FALSE | TRUE | 1,4,96 | - | CH-01 | ä¸€è™Ÿæ©Ÿå†°æ°´å›æ°´æº«åº¦ | confirmed |
| chiller_02_chwst | temperature | Â°C | backup | FALSE | TRUE | 1,4 | W403 | CH-02 | äºŒè™Ÿæ©Ÿå†°æ°´å›æ°´æº«åº¦(å‚™ç”¨) | confirmed |
| chiller_01_kw | power | kW | primary | TRUE | FALSE | - | - | CH-01 | ä¸€è™Ÿæ©ŸåŠŸç‡ï¼ˆç›®æ¨™è®Šæ•¸ï¼‰ | confirmed |
| chw_pri_pump_01_hz | frequency | Hz | primary | FALSE | TRUE | 1,4 | - | CHWP-01 | å†°æ°´æ³µ 01 é »ç‡ | confirmed |

**æ¬„ä½è¦æ ¼è©³ç´°èªªæ˜**:

**A. æ¬„ä½åç¨± (Column Name)**
- **é©—è­‰è¦å‰‡**: 
  - å¿…å¡«ï¼Œå¿…é ˆèˆ‡ CSV æ¬„ä½åç¨±å®Œå…¨åŒ¹é…ï¼ˆç¶“ Parser Header Standardization å¾Œçš„ snake_caseï¼‰
  - å¿…é ˆç¬¦åˆ HVAC å‘½åè¦ç¯„ï¼ˆè¦‹ç¬¬4ç« ï¼‰
  - ç¦æ­¢é‡è¤‡ï¼ˆExcel æ¢ä»¶æ ¼å¼æ¨™è¨˜ç´…è‰²ï¼‰
- **å‘½åè¦ç¯„**: `{equipment_code}_{sequence:02d}_{component_code}`
  - ç¯„ä¾‹: `chiller_01_chwst`, `ahu_01_chwv`
- **Header Standardization é—œè¯**: è‹¥åŸå§‹ CSV æ¨™é ­ç‚º `Chiller 1 Temp`ï¼Œç¶“ Parser æ­£è¦åŒ–å¾Œç‚º `chiller_1_temp`ï¼ŒExcel ä¸­çš„ `column_name` å¿…é ˆè¨˜éŒ„æ­£è¦åŒ–å¾Œçš„å€¼

**B. ç‰©ç†é¡å‹ (Physical Type)**
- **è¼¸å…¥**: éœæ…‹ä¸‹æ‹‰é¸å–®ï¼ˆ18 å€‹é¸é …ï¼‰
- **é¸é …æ¸…å–®**: 
  - åŸºç¤é¡: `temperature`, `pressure`, `flow_rate`, `power`, `chiller_load`, `status`, `gauge`
  - HVAC æ“´å……: `cooling_capacity`, `efficiency`, `energy`, `valve_position`, `frequency`, `rotational_speed`, `current`, `voltage`, `power_factor`, `pressure_differential`, `operating_status`

**C. å–®ä½ (Unit)**
- **è¼¸å…¥**: éœæ…‹é•·é¸å–®ï¼ˆä¾ç‰©ç†é¡å‹åˆ†ç¾¤é¡¯ç¤ºï¼‰
- **HVAC å–®ä½å°ç…§**:
  | ç‰©ç†é¡å‹ | å¯é¸å–®ä½ |
  |---------|---------|
  | cooling_capacity | RT, kW |
  | efficiency | COP, kW/RT |
  | energy | kWh |
  | valve_position | % |
  | frequency | Hz |
  | rotational_speed | RPM |
  | current | A |
  | voltage | V |
  | power_factor | PF |
  | pressure_differential | kPa, Pa, bar |

**D. è¨­å‚™è§’è‰² (Device Role)**
- **é¸é …**: `primary`ï¼ˆä¸»è¨­å‚™ï¼‰ã€`backup`ï¼ˆå‚™ç”¨ï¼‰ã€`seasonal`ï¼ˆå­£ç¯€æ€§ï¼‰
- **é è¨­**: `primary`
- **å½±éŸ¿é‚è¼¯**:
  - `backup`: æŠ‘åˆ¶ W403ï¼ˆé«˜é›¶å€¼æ¯”ä¾‹ï¼‰è­¦å‘Šï¼Œå…è¨±é•·æœŸé›¢ç·š
  - `seasonal`: æŠ‘åˆ¶ W401ï¼ˆå‡å€¼ç•°å¸¸ï¼‰èˆ‡ W403 è­¦å‘Š
  - ä¾› Cleaner èª¿æ•´ç•°å¸¸åµæ¸¬é–¾å€¼ï¼ˆå‚™ç”¨è¨­å‚™é–¾å€¼æ”¾å¯¬ 50%ï¼‰

**E. æ˜¯å¦ç›®æ¨™ (Is Target)**
- **è¼¸å…¥**: å‹¾é¸æ¡† (TRUE/FALSE)
- **é˜²å‘†æ©Ÿåˆ¶**: ç•¶è¨­ç‚º TRUE æ™‚ï¼ŒF æ¬„ï¼ˆå•Ÿç”¨ Lagï¼‰è‡ªå‹•è¨­ç‚º FALSE ä¸¦é–å®šç·¨è¼¯ï¼ˆç°è‰²èƒŒæ™¯ä¿è­·ï¼‰
- **HVAC å»ºè­°**: åŠŸç‡ï¼ˆkWï¼‰ã€æ•ˆç‡ï¼ˆCOPï¼‰é€šå¸¸è¨­ç‚ºç›®æ¨™è®Šæ•¸

**F. å•Ÿç”¨ Lag (Enable Lag)**
- **é©—è­‰**: è‹¥ E æ¬„ç‚º TRUEï¼Œæ­¤æ¬„å¼·åˆ¶ç‚º FALSEï¼ˆPydantic å±¤é©—è­‰éŒ¯èª¤ E405ï¼‰

**G. Lag é–“éš” (Lag Intervals)**
- **æ ¼å¼**: é€—è™Ÿåˆ†éš”æ­£æ•´æ•¸ï¼ˆå¦‚ `1,4,96`ï¼‰
- **é©—è­‰**: 
  - Python å±¤æª¢æŸ¥å¿…é ˆç‚ºåš´æ ¼éå¢åºåˆ—
  - æª¢æŸ¥æ•¸å€¼å¿…é ˆç‚ºæ­£æ•´æ•¸ï¼ˆæ™‚é–“é»é–“éš”ï¼‰
  - HVAC å»ºè­°: æº«åº¦é¡ç”¨ `1,4,96`ï¼ˆ15åˆ†, 1å°æ™‚, 24å°æ™‚ï¼‰ï¼ŒåŠŸç‡é¡ç”¨ `1,4`ï¼ˆé«˜é »ï¼‰

**H. å¿½ç•¥è­¦å‘Š (Ignore Warnings)**
- **è¼¸å…¥**: å¤šé¸ä¸‹æ‹‰ï¼ˆ`W401`, `W402`, `W403`, `W406`, `W407`, `-`ï¼‰
- **ç”¨é€”**: å…è¨±é ˜åŸŸå°ˆå®¶é¡¯å¼æ¨™è¨˜ã€Œæ­¤æ¬„ä½å…è¨±ç‰¹å®šçµ±è¨ˆç•°å¸¸ã€

**I. è¨­å‚™ ID (Equipment ID)**ï¼ˆv1.3 æ–°å¢ï¼‰
- **ç”¨é€”**: å»ºç«‹æ¬„ä½èˆ‡å¯¦é«”è¨­å‚™çš„é—œè¯ï¼Œä¾› Equipment Constraints ä½¿ç”¨
- **æ ¼å¼**: å¤§å¯«è¨­å‚™ä»£ç¢¼ï¼ˆå¦‚ CH-01, CHWP-01, AHU-North-01ï¼‰
- **é©—è­‰**: åœ¨åŒä¸€æ¡ˆå ´ä¸­ï¼ŒEquipment ID èˆ‡ Column Name å¿…é ˆå”¯ä¸€å°æ‡‰

**J. æè¿° (Description)**
- **å»ºè­°å…§å®¹**: è¨­å‚™ä½ç½®ã€è£½é€ å•†ã€å‹è™Ÿã€å®‰è£æ—¥æœŸç­‰

**K. ç‹€æ…‹ (Status)**
- **é¸é …**: `pending_review`ï¼ˆå¾…ç¢ºèªï¼‰ã€`confirmed`ï¼ˆå·²ç¢ºèªï¼‰ã€`deprecated`ï¼ˆå·²æ£„ç”¨ï¼‰
- **Wizard ç”Ÿæˆ**: æ–°æ¬„ä½é è¨­ç‚º `pending_review`

### 3.2 Sheet 2: Group Policiesï¼ˆç¾¤çµ„ç­–ç•¥ï¼‰

ç°¡åŒ–èªæ³•ï¼Œç„¡éœ€ Regexï¼Œæ”¯æ´ HVAC è¨­å‚™é¡å‹è‡ªå‹•åŒ¹é…ï¼š

| ç­–ç•¥åç¨± | åŒ¹é…é¡å‹ | åŒ¹é…å€¼ | ç‰©ç†é¡å‹ | é è¨­æ¨£æ¿ | è‡ªå®šç¾© Lag | è¨­å‚™é¡åˆ¥ |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| chillers_temp | prefix | chiller_ | temperature | Standard_Chiller | - | å†°æ°´ä¸»æ©Ÿ |
| chillers_power | prefix | chiller_ | power | Power_High_Freq | - | å†°æ°´ä¸»æ©Ÿ |
| chillers_eff | prefix | chiller_ | efficiency | Efficiency_Smooth | - | å†°æ°´ä¸»æ©Ÿ |
| pumps_vfd | prefix | pump_ | frequency | VFD_Control | 1,4 | æ°´æ³µ |
| pumps_elec | prefix | pump_ | current | Electrical_Monitor | 1,4 | æ°´æ³µ |
| cooling_towers | prefix | ct_ | frequency | CT_Fan_Control | 1,4 | å†·å»æ°´å¡” |
| ahu_valves | prefix | ahu_ | valve_position | Valve_Position | 1,96 | ç©ºèª¿ç®± |
| ahu_filters | prefix | ahu_ | pressure_differential | Filter_DP | 1 | ç©ºèª¿ç®± |

### 3.3 Sheet 3: Metadataï¼ˆæ–‡ä»¶å…ƒè³‡æ–™ï¼‰

| å±¬æ€§ | å€¼ | èªªæ˜ | é©—è­‰è¦å‰‡ |
|:---|:---|:---|:---|
| schema_version | 1.3 | æ–‡ä»¶æ ¼å¼ç‰ˆæœ¬ | å¿…é ˆç‚º "1.3" |
| template_version | 1.3 | Excel ç¯„æœ¬ç‰ˆæœ¬ | System sheet äº¤å‰é©—è­‰ |
| site_id | cgmh_ty | æ¡ˆå ´è­˜åˆ¥ | å¿…é ˆåŒ¹é…æª”å |
| inherit | base | ç¹¼æ‰¿ä¾†æº | å¿…é ˆå­˜åœ¨æ–¼ config/features/ |
| description | é•·åºšé†«é™¢å†°æ°´ä¸»æ©Ÿæˆ¿... | æ–‡ä»¶æè¿° | è‡ªç”±æ–‡å­— |
| editor | ç‹å·¥ç¨‹å¸« | ç·¨è¼¯è€… | å¿…å¡« |
| last_updated | 2026-02-14T10:00:00 | æœ€å¾Œæ›´æ–° | ISO 8601 æ ¼å¼ |
| yaml_checksum | sha256:abc123... | å°æ‡‰ YAML é›œæ¹Š | åŒæ­¥æª¢æŸ¥ç”¨ï¼ˆè¦‹ç¬¬7ç« ï¼‰ |
| equipment_schema | hvac_v1.3 | è¨­å‚™åˆ†é¡æ¶æ§‹ç‰ˆæœ¬ | HVAC å°ˆç”¨æ¨™è¨˜ |
| temporal_baseline_version | 1.0 | æ™‚é–“åŸºæº–ç‰ˆæœ¬ | å¿…é ˆç‚º "1.0" |

**Hidden Sheet: System**ï¼ˆç³»çµ±å…§éƒ¨ä½¿ç”¨ï¼‰:
- `B1`: template_version ("1.3")
- `B2`: schema_hash (SHA256 of schema.json)
- `B3`: last_generated_by ("wizard_v1.3" or "manual")
- `B4`: yaml_last_sync_timestamp (ISO 8601)
- `B5`: equipment_countï¼ˆè‡ªå‹•è¨ˆç®—è¨­å‚™æ•¸é‡ï¼‰
- `B6`: excel_checksum_sha256ï¼ˆExcel æª”æ¡ˆå…§å®¹é›œæ¹Šï¼Œä¾› E406 é©—è­‰ï¼‰

---

## 4. è¨­å‚™åˆ†é¡èˆ‡å‘½åè¦ç¯„ï¼ˆHVAC Taxonomyï¼‰

### 4.1 è¨­å‚™é¡åˆ¥å°ç…§è¡¨ (Equipment Category Mapping)

ç‚ºçµ±ä¸€æ¬„ä½å‘½åèˆ‡ Group Policy è‡ªå‹•åŒ¹é…ï¼Œå»ºç«‹ä»¥ä¸‹**å¼·åˆ¶å‰ç¶´è¦ç¯„**ï¼š

| è¨­å‚™ä¸­æ–‡å | è‹±æ–‡ä»£ç¢¼ | æ¬„ä½å‰ç¶´è¦ç¯„ | Device Role å»ºè­° | Equipment ID ç¯„ä¾‹ |
|-----------|---------|-------------|-----------------|------------------|
| **å†°æ°´ä¸»æ©Ÿ** | CH (Chiller) | `chiller_{nn}_` æˆ– `ch_{n}_` | primary/backup | CH-01, CH-02 |
| **å†°æ°´ä¸€æ¬¡æ³µ** | CHW-P (Primary) | `chw_pri_pump_{nn}_` æˆ– `chwp{n}_` | primary | CHWP-01 |
| **å†°æ°´å€åŸŸæ³µ** | CHW-S (Secondary) | `chw_sec_pump_{nn}_` æˆ– `chws{n}_` | primary | CHWS-01 |
| **å†·å»æ°´ä¸€æ¬¡æ³µ** | CW-P (Pump) | `cw_pump_{nn}_` æˆ– `cwp{n}_` | primary | CWP-01 |
| **å†·å»æ°´å¡”** | CT (Cooling Tower) | `ct_{nn}_` æˆ– `cooling_tower_{nn}_` | primary/backup | CT-01, CT-02 |
| **ç©ºèª¿ç®±** | AHU | `ahu_{nn}_` æˆ– `ahu_{zone}_` | primary | AHU-North-01 |

### 4.2 å…ƒä»¶é¡å‹å°ç…§è¡¨ (Component Type Mapping)

| å…ƒä»¶ä¸­æ–‡å | è‹±æ–‡ä»£ç¢¼ | æ¸¬é»é¡å‹ | Physical Type å»ºè­° | å–®ä½ |
|-----------|---------|---------|-------------------|------|
| **å†°æ°´å‡ºæ°´æº«åº¦** | CHWST | æº«åº¦è¨ˆ | `temperature` | Â°C |
| **å†°æ°´å›æ°´æº«åº¦** | CHWRT | æº«åº¦è¨ˆ | `temperature` | Â°C |
| **å†·å»æ°´å‡ºæ°´æº«åº¦** | CWST | æº«åº¦è¨ˆ | `temperature` | Â°C |
| **å†·å»æ°´å›æ°´æº«åº¦** | CWRT | æº«åº¦è¨ˆ | `temperature` | Â°C |
| **å†°æ°´é–¥é–‹åº¦** | CHWV | é–¥é–€ | `valve_position` | % |
| **è®Šé »å™¨é »ç‡** | VFD | æ§åˆ¶å™¨ | `frequency` | Hz |
| **ç´¯ç©ç”¨é›»é‡** | kWh | é›»è¡¨ | `energy` | kWh |
| **éæ¿¾å™¨å£“å·®** | DP | å£“å·® | `pressure_differential` | kPa |

---

## 5. HVAC å°ˆç”¨è¨­å‚™é™åˆ¶æ¢ä»¶ï¼ˆEquipment Constraintsï¼‰

æ–¼ YAML æ–°å¢ `equipment_constraints` å€æ®µï¼Œå®šç¾©å†°æ°´ä¸»æ©Ÿæˆ¿å°ˆç”¨é‚è¼¯ï¼š

```yaml
equipment_constraints:
  # ==========================================
  # å†°æ°´ä¸»æ©Ÿç³»çµ±äº’é– (Chiller Interlocks)
  # ==========================================
  
  chiller_pump_interlock:
    description: "å†°æ°´ä¸»æ©Ÿé–‹å•Ÿæ™‚å¿…é ˆæœ‰å°æ‡‰å†°æ°´æ³µé‹è½‰"
    check_type: "requires"
    check_phase: "precheck"              # Cleaner éšæ®µåŸ·è¡Œ
    trigger_status: ["chiller_01_status", "chiller_02_status"]
    required_status: ["chw_pri_pump_01_status", "chw_pri_pump_02_status"]
    severity: "critical"
    applicable_roles: ["primary", "backup"]
    error_code: "E350"
    
  chiller_cw_pump_interlock:
    description: "å†°æ°´ä¸»æ©Ÿé–‹å•Ÿæ™‚å¿…é ˆæœ‰å°æ‡‰å†·å»æ°´æ³µé‹è½‰"
    check_type: "requires"
    check_phase: "precheck"
    trigger_status: ["chiller_01_status"]
    required_status: ["cw_pump_01_status", "cw_pump_02_status"]
    severity: "critical"
    applicable_roles: ["primary", "backup"]
    
  chiller_ct_interlock:
    description: "å†°æ°´ä¸»æ©Ÿé–‹å•Ÿæ™‚å¿…é ˆæœ‰å°æ‡‰å†·å»æ°´å¡”é‹è½‰"
    check_type: "requires"
    check_phase: "precheck"
    trigger_status: ["chiller_01_status"]
    required_status: ["ct_01_status", "ct_02_status"]
    severity: "critical"
    
  chiller_temperature_protection:
    description: "å†°æ°´å‡ºæ°´æº«åº¦éä½ä¿è­·ï¼ˆé˜²å‡ï¼‰"
    check_type: "range_check"
    check_phase: "precheck"
    target_column: "chiller_01_chwst"
    min_value: 4.0                    # Â°Cï¼Œä½æ–¼ 4 åº¦è¦–ç‚ºç•°å¸¸
    max_value: 15.0
    severity: "critical"
    applicable_roles: ["primary", "backup"]
    
  # ==========================================
  # é‹è½‰æ™‚é–“é™åˆ¶ (Runtime Constraints) - Optimization éšæ®µ
  # ==========================================
  
  chiller_min_runtime:
    description: "ä¸»æ©Ÿé–‹å•Ÿå¾Œæœ€å°‘é‹è½‰ 15 åˆ†é˜ï¼ˆé˜²æ­¢é »ç¹å•Ÿåœï¼‰"
    check_type: "sequence"
    check_phase: "optimization"
    applies_to: ["chiller_01_status", "chiller_02_status"]
    min_duration_minutes: 15
    severity: "warning"
    error_code: "E355"                 # é€šç”¨ Sequence é•å
    
  chiller_min_downtime:
    description: "ä¸»æ©Ÿé—œé–‰å¾Œæœ€å°‘åœæ©Ÿ 10 åˆ†é˜ï¼ˆå£“ç¸®æ©Ÿä¿è­·ï¼‰"
    check_type: "sequence"
    check_phase: "optimization"
    applies_to: ["chiller_01_status", "chiller_02_status"]
    min_duration_minutes: 10
    severity: "warning"
    error_code: "E355"
    
  # ==========================================
  # å®¹é‡èˆ‡è² è¼‰é™åˆ¶ (Capacity Constraints)
  # ==========================================
  
  chiller_load_min_limit:
    description: "ä¸»æ©Ÿä½è¼‰ä¿è­·ï¼ˆä½æ–¼ 20% å»ºè­°åœæ©Ÿï¼‰"
    check_type: "threshold"
    check_phase: "optimization"
    target_column: "chiller_01_rt"
    reference_column: "chiller_01_rated_rt"  # é¡å®šå®¹é‡
    min_ratio: 0.2                           # 20%
    severity: "warning"
    suggestion: "å»ºè­°é—œé–‰æ­¤ä¸»æ©Ÿï¼Œæ”¹ç”±å…¶ä»–ä¸»æ©Ÿæ‰¿è¼‰"
    
  # ==========================================
  # ç©ºèª¿ç®±äº’é– (AHU Interlocks)
  # ==========================================
  
  ahu_valve_flow_interlock:
    description: "ç©ºèª¿ç®±é¢¨æ©Ÿé‹è½‰æ™‚æ‰å…è¨±é–‹å•Ÿå†°æ°´é–¥"
    check_type: "requires"
    check_phase: "precheck"
    trigger_status: ["ahu_01_chwv"]
    trigger_threshold: 5                    # é–¥ä½ > 5%
    required_status: ["ahu_01_status"]      # é¢¨æ©Ÿå¿…é ˆé‹è½‰
    severity: "warning"
    
  ahu_filter_dp_alarm:
    description: "éæ¿¾å™¨å£“å·®éé«˜è­¦å‘Šï¼ˆéœ€æ›´æ›ï¼‰"
    check_type: "threshold"
    check_phase: "precheck"
    target_column: "ahu_01_dp"
    max_value: 0.5                          # 0.5 kPa æˆ–ä¾è¨­è¨ˆ
    severity: "warning"
    maintenance_trigger: true               # è§¸ç™¼ç¶­è­·å·¥å–®æ¨™è¨˜
    
  # ==========================================
  # äº’æ–¥ç´„æŸ (Mutex Constraints) - é€šç”¨
  # ==========================================
  
  chiller_mutual_backup:
    description: "ä¸»æ©Ÿèˆ‡å‚™ç”¨ä¸»æ©Ÿä¸å¯åŒæ™‚é–‹å•Ÿï¼ˆè¦–æ¡ˆå ´ç­–ç•¥ï¼‰"
    check_type: "mutex"
    check_phase: "optimization"
    mutex_pairs: [["chiller_01_status", "chiller_02_status"]]
    condition: "device_role == 'backup'"    # åƒ…ç•¶è§’è‰²ç‚º backup æ™‚æª¢æŸ¥
    severity: "warning"
    error_code: "E354"                      # é€šç”¨ Mutex é•å
```

---

## 6. éŒ¯èª¤èˆ‡è­¦å‘Šä»£ç¢¼å°ç…§è¡¨ï¼ˆå®Œæ•´å°é½Š Interface Contract v1.1ï¼‰

### 6.1 Feature Annotation éŒ¯èª¤ (E400-E499)

| ä»£ç¢¼ | åç¨± | å±¤ç´š | è§¸ç™¼æ¢ä»¶ | è™•ç†æ–¹å¼ |
|:---:|:---|:---:|:---|:---|
| **E400** | `ANNOTATION_VERSION_MISMATCH` | Error | Schema ç‰ˆæœ¬ä¸ç¬¦ï¼ˆé 1.3ï¼‰ | åŸ·è¡Œ migrate_excel.py å‡ç´š |
| **E401** | `ORPHAN_COLUMN` | Warning | æ¨™è¨»æ¬„ä½ä¸å­˜åœ¨æ–¼è³‡æ–™ï¼ˆExcel æœ‰ä½† CSV æ²’æœ‰ï¼‰ | è¨˜éŒ„æ—¥èªŒï¼Œç¹¼çºŒåŸ·è¡Œ |
| **E402** | `UNANNOTATED_COLUMN` | Error | è³‡æ–™æ¬„ä½æœªå®šç¾©æ–¼ Annotationï¼ˆCSV æœ‰ä½† Excel æ²’æœ‰ï¼‰ | é˜»æ“‹æµç¨‹ï¼ŒåŸ·è¡Œ Wizard æ¨™è¨» |
| **E403** | `UNIT_INCOMPATIBLE` | Error | å–®ä½èˆ‡ç‰©ç†é¡å‹ä¸åŒ¹é…ï¼ˆå¦‚æº«åº¦é¸ barï¼‰ | é˜»æ“‹ç”Ÿæˆï¼Œè¿”å› Excel ä¿®æ­£ |
| **E404** | `LAG_FORMAT_INVALID` | Error | Lag é–“éš”æ ¼å¼éŒ¯èª¤ï¼ˆéé€—è™Ÿåˆ†éš”æ•´æ•¸ï¼‰ | é˜»æ“‹ç”Ÿæˆ |
| **E405** | `TARGET_LEAKAGE_RISK` | Error | is_target=True ä½† enable_lag=True | é˜»æ“‹ç”Ÿæˆï¼ˆPydantic è‡ªå‹•æ””æˆªï¼‰ |
| **E406** | `EXCEL_YAML_OUT_OF_SYNC` | Error | Excel ä¿®æ”¹æ™‚é–“æ™šæ–¼ YAMLï¼Œæˆ– checksum ä¸ç¬¦ | æç¤ºé‡æ–°åŸ·è¡Œ excel_to_yaml.py |
| **E407** | `CIRCULAR_INHERITANCE` | Error | YAML ç¹¼æ‰¿éˆå­˜åœ¨å¾ªç’°åƒç…§ | é˜»æ“‹è¼‰å…¥ï¼Œæª¢æŸ¥ inherit æ¬„ä½ |
| **E408** | `SSOT_QUALITY_FLAGS_MISMATCH` | Error | YAML ä¸­çš„ `ssot_flags_version` èˆ‡ `config_models.VALID_QUALITY_FLAGS` ç‰ˆæœ¬ä¸ä¸€è‡´ | é˜»æ“‹ Container å•Ÿå‹•ï¼Œè¦æ±‚åŒæ­¥ config_models.py |
| **E409** | `HEADER_ANNOTATION_MISMATCH` | Error | CSV æ¨™é ­ï¼ˆç¶“ Parser æ­£è¦åŒ–å¾Œï¼‰èˆ‡ Annotation ä¸­çš„ `column_name` ç„¡æ³•åŒ¹é… | æç¤ºæª¢æŸ¥ Excel æ¨™è¨»æˆ–åŸ·è¡Œ Wizard |

### 6.2 Equipment Validation éŒ¯èª¤ (E350-E399) - å°é½Šé€šç”¨å±¤ç´š

| ä»£ç¢¼ | åç¨± | å±¤ç´š | è§¸ç™¼æ¢ä»¶ | è™•ç†æ–¹å¼ |
|:---:|:---|:---:|:---|:---|
| **E350** | `EQUIPMENT_LOGIC_PRECHECK_FAILED` | Error | Cleaner éšæ®µåŸºç¤è¨­å‚™é‚è¼¯é æª¢å¤±æ•—ï¼ˆå¦‚ä¸»æ©Ÿé–‹ä½†æ°´æ³µé—œï¼‰ | æ¨™è¨˜ Quality Flag ç‚º PHYSICAL_IMPOSSIBLEï¼Œè¨˜éŒ„ç¨½æ ¸è»Œè·¡ |
| **E351** | `ENERGY_MONOTONICITY_VIOLATION` | Error | kWh é›»è¡¨è®€æ•¸éæ¸›ï¼ˆå–®èª¿æ€§é•åï¼‰ | æª¢æŸ¥é›»è¡¨é‡ç½®æˆ–æ•…éšœï¼Œåˆ†æ®µè™•ç† |
| **E352** | `EFFICIENCY_OUT_OF_RANGE` | Warning | COP < 2 æˆ– > 8ï¼ˆç‰©ç†ç•°å¸¸ï¼‰ | æ¨™è¨˜ç•°å¸¸ï¼Œå»ºè­°æª¢æŸ¥æº«åº¦/æµé‡æ„Ÿæ¸¬å™¨ |
| **E353** | `LOW_DELTA_T_SYNDROME` | Warning | å†°æ°´é€²å›æ°´æº«å·® < 1Â°Cï¼ˆä½æº«å·®ç—‡å€™ç¾¤ï¼‰ | å»ºè­°æ¸…æ´—ç†±äº¤æ›å™¨æˆ–æª¢æŸ¥æµé‡ |
| **E354** | `MUTEX_VIOLATION` | Error | é•åã€Œäº’æ–¥ã€ç´„æŸï¼ˆå¦‚ä¸»æ©Ÿèˆ‡å‚™ç”¨ä¸»æ©ŸåŒæ™‚é–‹ï¼‰ | æ¨™è¨˜ EQUIPMENT_VIOLATION |
| **E355** | `SEQUENCE_VIOLATION` | Error | é•åé–‹é—œæ©Ÿé †åºç´„æŸï¼ˆå¦‚æœªé”æœ€å°é‹è½‰æ™‚é–“ï¼‰ | æ¨™è¨˜ EQUIPMENT_VIOLATION |
| **E356** | `MIN_RUNTIME_VIOLATION` | Warning | é•åæœ€å°é‹è½‰æ™‚é–“é™åˆ¶ï¼ˆåŒ E355ï¼Œä¾›çµ±è¨ˆç”¨ï¼‰ | æ¨™è¨˜è­¦å‘Š |
| **E357** | `MIN_DOWNTIME_VIOLATION` | Warning | é•åæœ€å°åœæ©Ÿæ™‚é–“é™åˆ¶ï¼ˆåŒ E355ï¼Œä¾›çµ±è¨ˆç”¨ï¼‰ | æ¨™è¨˜è­¦å‘Š |

### 6.3 Governance & å®‰å…¨æ€§éŒ¯èª¤ (E500-E599)

| ä»£ç¢¼ | åç¨± | å±¤ç´š | è§¸ç™¼æ¢ä»¶ | è™•ç†æ–¹å¼ |
|:---:|:---|:---:|:---|:---|
| **E500** | `DEVICE_ROLE_LEAKAGE` | Error | DataFrame æˆ– Metadata åŒ…å« `device_role` æ¬„ä½ï¼ˆè·è²¬åˆ†é›¢é•åï¼‰ | ç«‹å³çµ‚æ­¢æµç¨‹ï¼Œç¦æ­¢ä¸‹æ¸¸ä½¿ç”¨ |
| **E501** | `DIRECT_WRITE_ATTEMPT` | Error | Python ç¨‹å¼ç¢¼è©¦åœ–ç›´æ¥å¯«å…¥ YAML SSOT è·¯å¾‘ | ç«‹å³çµ‚æ­¢æµç¨‹ï¼Œè¨˜éŒ„å®‰å…¨æ€§é•è¦ |

### 6.4 å…¨åŸŸæ™‚é–“åŸºæº–éŒ¯èª¤ (E000)

| ä»£ç¢¼ | åç¨± | å±¤ç´š | è§¸ç™¼æ¢ä»¶ | è™•ç†æ–¹å¼ |
|:---:|:---|:---:|:---|:---|
| **E000** | `TEMPORAL_BASELINE_MISSING` | Error | `pipeline_origin_timestamp` æœªå‚³éæˆ–éºå¤± | ç«‹å³çµ‚æ­¢ï¼Œè¨˜éŒ„ã€Œæ™‚é–“åŸºæº–æœªå»ºç«‹ã€ |
| **E000-W** | `TEMPORAL_DRIFT_WARNING` | Warning | Pipeline åŸ·è¡Œæ™‚é–“è¶…é 1 å°æ™‚ï¼Œæ‡·ç–‘æ™‚é–“æ¼‚ç§» | è¨˜éŒ„è­¦å‘Šï¼Œæª¢æŸ¥æ™‚é–“åŸºæº–ä¸€è‡´æ€§ |

### 6.5 è­¦å‘Šä»£ç¢¼ (W401-W407)

| ä»£ç¢¼ | åç¨± | å±¤ç´š | è§¸ç™¼æ¢ä»¶ | è™•ç†æ–¹å¼ |
|:---:|:---|:---:|:---|:---|
| **W401** | `MEAN_OUT_OF_RANGE` | Warning | å¹³å‡å€¼è¶…å‡ºé æœŸç¯„åœï¼ˆdistribution_checkï¼‰ | æ¨™è¨˜ pending_reviewï¼Œå¯é€é ignore_warnings å¿½ç•¥ |
| **W402** | `LOW_VARIANCE` | Warning | æ¨™æº–å·®æ¥è¿‘é›¶ï¼ˆå¯èƒ½ç‚ºå‡çµè³‡æ–™ï¼‰ | æª¢æŸ¥æ„Ÿæ¸¬å™¨ç‹€æ…‹ |
| **W403** | `HIGH_ZERO_RATIO` | Warning | é›¶å€¼æ¯”ä¾‹éé«˜ï¼ˆä¸»è¨­å‚™ > 10%ï¼‰ | å‚™ç”¨è¨­å‚™ï¼ˆbackup roleï¼‰è‡ªå‹•æŠ‘åˆ¶æ­¤è­¦å‘Š |
| **W404** | `BACKUP_CLEANUP_FAILED` | Warning | æ¸…ç†èˆŠå‚™ä»½æ™‚æ¬Šé™ä¸è¶³ | é€šçŸ¥ç³»çµ±ç®¡ç†å“¡ï¼Œä¸é˜»æ“‹æµç¨‹ |
| **W405** | `EQUIPMENT_CONSTRAINT_DEPRECATED` | Warning | ä½¿ç”¨äº†æ¨™è¨˜ç‚º deprecated çš„è¨­å‚™é™åˆ¶æ¢ä»¶ | å»ºè­°æ›´æ–°è‡³æ–°ç‰ˆé™åˆ¶æ¢ä»¶å®šç¾© |
| **W406** | `FREQUENCY_ZERO_WHILE_RUNNING` | Warning | é‹è½‰ç‹€æ…‹=1 ä½†é »ç‡=0ï¼ˆè®Šé »å™¨ç•°å¸¸ï¼‰ | æª¢æŸ¥ VFD å›æˆä¿¡è™Ÿ |
| **W407** | `POWER_FACTOR_LOW` | Warning | PF < 0.8 æŒçºŒè¶…é 1 å°æ™‚ | å»ºè­°æª¢æŸ¥é›»å®¹å™¨æˆ–é¦¬é”ç‹€æ…‹ |

---

## 7. Wizard äº¤äº’å¼ CLIï¼ˆå–®å‘æµç¨‹å¼·åŒ–èˆ‡åŒæ­¥æª¢æŸ¥ï¼‰

### 7.1 æ¶æ§‹ä¿®æ­£ï¼ˆè§£æ±ºç«¶æ…‹æ¢ä»¶ï¼‰

**v1.3 å¼·åˆ¶è¦ç¯„**: Wizard **åƒ…**æ›´æ–° Excelï¼ŒYAML ç”±ä½¿ç”¨è€…æ‰‹å‹•è§¸ç™¼ç”Ÿæˆ

```python
def wizard_update_excel(
    site_id: str,
    csv_path: Path,
    excel_path: Path,
    template_version: str = "1.3"
):
    """
    Wizardï¼šåµæ¸¬æ–°æ¬„ä½ä¸¦è¿½åŠ è‡³ Excelï¼ˆä¸ç›´æ¥å¯« YAMLï¼‰
    åŒ…å«è‡ªå‹•å‚™ä»½æ©Ÿåˆ¶ï¼ˆUndo é˜²è­·ï¼‰èˆ‡ Header Standardization é è¦½
    """
    # 0. è‡ªå‹•å‚™ä»½æ©Ÿåˆ¶ï¼ˆç½é›£æ¢å¾©é˜²è­·ï¼‰
    if excel_path.exists():
        backup_dir = excel_path.parent / ".backups"
        backup_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"{excel_path.stem}.backup.{timestamp}{excel_path.suffix}"
        backup_path = backup_dir / backup_filename
        
        import shutil
        shutil.copy2(excel_path, backup_path)
        
        # æ¸…ç†èˆŠå‚™ä»½ï¼ˆä¿ç•™æœ€è¿‘ 10 å€‹ç‰ˆæœ¬ï¼‰
        backup_pattern = f"{excel_path.stem}.backup.*"
        all_backups = sorted(
            backup_dir.glob(backup_pattern), 
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )
        
        for old_backup in all_backups[10:]:
            try:
                old_backup.unlink()
            except Exception as e:
                print(f"âš ï¸  ç„¡æ³•æ¸…ç†èˆŠå‚™ä»½ {old_backup.name}: {e}")
        
        print(f"ğŸ’¾ å·²è‡ªå‹•å‚™ä»½: {backup_path.name}ï¼ˆä¿ç•™æœ€è¿‘ 10 å€‹ç‰ˆæœ¬ï¼‰")
    
    # 1. æª¢æŸ¥ Excel ç‰ˆæœ¬ç›¸å®¹æ€§
    if excel_path.exists():
        wb = load_workbook(excel_path)
        current_ver = wb['System']['B1'].value
        if current_ver != template_version:
            raise CompatibilityError(
                f"E400: Excel ç¯„æœ¬éèˆŠ (v{current_ver})ï¼Œè«‹å…ˆåŸ·è¡Œï¼š\n"
                f"python migrate_excel.py --from {current_ver} --to {template_version}"
            )
    else:
        wb = load_workbook(f"tools/features/templates/Feature_Template_v{template_version}.xlsx")
        print(f"ğŸ†• åˆå§‹åŒ–æ–° Excel æª”æ¡ˆ: {excel_path}")
    
    # 2. è®€å– CSV æ¬„ä½ä¸¦åŸ·è¡Œ Header Standardization
    from src.etl.header_standardizer import HeaderStandardizer
    
    df_csv = pl.read_csv(csv_path, n_rows=1000)
    original_headers = df_csv.columns
    standardizer = HeaderStandardizer()
    
    standardized_map = {}
    for header in original_headers:
        if header == 'timestamp':
            standardized_map[header] = header
        else:
            standardized = standardizer.standardize(header)
            standardized_map[header] = standardized
    
    # é¡¯ç¤ºæ¨™é ­è½‰æ›é è¦½
    print("\nğŸ“‹ Header Standardization é è¦½:")
    for orig, std in standardized_map.items():
        if orig != std:
            print(f"   {orig} â†’ {std}")
    
    existing_cols = get_existing_columns(wb)
    new_cols = set(standardized_map.values()) - existing_cols - {'timestamp'}
    
    if not new_cols:
        print("âœ… ç„¡æ–°æ¬„ä½éœ€è¦æ¨™è¨»")
        return
    
    print(f"ğŸ” ç™¼ç¾ {len(new_cols)} å€‹æ–°æ¬„ä½å¾…æ¨™è¨»")

    # === æ­¥é©Ÿ 3: HVAC èªæ„æ¨æ¸¬ ===
    for col in sorted(new_cols):
        # æ‰¾å›åŸå§‹æ¬„ä½åç¨±ï¼ˆç”¨æ–¼çµ±è¨ˆè¨ˆç®—ï¼‰
        original_col = [k for k, v in standardized_map.items() if v == col][0]
        stats = calculate_stats(df_csv[original_col])
        suggestion = hvac_semantic_guess(col, stats)  # HVAC å°ˆç”¨æ¨æ¸¬é‚è¼¯

        print(f"\n{'='*60}")
        print(f"ğŸ” æ–°æ¬„ä½: {col} (åŸå§‹: {original_col})")
        print(f"   çµ±è¨ˆæ‘˜è¦: å‡å€¼={stats['mean']:.2f}, é›¶å€¼æ¯”ä¾‹={stats['zero_ratio']:.1%}")
        print(f"   HVAC æ¨æ¸¬: {suggestion['equipment_type']} / {suggestion['physical_type']}")
        print(f"   å»ºè­°è¨­å‚™ ID: {suggestion['equipment_id']}")

        # äº¤äº’å¼ç¢ºèªï¼ˆå«é˜²å‘†ï¼‰
        choice = input("[Y]ç¢ºèª [N]ä¿®æ”¹ [S]è·³é [D]æŸ¥çœ‹åˆ†ä½ˆ [Q]é€€å‡º > ").strip().upper()

        if choice == 'Q':
            print("ğŸ›‘ ä½¿ç”¨è€…ä¸­æ–·ï¼Œå·²è™•ç†çš„æ¬„ä½å·²å„²å­˜")
            break
        elif choice == 'S':
            continue
        elif choice == 'D':
            plot_distribution(df_csv[original_col])
            continue

        # å¯«å…¥ Excelï¼ˆå« HVAC é è¨­å€¼ï¼‰
        row_data = {
            'column_name': col,  # è¨˜éŒ„æ­£è¦åŒ–å¾Œçš„åç¨±
            'physical_type': suggestion['physical_type'],
            'unit': suggestion['unit'],
            'device_role': suggestion.get('device_role', 'primary'),
            'equipment_id': suggestion['equipment_id'],
            'is_target': suggestion.get('is_target', False),
            'enable_lag': not suggestion.get('is_target', False),
            'lag_intervals': suggestion.get('lag_intervals', '1,4'),
            'ignore_warnings': '',
            'description': suggestion['description'],
            'status': 'pending_review'
        }

        write_to_excel_row(wb['Columns'], row_data)
        print(f"âœ… å·²å¯«å…¥ Excelï¼ˆç‹€æ…‹: pending_reviewï¼‰")

    # === æ­¥é©Ÿ 4: æ›´æ–° Metadata ===
    update_metadata(wb, source_csv=csv_path.name)

    # === æ­¥é©Ÿ 5: åŸå­å¯«å…¥ ===
    temp_excel = excel_path.with_suffix('.tmp.xlsx')
    wb.save(temp_excel)
    temp_excel.replace(excel_path)

    # === æ­¥é©Ÿ 6: è¨ˆç®—ä¸¦è¨˜éŒ„ Excel Checksum ===
    excel_checksum = compute_file_hash(excel_path, algorithm='sha256')
    wb = load_workbook(excel_path)  # é‡æ–°è¼‰å…¥ä»¥æ›´æ–° System sheet
    wb['System']['B6'] = excel_checksum
    wb.save(excel_path)

    print(f"\n{'='*60}")
    print(f"âœ… å·²æ›´æ–° Excel: {excel_path}")
    print(f"ğŸ“Š Excel Checksum: {excel_checksum[:16]}...")
    print(f"âš ï¸  è«‹é–‹å•Ÿ Excel ç¢ºèªè¨­å‚™è§’è‰²èˆ‡ Equipment IDï¼Œç„¶å¾ŒåŸ·è¡Œï¼š")
    print(f"   python tools/features/excel_to_yaml.py --input {excel_path}")
```

### 7.2 åŒæ­¥ç‹€æ…‹æª¢æŸ¥ï¼ˆé˜²æ­¢éºå¿˜ç”Ÿæˆ YAMLï¼‰

```python
def check_sync_status(excel_path: Path, yaml_path: Path) -> dict:
    """
    æª¢æŸ¥ Excel èˆ‡ YAML æ˜¯å¦åŒæ­¥ï¼ˆE406 å¯¦ä½œç´°ç¯€ï¼‰
    å›å‚³è©³ç´°å·®ç•°å ±å‘Šèˆ‡å»ºè­°æ“ä½œ
    """
    wb = load_workbook(excel_path)
    excel_mtime = datetime.fromtimestamp(excel_path.stat().st_mtime)
    
    # è®€å– Excel ä¸­è¨˜éŒ„çš„ checksum
    stored_excel_checksum = wb['System']['B6'].value

    if not yaml_path.exists():
        return {
            "synced": False,
            "error_code": "E406",
            "reason": "YAML ä¸å­˜åœ¨",
            "action": f"python tools/features/excel_to_yaml.py --input {excel_path} --output {yaml_path}",
            "severity": "High"
        }

    yaml_mtime = datetime.fromtimestamp(yaml_path.stat().st_mtime)

    # æª¢æŸ¥æ™‚é–“æˆ³ï¼ˆExcel å¿…é ˆæ—©æ–¼æˆ–ç­‰æ–¼ YAMLï¼‰
    if excel_mtime > yaml_mtime:
        time_diff = (excel_mtime - yaml_mtime).total_seconds() / 60
        return {
            "synced": False,
            "error_code": "E406",
            "reason": f"Excel è¼ƒæ–°ï¼ˆå·®è· {time_diff:.1f} åˆ†é˜ï¼‰",
            "excel_time": excel_mtime.isoformat(),
            "yaml_time": yaml_mtime.isoformat(),
            "action": "è«‹é‡æ–°åŸ·è¡Œ excel_to_yaml.py",
            "severity": "High"
        }

    # Checksum é©—è­‰ï¼ˆé˜²æ­¢æ‰‹å‹•ä¿®æ”¹ YAML æˆ– Excel è¢«å¤–éƒ¨ä¿®æ”¹ï¼‰
    if stored_excel_checksum and stored_excel_checksum != 'pending_sync':
        current_excel_checksum = compute_file_hash(excel_path, algorithm='sha256')
        if stored_excel_checksum != current_excel_checksum:
            return {
                "synced": False,
                "error_code": "E406",
                "reason": "Excel æª”æ¡ˆå…§å®¹èˆ‡è¨˜éŒ„çš„ Checksum ä¸ç¬¦ï¼ˆå¯èƒ½è¢«å¤–éƒ¨ä¿®æ”¹ï¼‰",
                "warning": "å»ºè­°é‡æ–°åŸ·è¡Œ Wizard ç¢ºèªæ¬„ä½ä¸€è‡´æ€§",
                "severity": "Medium"
            }
        
        # é©—è­‰ YAML å…§å®¹æ˜¯å¦å°æ‡‰æ­¤ Excel ç‰ˆæœ¬
        with open(yaml_path, 'r', encoding='utf-8') as f:
            yaml_content = yaml.safe_load(f)
        
        if yaml_content.get('metadata', {}).get('excel_checksum') != stored_excel_checksum:
            return {
                "synced": False,
                "error_code": "E406",
                "reason": "YAML å°æ‡‰çš„ Excel Checksum èˆ‡ç•¶å‰ Excel ä¸ç¬¦",
                "warning": "YAML å¯èƒ½æ˜¯ç”±èˆŠç‰ˆ Excel ç”Ÿæˆï¼Œå»ºè­°é‡æ–°ç”Ÿæˆ",
                "severity": "High"
            }

    return {
        "synced": True, 
        "last_sync": yaml_mtime.isoformat(),
        "excel_checksum": stored_excel_checksum
    }
```

---

## 8. FeatureAnnotationManager APIï¼ˆå®Œæ•´è¦ç¯„ï¼‰

### 8.1 é¡åˆ¥å®šç¾©èˆ‡åˆå§‹åŒ–

```python
# src/features/annotation_manager.py
from typing import Dict, List, Optional, Any, Set, Tuple
from pathlib import Path
import yaml
from pydantic import BaseModel, validator, root_validator

class ColumnAnnotation(BaseModel):
    """æ¬„ä½æ¨™è¨»è³‡æ–™æ¨¡å‹ï¼ˆå°é½Š YAML Schema v1.3ï¼‰"""
    column_name: str
    physical_type: str
    unit: Optional[str]
    device_role: str = "primary"
    equipment_id: Optional[str] = None      # v1.3 æ–°å¢
    description: Optional[str]
    is_target: bool = False
    enable_lag: bool = True
    lag_intervals: List[int] = []
    rolling_windows: List[int] = []
    ignore_warnings: List[str] = []
    status: str = "pending_review"
    tags: List[str] = []

    @validator('device_role')
    def validate_role(cls, v):
        if v not in ['primary', 'backup', 'seasonal']:
            raise ValueError(f"Invalid device_role: {v}")
        return v

    @root_validator
    def check_target_lag(cls, values):
        """E405: ç›®æ¨™è®Šæ•¸ç¦æ­¢ Lag"""
        if values.get('is_target') and values.get('enable_lag'):
            raise ValueError("E405: ç›®æ¨™è®Šæ•¸ä¸å¯å•Ÿç”¨ Lag")
        return values

class EquipmentConstraint(BaseModel):
    """è¨­å‚™é™åˆ¶æ¢ä»¶æ¨¡å‹ï¼ˆå°é½Š Interface Contract v1.1ï¼‰"""
    constraint_id: str
    description: str
    check_type: str                      # requires, mutex, sequence, range_check, threshold
    check_phase: str                     # precheck, optimization
    trigger_status: Optional[List[str]]
    required_status: Optional[List[str]]
    target_column: Optional[str]
    min_value: Optional[float]
    max_value: Optional[float]
    min_duration_minutes: Optional[int]
    severity: str                        # critical, warning
    applicable_roles: List[str] = ["primary", "backup"]
    error_code: Optional[str]

class FeatureAnnotationManager:
    """
    ç‰¹å¾µæ¨™è¨»ç®¡ç†å™¨ï¼ˆFeatureAnnotationManagerï¼‰

    è¨­è¨ˆåŸå‰‡ï¼š
    1. å”¯è®€ä»‹é¢ï¼šæä¾›æŸ¥è©¢æ–¹æ³•ï¼Œç¦æ­¢ä¿®æ”¹ YAML
    2. SSOT å­˜å–ï¼šæ‰€æœ‰è³‡æ–™ä¾†è‡ª config/features/sites/{site_id}.yaml
    3. å¿«å–æ©Ÿåˆ¶ï¼šYAML è¼‰å…¥å¾Œå¿«å–æ–¼è¨˜æ†¶é«”ï¼Œé¿å…é‡è¤‡ I/O
    4. HVAC æ„ŸçŸ¥ï¼šæ”¯æ´è¨­å‚™äº’é–æŸ¥è©¢èˆ‡é©—è­‰
    5. æ™‚é–“åŸºæº–æ„ŸçŸ¥ï¼šæ”¯æ´ TemporalContext å‚³é

    ä½¿ç”¨ç¯„ä¾‹ï¼š
        from src.features.temporal_context import TemporalContext
        
        context = TemporalContext()
        manager = FeatureAnnotationManager("cgmh_ty", temporal_context=context)
        
        # åŸºç¤æŸ¥è©¢
        annotation = manager.get_column_annotation("chiller_01_chwst")
        
        # HVAC å°ˆç”¨æŸ¥è©¢
        chillers = manager.get_columns_by_equipment_type("chiller")
        constraints = manager.get_equipment_constraints(phase="precheck")
    """

    def __init__(
        self, 
        site_id: str, 
        config_root: Path = Path("config/features"),
        temporal_context: Optional['TemporalContext'] = None
    ):
        self.site_id = site_id
        self.config_path = config_root / "sites" / f"{site_id}.yaml"
        self.temporal_context = temporal_context
        self._cache: Optional[Dict[str, Any]] = None
        self._annotations: Dict[str, ColumnAnnotation] = {}
        self._constraints: Dict[str, EquipmentConstraint] = {}
        self._equipment_map: Dict[str, List[str]] = {}  # equipment_id -> columns

        self._load_and_validate()

    def _load_and_validate(self):
        """è¼‰å…¥ YAML ä¸¦é©—è­‰ Schema ç‰ˆæœ¬èˆ‡ SSOT ä¸€è‡´æ€§"""
        if not self.config_path.exists():
            raise FileNotFoundError(
                f"E402: æ‰¾ä¸åˆ°æ¡ˆå ´æ¨™è¨»æª”æ¡ˆ: {self.config_path}"
            )

        with open(self.config_path, 'r', encoding='utf-8') as f:
            raw_data = yaml.safe_load(f)

        # é©—è­‰ Schema ç‰ˆæœ¬
        schema_version = raw_data.get('schema_version', 'unknown')
        if schema_version != "1.3":
            raise CompatibilityError(
                f"E400: ä¸æ”¯æ´çš„ Schema ç‰ˆæœ¬: {schema_version}ï¼Œé æœŸ: 1.3"
            )

        # é©—è­‰ SSOT Quality Flags ç‰ˆæœ¬ï¼ˆE408ï¼‰
        ssot_flags_version = raw_data.get('metadata', {}).get('ssot_flags_version')
        from src.etl.config_models import VALID_QUALITY_FLAGS_VERSION
        if ssot_flags_version != VALID_QUALITY_FLAGS_VERSION:
            raise SSOTMismatchError(
                f"E408: SSOT Quality Flags ç‰ˆæœ¬ä¸åŒ¹é…: "
                f"YAML ç‚º {ssot_flags_version}ï¼Œç³»çµ±è¦æ±‚ {VALID_QUALITY_FLAGS_VERSION}"
            )

        # è§£æ Columns
        for col_name, col_data in raw_data.get('columns', {}).items():
            self._annotations[col_name] = ColumnAnnotation(**col_data)

            # å»ºç«‹ Equipment ID æ˜ å°„
            eq_id = col_data.get('equipment_id')
            if eq_id:
                if eq_id not in self._equipment_map:
                    self._equipment_map[eq_id] = []
                self._equipment_map[eq_id].append(col_name)

        # è§£æ Equipment Constraints
        for const_id, const_data in raw_data.get('equipment_constraints', {}).items():
            const_data['constraint_id'] = const_id
            self._constraints[const_id] = EquipmentConstraint(**const_data)

        self._cache = raw_data

    # ==================== æ ¸å¿ƒæŸ¥è©¢ API ====================

    def get_column_annotation(self, column_name: str) -> Optional[ColumnAnnotation]:
        """å–å¾—æ¬„ä½å®Œæ•´æ¨™è¨»"""
        return self._annotations.get(column_name)

    def is_column_annotated(self, column_name: str) -> bool:
        """æª¢æŸ¥æ¬„ä½æ˜¯å¦å·²å®šç¾©ï¼ˆE402 æª¢æŸ¥ï¼‰"""
        return column_name in self._annotations

    def get_device_role(self, column_name: str) -> Optional[str]:
        """
        å–å¾—è¨­å‚™è§’è‰²ï¼ˆprimary/backup/seasonalï¼‰
        ä¾› Cleaner v2.2 é€²è¡Œèªæ„æ„ŸçŸ¥æ¸…æ´—
        """
        anno = self._annotations.get(column_name)
        return anno.device_role if anno else None

    def get_equipment_id(self, column_name: str) -> Optional[str]:
        """å–å¾—è¨­å‚™ IDï¼ˆv1.3 æ–°å¢ï¼‰"""
        anno = self._annotations.get(column_name)
        return anno.equipment_id if anno else None

    def get_columns_by_equipment_id(self, equipment_id: str) -> List[str]:
        """ä¾è¨­å‚™ ID å–å¾—æ‰€æœ‰ç›¸é—œæ¬„ä½"""
        return self._equipment_map.get(equipment_id, [])

    def get_columns_by_equipment_type(self, equipment_type: str) -> List[str]:
        """
        ä¾è¨­å‚™é¡å‹å–å¾—æ¬„ä½ï¼ˆåŸºæ–¼å‘½åå‰ç¶´åˆ†æï¼‰

        Args:
            equipment_type: "chiller", "pump", "cooling_tower", "ahu"
        """
        prefix_map = {
            "chiller": ["chiller_", "ch_"],
            "pump": ["pump_", "chw_pri_pump_", "chw_sec_pump_", "cw_pump_"],
            "cooling_tower": ["ct_", "cooling_tower_"],
            "ahu": ["ahu_"]
        }

        prefixes = prefix_map.get(equipment_type, [])
        return [
            name for name in self._annotations.keys()
            if any(name.startswith(p) for p in prefixes)
        ]

    def get_target_columns(self) -> List[str]:
        """å–å¾—æ‰€æœ‰ç›®æ¨™è®Šæ•¸æ¬„ä½ï¼ˆis_target=Trueï¼‰"""
        return [
            name for name, anno in self._annotations.items() 
            if anno.is_target
        ]

    def get_columns_by_role(self, role: str) -> List[str]:
        """
        ä¾è¨­å‚™è§’è‰²å–å¾—æ¬„ä½æ¸…å–®
        
        Args:
            role: "primary", "backup", æˆ– "seasonal"
        """
        return [
            name for name, anno in self._annotations.items()
            if anno.device_role == role
        ]

    def get_electrical_columns(self) -> Dict[str, List[str]]:
        """
        å–å¾—æ‰€æœ‰é›»åŠ›ç›¸é—œæ¬„ä½åˆ†é¡ï¼ˆé›»æµã€é›»å£“ã€åŠŸç‡ã€åŠŸç‡å› æ•¸ï¼‰
        
        Returns:
            {
                "power": ["chiller_01_kw", ...],
                "current": ["chiller_01_a", ...],
                "voltage": ["chiller_01_v", ...],
                "pf": ["chiller_01_pf", ...],
                "energy": ["chiller_01_kwh", ...]
            }
        """
        electrical_types = ["power", "current", "voltage", "power_factor", "energy"]
        return {
            ptype: [
                name for name, anno in self._annotations.items()
                if anno.physical_type == ptype
            ]
            for ptype in electrical_types
        }

    # ==================== Equipment Validation API ====================

    def get_equipment_constraints(self, phase: Optional[str] = None) -> List[EquipmentConstraint]:
        """
        å–å¾—è¨­å‚™é‚è¼¯é™åˆ¶æ¢ä»¶ï¼ˆå°é½Š Interface Contract v1.1 ç¬¬ 11 ç« ï¼‰
        
        Args:
            phase: ç¯©é¸æª¢æŸ¥éšæ®µ ("precheck" æˆ– "optimization")ï¼ŒNone å‰‡å›å‚³å…¨éƒ¨
        
        Returns:
            EquipmentConstraint ç‰©ä»¶åˆ—è¡¨
        """
        constraints = list(self._constraints.values())
        if phase:
            constraints = [c for c in constraints if c.check_phase == phase]
        return constraints

    def get_constraints_for_column(self, column_name: str) -> List[EquipmentConstraint]:
        """
        å–å¾—é©ç”¨æ–¼ç‰¹å®šæ¬„ä½çš„é™åˆ¶æ¢ä»¶
        
        é‚è¼¯ï¼š
        - æª¢æŸ¥æ¬„ä½æ˜¯å¦ç‚º trigger_status æˆ– required_status çš„æˆå“¡
        - æª¢æŸ¥æ¬„ä½çš„ device_role æ˜¯å¦åœ¨ applicable_roles ä¸­
        """
        anno = self._annotations.get(column_name)
        if not anno:
            return []
        
        applicable = []
        for const in self._constraints.values():
            involved = False
            if const.trigger_status and column_name in const.trigger_status:
                involved = True
            if const.required_status and column_name in const.required_status:
                involved = True
            
            if involved and anno.device_role in const.applicable_roles:
                applicable.append(const)
        
        return applicable

    def get_interlock_constraints_for_equipment(self, equipment_id: str) -> List[EquipmentConstraint]:
        """
        å–å¾—ç‰¹å®šè¨­å‚™çš„äº’é–é™åˆ¶ï¼ˆHVAC å°ˆç”¨ï¼‰
        
        Args:
            equipment_id: è¨­å‚™ IDï¼ˆå¦‚ "CH-01"ï¼‰
        """
        columns = self._equipment_map.get(equipment_id, [])
        constraints = []
        
        for col in columns:
            col_constraints = self.get_constraints_for_column(col)
            # ç¯©é¸äº’é–é¡å‹ï¼ˆrequires, mutexï¼‰
            interlocks = [c for c in col_constraints if c.check_type in ['requires', 'mutex']]
            constraints.extend(interlocks)
        
        return constraints

    def validate_monotonic_energy(self, df: pl.DataFrame) -> List[dict]:
        """
        é©—è­‰ç´¯ç©ç”¨é›»é‡ï¼ˆkWhï¼‰æ˜¯å¦å–®èª¿éå¢ï¼ˆE351 éŒ¯èª¤ç¢¼ï¼‰
        
        Returns:
            é•åå–®èª¿æ€§çš„æ¬„ä½åˆ—è¡¨ï¼ˆå«è©³ç´°è³‡è¨Šï¼‰
        """
        violations = []
        energy_cols = [
            name for name, anno in self._annotations.items()
            if anno.physical_type == "energy"
        ]
        
        for col in energy_cols:
            if col in df.columns:
                diff = df[col].diff()
                significant_drop = (diff < -0.01).sum()
                
                if significant_drop > 0:
                    violations.append({
                        "column": col,
                        "drops_count": int(significant_drop),
                        "error_code": "E351",
                        "message": f"ç´¯ç©ç”¨é›»é‡ {col} ç™¼ç”Ÿéé æœŸéæ¸›ï¼Œå¯èƒ½é›»è¡¨æ•…éšœæˆ–é‡ç½®"
                    })
        
        return violations

    def get_efficiency_baseline(self, chiller_id: str) -> Dict[str, float]:
        """
        å–å¾—ç‰¹å®šä¸»æ©Ÿçš„æ•ˆç‡åŸºæº–ç¯„åœï¼ˆä¾› Cleaner ç•°å¸¸æª¢æ¸¬ä½¿ç”¨ï¼‰
        
        Returns:
            {"cop_min": 3.0, "cop_max": 6.0, "kw_per_rt_max": 1.2}
        """
        ptype_config = self._cache.get("physical_types", {}).get("efficiency", {})
        mean_range = ptype_config.get("distribution_check", {}).get("expected_mean_range", [3.0, 6.0])
        
        return {
            "cop_min": mean_range[0],
            "cop_max": mean_range[1],
            "kw_per_rt_max": 3.517 / mean_range[0]
        }

    # ==================== æ™‚é–“åŸºæº–æ•´åˆ ====================

    def get_temporal_baseline(self) -> Optional[datetime]:
        """
        å–å¾— Pipeline æ™‚é–“åŸºæº–ï¼ˆå°é½Š Interface Contract ç¬¬8ç« ï¼‰
        
        Returns:
            pipeline_origin_timestamp (datetime)
        """
        if self.temporal_context:
            return self.temporal_context.get_baseline()
        return None

    def is_future_data(self, timestamp: datetime, tolerance_minutes: int = 5) -> bool:
        """
        åˆ¤æ–·æ™‚é–“æˆ³æ˜¯å¦ç‚ºæœªä¾†è³‡æ–™ï¼ˆä½¿ç”¨ TemporalContextï¼‰
        
        Args:
            timestamp: å¾…æª¢æŸ¥æ™‚é–“æˆ³
            tolerance_minutes: å®¹è¨±èª¤å·®ï¼ˆé è¨­5åˆ†é˜ï¼‰
        
        Returns:
            bool: æ˜¯å¦ç‚ºæœªä¾†è³‡æ–™
        """
        if not self.temporal_context:
            raise RuntimeError("E000: TemporalContext æœªåˆå§‹åŒ–")
        
        return self.temporal_context.is_future(timestamp, tolerance_minutes)

    # ==================== ç¦æ­¢å¯«å…¥é˜²è­· ====================

    def __setattr__(self, name, value):
        """ç¦æ­¢å‹•æ…‹ä¿®æ”¹å±¬æ€§ï¼ˆE500 é˜²è­·ï¼‰"""
        if name.startswith('_') or name in ['site_id', 'config_path', 'temporal_context']:
            super().__setattr__(name, value)
        else:
            raise PermissionError(
                f"E500: FeatureAnnotationManager ç‚ºå”¯è®€ä»‹é¢ï¼Œ"
                f"ç¦æ­¢ä¿®æ”¹å±¬æ€§ '{name}'ã€‚è«‹ä½¿ç”¨ Excel ç·¨è¼¯å¾Œé‡æ–°ç”Ÿæˆ YAMLã€‚"
            )

    def save(self, *args, **kwargs):
        """æ˜ç¢ºç¦æ­¢å„²å­˜æ“ä½œï¼ˆE501 é˜²è­·ï¼‰"""
        raise NotImplementedError(
            "E501: ç¦æ­¢é€é FeatureAnnotationManager å„²å­˜è®Šæ›´ã€‚"
            "æ­£ç¢ºæµç¨‹: Excel â†’ excel_to_yaml.py â†’ Git Commit"
        )
```

---

## 9. Header Standardization è¦ç¯„ï¼ˆCSV æ¨™é ­æ­£è¦åŒ–ï¼‰

### 9.1 å•é¡Œå®šç¾©èˆ‡å¯¦ä½œ

CSV æª”æ¡ˆçš„æ¨™é ­ï¼ˆæ¬„ä½åç¨±ï¼‰å¸¸åŒ…å«ä¸ä¸€è‡´çš„å‘½åï¼ˆå¦‚ `Chiller 1 Temp`ã€`power(kW)`ã€`sensor-A`ï¼‰ï¼Œå°è‡´èˆ‡ Feature Annotation ä¸­å®šç¾©çš„ `column_name` ç„¡æ³•åŒ¹é…ã€‚ç‚ºè§£æ±ºæ­¤å•é¡Œï¼Œå»ºç«‹è‡ªå‹•æ­£è¦åŒ–æ©Ÿåˆ¶ã€‚

### 9.2 æ­£è¦åŒ–è¦å‰‡ (Regex-based)

**æ¨™æº–å‘½åè¦ç¯„**: `snake_case`ï¼Œåƒ…å…è¨±å°å¯«è‹±æ–‡å­—æ¯ã€æ•¸å­—ã€åº•ç·šã€‚

**æ­£è¦åŒ–æµç¨‹**ï¼ˆå°é½Š Interface Contract ç¬¬10ç« ï¼‰:

```python
# src/etl/header_standardizer.py
import re
from typing import List, Tuple

class HeaderStandardizer:
    """
    CSV æ¨™é ­æ­£è¦åŒ–å™¨ï¼ˆå°é½Š Interface Contract v1.1 ç¬¬10ç« ï¼‰
    
    å¯¦ä½œ HEADER_STANDARDIZATION_RULES çš„å…·é«”æ­£è¦åŒ–é‚è¼¯
    """
    
    RULES: List[Tuple[str, str]] = [
        # æ­¥é©Ÿ 1: ç§»é™¤å‰å¾Œç©ºç™½
        (r'^\s+|\s+$', ''),
        
        # æ­¥é©Ÿ 2: å°‡ camelCase/PascalCase è½‰æ›ç‚º snake_case
        # æ’å…¥åº•ç·šåœ¨å¤§å¯«å­—æ¯å‰ï¼Œç„¶å¾Œè½‰å°å¯«
        (r'(?<=[a-z0-9])(?=[A-Z])', '_'),      # åœ¨å°å¯«/æ•¸å­—å¾Œçš„å¤§å¯«å‰æ’å…¥åº•ç·š
        (r'(?<=[A-Z])(?=[A-Z][a-z])', '_'),    # åœ¨é€£çºŒå¤§å¯«ä¸­çš„ç¬¬äºŒå€‹å¤§å¯«å‰æ’å…¥åº•ç·š
        
        # æ­¥é©Ÿ 3: æ›¿æ›éæ³•å­—å…ƒç‚ºåº•ç·š
        (r'[^a-zA-Z0-9_]', '_'),               # éå­—æ¯æ•¸å­—åº•ç·šçš„å­—å…ƒæ›¿æ›ç‚ºåº•ç·š
        
        # æ­¥é©Ÿ 4: åˆä½µé€£çºŒåº•ç·š
        (r'_+', '_'),
        
        # æ­¥é©Ÿ 5: ç§»é™¤é–‹é ­æ•¸å­—ï¼ˆPython è®Šæ•¸é™åˆ¶ï¼‰
        (r'^[0-9]+', 'col_'),
        
        # æ­¥é©Ÿ 6: è½‰æ›ç‚ºå°å¯«ï¼ˆé€éæ¨™èªŒè™•ç†ï¼‰
    ]

    def standardize(self, header: str) -> str:
        """
        å°‡ CSV æ¨™é ­æ­£è¦åŒ–ç‚º snake_case
        
        Args:
            header: åŸå§‹æ¨™é ­å­—ä¸²
            
        Returns:
            æ­£è¦åŒ–å¾Œçš„æ¨™é ­ï¼ˆsnake_caseï¼‰
            
        Raises:
            HeaderStandardizationError: è‹¥æ­£è¦åŒ–å¾Œä»ä¸ç¬¦åˆè¦å‰‡ï¼ˆE105ï¼‰
        """
        result = header
        
        # å¥—ç”¨ Regex è¦å‰‡
        for pattern, replacement in self.RULES:
            result = re.sub(pattern, replacement, result)
        
        # è½‰æ›ç‚ºå°å¯«
        result = result.lower()
        
        # æœ€çµ‚é©—è­‰
        if not result or result == '_' or not re.match(r'^[a-z][a-z0-9_]*$', result):
            raise HeaderStandardizationError(
                f"E105: æ¨™é ­ '{header}' ç„¡æ³•æ­£è¦åŒ–ç‚ºæœ‰æ•ˆè­˜åˆ¥ç¬¦ï¼Œçµæœ: '{result}'"
            )
        
        # æª¢æŸ¥ä¿ç•™é—œéµå­—ï¼ˆé¿å…èˆ‡ Python å…§å»ºè¡çªï¼‰
        if result in ['class', 'def', 'if', 'else', 'for', 'while', 'timestamp']:
            result = f"{result}_col"
        
        return result

    def standardize_headers(self, headers: List[str]) -> dict:
        """
        æ‰¹æ¬¡æ­£è¦åŒ–æ¨™é ­ä¸¦å›å‚³æ˜ å°„è¡¨
        
        Returns:
            Dict[åŸå§‹æ¨™é ­, æ­£è¦åŒ–å¾Œæ¨™é ­]
        """
        mapping = {}
        standardized_set = set()
        
        for header in headers:
            if header == 'timestamp':
                mapping[header] = header
                standardized_set.add(header)
                continue
                
            standardized = self.standardize(header)
            
            # æª¢æŸ¥æ­£è¦åŒ–å¾Œé‡è¤‡ï¼ˆE105 é¢¨éšªï¼‰
            if standardized in standardized_set:
                raise HeaderStandardizationError(
                    f"E105: æ­£è¦åŒ–å¾Œç”¢ç”Ÿé‡è¤‡æ¨™é ­: '{standardized}' "
                    f"ï¼ˆåŸå§‹: '{header}' èˆ‡ '{[k for k, v in mapping.items() if v == standardized][0]}'ï¼‰"
                )
            
            mapping[header] = standardized
            standardized_set.add(standardized)
        
        return mapping
```

### 9.3 å¸¸è¦‹æ¨™é ­è½‰æ›ç¯„ä¾‹

| åŸå§‹æ¨™é ­ | æ­£è¦åŒ–çµæœ | èªªæ˜ |
|:---|:---|:---|
| `Chiller 1 Temp` | `chiller_1_temp` | ç©ºæ ¼è½‰åº•ç·šï¼Œå¤§å¯«è½‰å°å¯« |
| `power(kW)` | `power_kw` | ç§»é™¤æ‹¬è™Ÿï¼Œä¿ç•™å­—æ¯æ•¸å­— |
| `sensor-A` | `sensor_a` | é€£å­—è™Ÿè½‰åº•ç·š |
| `HTTPRequest` | `http_request` | PascalCase è½‰ snake_case |
| `Total_Power` | `total_power` | å¤§å¯«è½‰å°å¯« |
| `123_sensor` | `col_123_sensor` | é–‹é ­æ•¸å­—å‰ç¶´ `col_` |
| `Temp..Value` | `temp_value` | åˆä½µé€£çºŒåº•ç·š |

### 9.4 Parser æ•´åˆè¦ç¯„

**åŸ·è¡Œæ™‚æ©Ÿ**: Parser è®€å– CSV å¾Œã€å»ºç«‹ DataFrame å‰ï¼Œå¿…é ˆåŸ·è¡Œæ¨™é ­æ­£è¦åŒ–ã€‚

```python
class ReportParser:
    def __init__(self, temporal_context: TemporalContext):
        self.temporal_context = temporal_context
        self.header_standardizer = HeaderStandardizer()
        self.logger = logging.getLogger(__name__)

    def parse_csv(self, filepath: Path) -> pl.DataFrame:
        # è®€å–åŸå§‹ CSVï¼ˆä¸æŒ‡å®šæ¬„ä½åç¨±ï¼‰
        raw_df = pl.read_csv(filepath, n_rows=5)
        original_headers = raw_df.columns
        
        # åŸ·è¡Œæ¨™é ­æ­£è¦åŒ–
        try:
            header_mapping = self.header_standardizer.standardize_headers(original_headers)
        except HeaderStandardizationError as e:
            self.logger.error(f"E105: {e}")
            raise
        
        # è¨˜éŒ„æ­£è¦åŒ–æ˜ å°„ä¾›é™¤éŒ¯
        for orig, std in header_mapping.items():
            if orig != std:
                self.logger.info(f"E105-Warning: æ¨™é ­æ­£è¦åŒ–: '{orig}' â†’ '{std}'")
        
        # é‡æ–°è®€å–ä¸¦å¥—ç”¨æ­£è¦åŒ–æ¨™é ­
        df = pl.read_csv(filepath)
        df = df.rename(header_mapping)
        
        # é©—è­‰ timestamp æ¬„ä½å­˜åœ¨
        if 'timestamp' not in df.columns:
            raise ValueError("E003: ç¼ºå°‘å¿…è¦æ¬„ä½ 'timestamp'")
        
        # è½‰æ›æ™‚é–“æˆ³æ ¼å¼ï¼ˆå°é½Š Interface Contract ç¬¬4ç« ï¼‰
        df = df.with_columns(
            pl.col('timestamp').str.to_datetime().dt.cast_time_unit('ns').dt.replace_time_zone('UTC')
        )
        
        return df
```

### 9.5 èˆ‡ Feature Annotation çš„å°æ¥

æ­£è¦åŒ–å¾Œçš„æ¨™é ­å¿…é ˆèˆ‡ Annotation YAML ä¸­çš„ `column_name` å®Œå…¨åŒ¹é…ï¼š

```python
def validate_header_annotation_match(
    standardized_headers: List[str], 
    annotation_manager: FeatureAnnotationManager
) -> None:
    """
    é©—è­‰æ­£è¦åŒ–å¾Œçš„æ¨™é ­èˆ‡ Annotation å®šç¾©åŒ¹é…ï¼ˆæª¢æŸ¥é» #6 å»¶ä¼¸ï¼‰
    
    Raises:
        E409: è‹¥å­˜åœ¨ç„¡æ³•åŒ¹é…çš„æ¨™é ­
    """
    unannotated = []
    for header in standardized_headers:
        if not annotation_manager.is_column_annotated(header):
            unannotated.append(header)
    
    if unannotated:
        raise AnnotationSyncError(
            f"E409: CSV æ¨™é ­ï¼ˆæ­£è¦åŒ–å¾Œï¼‰ç„¡æ³•å°æ‡‰è‡³ Annotation: {unannotated}ã€‚ "
            f"è«‹ç¢ºèª Excel æ¨™è¨»ä¸­çš„ column_name æ˜¯å¦èˆ‡æ­£è¦åŒ–çµæœä¸€è‡´ï¼Œ"
            f"æˆ–åŸ·è¡Œ features wizard é€²è¡Œæ¨™è¨»ã€‚"
        )
```

---

## 10. Temporal Baseline å‚³éè¦ç¯„ï¼ˆæ™‚é–“åŸºæº–é˜²è­·ï¼‰

### 10.1 æ ¸å¿ƒæ©Ÿåˆ¶

ç‚ºè§£æ±ºã€ŒPipeline åŸ·è¡ŒæœŸé–“æ™‚é–“æ¼‚ç§»å°è‡´æœªä¾†è³‡æ–™èª¤åˆ¤ã€å•é¡Œï¼ˆåŸ E102/E205 é¢¨éšªï¼‰ï¼Œå»ºç«‹ä»¥ä¸‹æ©Ÿåˆ¶ï¼š

**æ™‚é–“åŸºæº–ç”¢ç”Ÿ**ï¼š
- **æ™‚æ©Ÿ**: `Container.__init__` åˆå§‹åŒ–æ™‚ï¼ˆç¬¬ä¸€å€‹å‹•ä½œï¼Œæ—©æ–¼ä»»ä½•æ¨¡çµ„åˆå§‹åŒ–ï¼‰
- **æ ¼å¼**: ISO 8601 UTC (e.g., `2026-02-13T10:00:00.000000000Z`)
- **å„²å­˜**: `TemporalContext` ç‰©ä»¶ï¼ˆThread-safe Singletonï¼‰

```python
# src/features/temporal_context.py
import threading
from datetime import datetime, timedelta, timezone
from typing import Optional

class TemporalContext:
    """
    å…¨åŸŸæ™‚é–“åŸºæº–å®¹å™¨ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰ï¼ˆå°é½Š Interface Contract v1.1 ç¬¬8ç« ï¼‰
    
    æ‰€æœ‰ã€Œæœªä¾†è³‡æ–™æª¢æŸ¥ã€èˆ‡ã€Œæ™‚é–“ç›¸é—œé©—è­‰ã€å¿…é ˆä½¿ç”¨æ­¤åŸºæº–ï¼Œ
    è€Œéæ¨¡çµ„åŸ·è¡Œæ™‚çš„å‹•æ…‹ datetime.now()ï¼Œä»¥é˜²æ­¢é•·æ™‚é–“åŸ·è¡Œæµç¨‹ä¸­çš„æ™‚é–“æ¼‚ç§»ã€‚
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance.origin_timestamp = datetime.now(timezone.utc)
                    cls._instance.baseline_version = "1.0"
                    cls._instance._initialized = True
        return cls._instance
    
    @classmethod
    def reset_for_testing(cls):
        """åƒ…ä¾›å–®å…ƒæ¸¬è©¦ä½¿ç”¨ï¼Œé‡ç½®æ™‚é–“åŸºæº–"""
        with cls._lock:
            cls._instance = None
    
    def get_baseline(self) -> datetime:
        """å–å¾— Pipeline å•Ÿå‹•æ™‚é–“æˆ³ï¼ˆUTCï¼‰"""
        return self.origin_timestamp
    
    def get_baseline_iso(self) -> str:
        """å–å¾— ISO 8601 æ ¼å¼çš„æ™‚é–“åŸºæº–"""
        return self.origin_timestamp.isoformat()
    
    def is_future(self, timestamp: datetime, tolerance_minutes: int = 5) -> bool:
        """
        åˆ¤æ–·æ™‚é–“æˆ³æ˜¯å¦ç‚ºã€Œæœªä¾†è³‡æ–™ã€
        
        æ¨™æº–ï¼štimestamp > origin_timestamp + tolerance_minutes
        
        Args:
            timestamp: å¾…æª¢æŸ¥æ™‚é–“æˆ³ï¼ˆå¿…é ˆå«æ™‚å€è³‡è¨Šï¼‰
            tolerance_minutes: å®¹è¨±èª¤å·®ï¼ˆé è¨­5åˆ†é˜ï¼Œè€ƒé‡è³‡æ–™å‚³è¼¸å»¶é²ï¼‰
        
        Returns:
            bool: True è‹¥ç‚ºæœªä¾†è³‡æ–™
        """
        if timestamp.tzinfo is None:
            raise ValueError("æ™‚é–“æˆ³å¿…é ˆå«æ™‚å€è³‡è¨Š")
        
        threshold = self.origin_timestamp + timedelta(minutes=tolerance_minutes)
        return timestamp > threshold
    
    def get_elapsed_minutes(self) -> float:
        """å–å¾— Pipeline å·²åŸ·è¡Œæ™‚é–“ï¼ˆç”¨æ–¼æ¼‚ç§»æª¢æ¸¬ï¼‰"""
        return (datetime.now(timezone.utc) - self.origin_timestamp).total_seconds() / 60
    
    def check_drift_warning(self) -> Optional[str]:
        """
        æª¢æŸ¥æ™‚é–“æ¼‚ç§»è­¦å‘Šï¼ˆE000-Wï¼‰
        
        Returns:
            è­¦å‘Šè¨Šæ¯è‹¥åŸ·è¡Œè¶…é 1 å°æ™‚ï¼Œå¦å‰‡ None
        """
        elapsed = self.get_elapsed_minutes()
        if elapsed > 60:
            return f"E000-W: Pipeline åŸ·è¡Œæ™‚é–“éé•· ({elapsed:.1f} åˆ†é˜)ï¼Œè«‹æª¢æŸ¥æ™‚é–“åŸºæº–ä¸€è‡´æ€§"
        return None
    
    def to_metadata(self) -> dict:
        """è½‰æ›ç‚ºå„²å­˜ç”¨çš„ metadata æ ¼å¼"""
        return {
            "pipeline_origin_timestamp": self.get_baseline_iso(),
            "baseline_version": self.baseline_version,
            "timezone": "UTC",
            "time_unit": "nanoseconds"
        }
```

### 10.2 å„æ¨¡çµ„å¯¦ä½œè¦ç¯„

**Parser**:
- æ¥æ”¶ `TemporalContext`ï¼Œåœ¨è¼¸å‡º metadata ä¸­è¨˜éŒ„ `pipeline_origin_timestamp`
- é©—è­‰é‚è¼¯ï¼šè‹¥è¼¸å…¥è³‡æ–™æ™‚é–“ > `context.get_baseline() + 5min`ï¼Œæ‹‹å‡º E102
- **å¼·åŒ–**: è‹¥ `context.get_elapsed_minutes() > 60`ï¼Œè¨˜éŒ„ E000-W è­¦å‘Š

**Cleaner**:
- å¾è¼¸å…¥ metadata è®€å– `pipeline_origin_timestamp`ï¼Œå‚³éè‡³è¼¸å‡º
- é©—è­‰é‚è¼¯ï¼šæ¸…æ´—å¾Œè³‡æ–™æ™‚é–“ä¸å¯è¶…éåŸºæº–+5åˆ†é˜ï¼ˆE102ï¼‰
- **å¼·åŒ–**: è‹¥å•Ÿç”¨ `enforce_equipment_validation_sync`ï¼Œåœ¨æ™‚é–“æª¢æŸ¥å¾ŒåŸ·è¡Œè¨­å‚™é‚è¼¯é æª¢

**BatchProcessor**:
- å°‡ `temporal_baseline` å¯«å…¥ Manifestï¼ˆè¦‹ç¬¬2.3ç¯€ Manifest å¥‘ç´„ï¼‰
- æ‰¹æ¬¡é©—è­‰ï¼šæ•´å€‹æ‰¹æ¬¡æ™‚é–“ç¯„åœä¸å¯è¶…éåŸºæº–+5åˆ†é˜ï¼ˆE205ï¼‰
- **å¼·åŒ–**: è¨˜éŒ„ `baseline_version` è‡³ Manifestï¼Œä¾›ä¸‹æ¸¸ç›¸å®¹æ€§æª¢æŸ¥

**FeatureAnnotationManager**:
- åˆå§‹åŒ–æ™‚æ¥æ”¶ `TemporalContext`ï¼ˆè¦‹ç¬¬8.1ç¯€ï¼‰
- æä¾› `is_future_data()` æ–¹æ³•ä¾› Cleaner å‘¼å«ï¼ˆè¦‹ç¬¬8.2ç¯€ï¼‰
- **ç¦æ­¢**: ä½¿ç”¨ `datetime.now()` é€²è¡Œæœªä¾†è³‡æ–™æª¢æŸ¥

**FeatureEngineer â†’ Model Training**:
- ç‰¹å¾µçŸ©é™£ metadata å¿…é ˆåŒ…å« `pipeline_origin_timestamp`ï¼ˆç”¨æ–¼è¿½æº¯ï¼‰
- **æ³¨æ„**: Training éšæ®µä¸ç›´æ¥ä½¿ç”¨æ­¤æ™‚é–“æˆ³é€²è¡Œã€Œæœªä¾†æª¢æŸ¥ã€ï¼Œä½†å¿…é ˆå‚³éè‡³æ¨¡å‹ç”¢ç‰©
- **å¼·åŒ–**: è¨˜éŒ„ç‰¹å¾µå·¥ç¨‹åŸ·è¡Œæ™‚é–“èˆ‡åŸºæº–æ™‚é–“çš„å·®ç•°ï¼ˆç”¨æ–¼æ•ˆèƒ½åˆ†æï¼‰

**Optimization**:
- **ç”¢ç”Ÿæ–°åŸºæº–**: Optimization éšæ®µå¿…é ˆç”¢ç”Ÿæ–°çš„ `pipeline_origin_timestamp`ï¼ˆæ¨è«–ç•¶ä¸‹æ™‚é–“ï¼‰
- **ä¸å¯æ²¿ç”¨ Training æ™‚é–“**: é˜²æ­¢ã€Œè¨“ç·´æ™‚çš„æœªä¾†è³‡æ–™ã€åœ¨æ¨è«–æ™‚è®Šæˆã€Œéå»è³‡æ–™ã€çš„é‚è¼¯éŒ¯èª¤
- **å¼·åŒ–**: é©—è­‰è¼¸å…¥è³‡æ–™æ™‚é–“ç¯„åœèˆ‡æ–°åŸºæº–çš„åˆç†æ€§

### 10.3 è·¨æ—¥åŸ·è¡Œé˜²è­·

é‡å°è·¨æ—¥ï¼ˆ00:00 å‰å¾Œï¼‰åŸ·è¡Œçš„ç‰¹æ®Šè™•ç†ï¼š

```python
def validate_cross_day_consistency(timestamps: List[datetime], baseline: datetime) -> None:
    """
    é©—è­‰è·¨æ—¥åŸ·è¡Œæ™‚çš„æ™‚é–“ä¸€è‡´æ€§
    
    æª¢æŸ¥é …ç›®ï¼š
    1. æ™‚é–“æˆ³æ˜¯å¦åŒ…å«æ­£ç¢ºæ—¥æœŸï¼ˆé 1970-01-01 ç­‰é è¨­å€¼ï¼‰
    2. æ™‚é–“æˆ³èˆ‡åŸºæº–çš„æ—¥æœŸå·®è·æ˜¯å¦åˆç†ï¼ˆ< 1 å¤©ï¼‰
    """
    for ts in timestamps:
        # æª¢æŸ¥æ˜¯å¦ç‚ºç„¡æ•ˆæ—¥æœŸ
        if ts.year < 2020:
            raise ValueError(f"E000: ç„¡æ•ˆæ™‚é–“æˆ³å¹´ä»½: {ts}")
        
        # æª¢æŸ¥èˆ‡åŸºæº–å·®è·
        date_diff = abs((ts.date() - baseline.date()).days)
        if date_diff > 1:
            raise ValueError(
                f"E000: æ™‚é–“æˆ³æ—¥æœŸ {ts.date()} èˆ‡åŸºæº– {baseline.date()} å·®è·éå¤§"
            )
```

---

## 11. Feature Alignment & Scaler Parameters å‚³éè¦ç¯„

### 11.1 å•é¡Œå®šç¾©

ç‚ºè§£æ±ºã€ŒTraining èˆ‡ Optimization ç‰¹å¾µå‘é‡ä¸ä¸€è‡´å°è‡´ Silent Failureã€é¢¨éšªï¼ˆåŸç¬¬3é»å»ºè­°ï¼‰ï¼Œå»ºç«‹ä»¥ä¸‹åš´æ ¼å¥‘ç´„ï¼š

**é¢¨éšªå ´æ™¯**ï¼š
- Training: ç‰¹å¾µé †åº `[chiller_1_load, chiller_2_load, wb_temp, ...]`
- Optimization: ç‰¹å¾µé †åº `[wb_temp, chiller_1_load, chiller_2_load, ...]`
- çµæœï¼šæ¨¡å‹å°‡ `wb_temp` èª¤èªç‚º `chiller_2_load`ï¼Œå°è‡´é æ¸¬å®Œå…¨éŒ¯èª¤ä½†ç„¡è­¦å‘Š

### 11.2 Feature Manifest è¦æ ¼ï¼ˆå°é½Š Interface Contract ç¬¬9ç« ï¼‰

**è¼¸å‡ºä½ç½®**: `ModelTrainer` è¼¸å‡ºç›®éŒ„ä¸­çš„ `feature_manifest.json`

```json
{
  "manifest_version": "2.0-ALIGN",
  "created_at": "2026-02-13T10:30:00Z",
  "pipeline_origin_timestamp": "2026-02-13T10:00:00Z",
  
  "feature_specification": {
    "feature_names": ["chiller_1_load", "chiller_2_load", "wb_temp", "chwst_temp"],
    "feature_count": 4,
    "feature_hash": "sha256:a1b2c3d4...",
    "hash_algorithm": "SHA256",
    "hash_computation": "sha256(','.join(feature_names).encode())"
  },
  
  "scaling_specification": {
    "scaler_type": "StandardScaler",
    "scaler_params": {
      "mean_": [450.5, 420.3, 28.5, 7.2],
      "scale_": [120.2, 115.8, 2.1, 0.5],
      "var_": [14448.04, 13401.64, 4.41, 0.25]
    },
    "scaler_feature_names": ["chiller_1_load", "chiller_2_load", "wb_temp", "chwst_temp"],
    "scaler_hash": "sha256:e5f6g7h8..."
  },
  
  "equipment_constraints": {
    "constraints_applied": ["chiller_pump_mutex", "min_runtime_15min"],
    "validation_enabled": true,
    "constraint_hash": "sha256:i9j0k1l2..."
  },
  
  "validation_rules": {
    "allow_subset": false,
    "allow_superset": false,
    "strict_order": true,
    "case_sensitive": true,
    "validate_equipment_constraints": true
  }
}
```

### 11.3 Python å¯¦ä½œï¼ˆFeature Manifest ç”Ÿæˆå™¨ï¼‰

```python
# src/features/feature_manifest.py
import json
import hashlib
from typing import List, Dict, Any, Optional
from pathlib import Path
import numpy as np

class FeatureManifest:
    """
    Feature Manifest ç”Ÿæˆèˆ‡é©—è­‰å™¨ï¼ˆå°é½Š Interface Contract v1.1 ç¬¬9ç« ï¼‰
    
    ç¢ºä¿ Training èˆ‡ Optimization éšæ®µçš„ç‰¹å¾µä¸€è‡´æ€§
    """
    
    def __init__(
        self,
        feature_names: List[str],
        scaler_params: Optional[Dict[str, Any]] = None,
        equipment_constraints: Optional[List[str]] = None,
        pipeline_origin_timestamp: str = "",
        temporal_context: Optional['TemporalContext'] = None
    ):
        self.feature_names = feature_names
        self.scaler_params = scaler_params or {}
        self.equipment_constraints = equipment_constraints or []
        self.pipeline_origin_timestamp = pipeline_origin_timestamp or (
            temporal_context.get_baseline_iso() if temporal_context else ""
        )
        
        # è¨ˆç®—é›œæ¹Š
        self.feature_hash = self._compute_hash(','.join(feature_names))
        self.scaler_hash = self._compute_hash(str(scaler_params)) if scaler_params else ""
        self.constraint_hash = self._compute_hash(str(equipment_constraints)) if equipment_constraints else ""
    
    def _compute_hash(self, content: str) -> str:
        """è¨ˆç®— SHA256 é›œæ¹Š"""
        return f"sha256:{hashlib.sha256(content.encode()).hexdigest()}"
    
    def to_dict(self) -> dict:
        """è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        return {
            "manifest_version": "2.0-ALIGN",
            "created_at": datetime.now(timezone.utc).isoformat(),
            "pipeline_origin_timestamp": self.pipeline_origin_timestamp,
            "feature_specification": {
                "feature_names": self.feature_names,
                "feature_count": len(self.feature_names),
                "feature_hash": self.feature_hash,
                "hash_algorithm": "SHA256",
                "hash_computation": "sha256(','.join(feature_names).encode())"
            },
            "scaling_specification": {
                "scaler_type": self.scaler_params.get("type", "StandardScaler"),
                "scaler_params": {
                    "mean_": self.scaler_params.get("mean_", []),
                    "scale_": self.scaler_params.get("scale_", []),
                    "var_": self.scaler_params.get("var_", [])
                },
                "scaler_feature_names": self.scaler_params.get("feature_names", []),
                "scaler_hash": self.scaler_hash
            } if self.scaler_params else None,
            "equipment_constraints": {
                "constraints_applied": self.equipment_constraints,
                "validation_enabled": len(self.equipment_constraints) > 0,
                "constraint_hash": self.constraint_hash
            },
            "validation_rules": {
                "allow_subset": false,
                "allow_superset": false,
                "strict_order": true,
                "case_sensitive": true,
                "validate_equipment_constraints": true
            }
        }
    
    def save(self, filepath: Path):
        """å„²å­˜è‡³ JSON æª”æ¡ˆ"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=2, ensure_ascii=False)
    
    @classmethod
    def load(cls, filepath: Path) -> 'FeatureManifest':
        """å¾ JSON æª”æ¡ˆè¼‰å…¥"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        spec = data.get("feature_specification", {})
        scaling = data.get("scaling_specification", {})
        
        return cls(
            feature_names=spec.get("feature_names", []),
            scaler_params={
                "type": scaling.get("scaler_type"),
                "mean_": scaling.get("scaler_params", {}).get("mean_"),
                "scale_": scaling.get("scaler_params", {}).get("scale_"),
                "feature_names": scaling.get("scaler_feature_names")
            } if scaling else None,
            equipment_constraints=data.get("equipment_constraints", {}).get("constraints_applied"),
            pipeline_origin_timestamp=data.get("pipeline_origin_timestamp")
        )

class FeatureAlignmentValidator:
    """
    ç‰¹å¾µå°é½Šé©—è­‰å™¨ï¼ˆæª¢æŸ¥é» #7 å¯¦ä½œï¼‰
    
    åœ¨ Optimization éšæ®µé©—è­‰è¼¸å…¥ç‰¹å¾µèˆ‡ Training æ™‚çš„ä¸€è‡´æ€§
    """
    
    def __init__(self, manifest: FeatureManifest):
        self.manifest = manifest
    
    def validate(self, input_features: List[str], input_scaler_params: Optional[dict] = None) -> None:
        """
        é©—è­‰è¼¸å…¥ç‰¹å¾µèˆ‡ Manifest çš„ä¸€è‡´æ€§
        
        Raises:
            FeatureAlignmentError: E901, E902, E903, E904
        """
        # E901: ç‰¹å¾µé †åºæ¯”å°
        self._validate_feature_order(input_features)
        
        # E902: ç‰¹å¾µæ•¸é‡ä¸€è‡´æ€§
        self._validate_feature_count(input_features)
        
        # E903: ç¸®æ”¾åƒæ•¸å°é½Šï¼ˆè‹¥å­˜åœ¨ï¼‰
        if self.manifest.scaler_params and input_scaler_params:
            self._validate_scaler_params(input_scaler_params)
        
        # E904: è¨­å‚™é™åˆ¶ä¸€è‡´æ€§
        self._validate_equipment_constraints()
    
    def _validate_feature_order(self, input_features: List[str]):
        """E901: é©—è­‰ç‰¹å¾µé †åºèˆ‡åç¨±å®Œå…¨ä¸€è‡´"""
        expected = self.manifest.feature_names
        
        if len(input_features) != len(expected):
            raise FeatureAlignmentError(
                f"E902: ç‰¹å¾µç¶­åº¦ä¸åŒ¹é…: è¨“ç·´æ™‚ {len(expected)} ç¶­ï¼Œè¼¸å…¥ {len(input_features)} ç¶­"
            )
        
        for i, (exp, inp) in enumerate(zip(expected, input_features)):
            if exp != inp:
                raise FeatureAlignmentError(
                    f"E901: ç‰¹å¾µéŒ¯ä½æ–¼ç´¢å¼• {i}: è¨“ç·´æ™‚ç‚º '{exp}'ï¼Œè¼¸å…¥ç‚º '{inp}'"
                )
        
        # é›œæ¹Šé©—è­‰ï¼ˆå¯é¸ä½†å»ºè­°ï¼‰
        input_hash = self.manifest._compute_hash(','.join(input_features))
        if input_hash != self.manifest.feature_hash:
            raise FeatureAlignmentError(
                f"E901: ç‰¹å¾µé›œæ¹Šé©—è­‰å¤±æ•—ï¼Œç‰¹å¾µåˆ—è¡¨å¯èƒ½é­ä¿®æ”¹"
            )
    
    def _validate_feature_count(self, input_features: List[str]):
        """E902: é©—è­‰ç‰¹å¾µæ•¸é‡ï¼ˆå†—é¤˜æª¢æŸ¥ï¼‰"""
        if len(input_features) != self.manifest.feature_count:
            raise FeatureAlignmentError(
                f"E902: ç‰¹å¾µæ•¸é‡ä¸ä¸€è‡´: é æœŸ {self.manifest.feature_count}ï¼Œå¯¦éš› {len(input_features)}"
            )
    
    def _validate_scaler_params(self, input_params: dict):
        """E903: é©—è­‰ç¸®æ”¾åƒæ•¸èˆ‡ç‰¹å¾µé †åºä¸€è‡´"""
        scaler_features = input_params.get("feature_names", [])
        
        if scaler_features != self.manifest.feature_names:
            raise FeatureAlignmentError(
                "E903: ç¸®æ”¾åƒæ•¸ç‰¹å¾µé †åºèˆ‡è¨“ç·´ç‰¹å¾µé †åºä¸ä¸€è‡´ï¼Œå¯èƒ½å°è‡´ç¸®æ”¾éŒ¯ä½"
            )
        
        # é©—è­‰æ•¸å€¼é•·åº¦
        mean_len = len(input_params.get("mean_", []))
        if mean_len != len(self.manifest.feature_names):
            raise FeatureAlignmentError(
                f"E903: ç¸®æ”¾åƒæ•¸é•·åº¦ {mean_len} èˆ‡ç‰¹å¾µæ•¸ {len(self.manifest.feature_names)} ä¸åŒ¹é…"
            )
    
    def _validate_equipment_constraints(self):
        """E904: é©—è­‰è¨­å‚™é™åˆ¶ä¸€è‡´æ€§"""
        from src.etl.config_models import EQUIPMENT_VALIDATION_CONSTRAINTS
        
        current_constraints = set(EQUIPMENT_VALIDATION_CONSTRAINTS.keys())
        train_constraints = set(self.manifest.equipment_constraints)
        
        if train_constraints != current_constraints:
            raise FeatureAlignmentError(
                f"E904: è¨­å‚™é™åˆ¶ä¸ä¸€è‡´: è¨“ç·´æ™‚ä½¿ç”¨ {train_constraints}ï¼Œ"
                f"ç•¶å‰ä½¿ç”¨ {current_constraints}ã€‚é€™å¯èƒ½å°è‡´å„ªåŒ–çµæœèˆ‡æ¨¡å‹è¨“ç·´æ™‚çš„ç‰©ç†å‡è¨­è¡çªã€‚"
            )
```

### 11.4 å°é½Šé©—è­‰æµç¨‹ï¼ˆOptimization éšæ®µï¼‰

```python
# src/optimization/input_validator.py
def validate_feature_alignment(model_artifact_path: Path, input_features: List[str]):
    """
    Optimization éšæ®µç‰¹å¾µå°é½Šé©—è­‰ï¼ˆæª¢æŸ¥é» #7ï¼‰
    
    Args:
        model_artifact_path: æ¨¡å‹ç”¢ç‰©ç›®éŒ„ï¼ˆå« feature_manifest.jsonï¼‰
        input_features: ç•¶å‰è¼¸å…¥ç‰¹å¾µåç¨±åˆ—è¡¨ï¼ˆä¾é †åºï¼‰
    
    Raises:
        FeatureAlignmentError: E901-E904
    """
    manifest_path = model_artifact_path / "feature_manifest.json"
    
    if not manifest_path.exists():
        raise FeatureAlignmentError(
            "E901: ç¼ºå°‘ feature_manifest.jsonï¼Œç„¡æ³•é©—è­‰ç‰¹å¾µå°é½Š"
        )
    
    # è¼‰å…¥ Training æ™‚çš„ Feature Manifest
    manifest = FeatureManifest.load(manifest_path)
    
    # åŸ·è¡Œé©—è­‰
    validator = FeatureAlignmentValidator(manifest)
    validator.validate(input_features)
    
    print("âœ… ç‰¹å¾µå°é½Šé©—è­‰é€šéï¼ˆE901-E904ï¼‰")
```

---

## 12. ç‰ˆæœ¬ç›¸å®¹æ€§åˆ¤å®šæ¨™æº–ï¼ˆå°é½Š Interface Contract ç¬¬5ç« ï¼‰

### 12.1 ç›¸å®¹æ€§ç­‰ç´šå®šç¾©

| ç­‰ç´š | å®šç¾© | è¡Œç‚º | æ¨™ç¤º |
|:---:|:---|:---|:---:|
| **å®Œå…¨ç›¸å®¹** (Full Compatible) | ä¸Šä¸‹æ¸¸æ¨¡çµ„ç‰ˆæœ¬çµ„åˆé€šéæ‰€æœ‰æª¢æŸ¥é»ï¼Œç„¡éœ€è½‰æ›æˆ–é™ç´š | æ­£å¸¸åŸ·è¡Œï¼Œç„¡è­¦å‘Š | ğŸŸ¢ |
| **éƒ¨åˆ†ç›¸å®¹** (Partial Compatible) | ä¸Šæ¸¸è¼¸å‡ºå¯è¢«ä¸‹æ¸¸è®€å–ï¼Œä½†éƒ¨åˆ†åŠŸèƒ½é™ç´šï¼ˆå¦‚ç¼ºå°‘ audit_trailï¼‰ | åŸ·è¡Œï¼Œä½†è¨˜éŒ„ Warning | ğŸŸ¡ |
| **ä¸ç›¸å®¹** (Incompatible) | ä¸Šæ¸¸è¼¸å‡ºç„¡æ³•é€šéä¸‹æ¸¸æª¢æŸ¥é»ï¼Œæˆ–è³‡æ–™èªæ„ä¸ä¸€è‡´ | æ‹’çµ•åŸ·è¡Œï¼Œæ‹‹å‡ºéŒ¯èª¤ | ğŸ”´ |

### 12.2 æ¨¡çµ„ç‰ˆæœ¬ç›¸å®¹æ€§çŸ©é™£

| Feature Annotation | Parser | Cleaner | BatchProcessor | Feature Engineer | Model Training | Optimization | ç›¸å®¹æ€§ | èªªæ˜ |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---|
| v1.3 | v2.1+ | v2.2+ | v1.3+ | v1.3+ | v1.2+ | v1.1+ | ğŸŸ¢ **å®Œå…¨ç›¸å®¹** | æ¨è–¦é…ç½®ï¼Œæ”¯æ´ E901-E904ï¼ŒTemporal Baselineï¼ŒEquipment Validation Sync |
| v1.3 | v2.1+ | v2.1 | v1.3+ | v1.3+ | v1.2+ | v1.1+ | ğŸ”´ **ä¸ç›¸å®¹** | Cleaner v2.1 ç¼ºå°‘ Equipment Validation Syncï¼ˆE350 é¢¨éšªï¼‰ |
| v1.3 | v2.1+ | v2.2+ | v1.2 | v1.3+ | v1.2+ | v1.1+ | ğŸŸ¡ **éƒ¨åˆ†ç›¸å®¹** | BatchProcessor v1.2 ç¼ºå°‘ temporal_baseline å‚³éï¼ˆE000 é¢¨éšªï¼‰ |
| v1.3 | v2.1+ | v2.2+ | v1.3+ | v1.2 | v1.2+ | v1.1+ | ğŸŸ¡ **éƒ¨åˆ†ç›¸å®¹** | Feature Engineer v1.2 ç„¡æ³•è¼¸å‡º Feature Manifestï¼ˆE601 é¢¨éšªï¼‰ |
| v1.2 | v2.1+ | v2.2+ | v1.3+ | v1.3+ | v1.2+ | v1.1+ | ğŸ”´ **ä¸ç›¸å®¹** | Feature Annotation v1.2 ç¼ºå°‘ Equipment ID èˆ‡ Constraintsï¼ˆE904 é¢¨éšªï¼‰ |
| v1.3 | v2.0 | v2.2+ | v1.3+ | v1.3+ | v1.2+ | v1.1+ | ğŸ”´ **ä¸ç›¸å®¹** | Parser v2.0 ç¼ºå°‘ Header Standardizationï¼ˆE105/E409 é¢¨éšªï¼‰ |

### 12.3 å¼·åˆ¶å‡ç´šè·¯å¾‘

**ä¸å…è¨±çš„çµ„åˆ**ï¼ˆç³»çµ±å¿…é ˆæ‹’çµ•å•Ÿå‹•ï¼‰ï¼š
1. **Feature Annotation v1.3 + Cleaner v2.1**: ç¼ºå°‘ `equipment_id` æ”¯æ´èˆ‡ E350 æª¢æŸ¥
2. **Feature Engineer v1.2 + Optimization v1.1**: ç¼ºå°‘ Feature Manifest è¼¸å‡ºï¼Œç„¡æ³•é€šé E901-E903
3. **ä»»æ„çµ„åˆç¼ºå°‘ TemporalContext**: è§¸ç™¼ E000 éŒ¯èª¤

**å»ºè­°å‡ç´šé †åº**ï¼š
```
Feature Annotation v1.3 (åŸºç¤è¨­æ–½ - æœ¬æ–‡ä»¶)
    â†“
Parser v2.1 (ä¸Šæ¸¸è¼¸å‡ºæ¨™æº–åŒ– + Header Standardization)
    â†“
Cleaner v2.2 (è·è²¬åˆ†é›¢å¯¦ä½œ + Equipment Validation Sync + Temporal Baseline æ¥æ”¶)
    â†“
BatchProcessor v1.3 (æ™‚é–“åŸºæº–å‚³é + Audit Trail)
    â†“
FeatureEngineer v1.3 (ç‰¹å¾µé †åºä¿è­‰ E601 + Scaler Parameters E602 + Feature Manifest è¼¸å‡º)
    â†“
Model Training v1.2 (ç¸®æ”¾åƒæ•¸è¼¸å‡º E602 + Model Artifact æ ¼å¼)
    â†“
Optimization v1.1 (ç‰¹å¾µå°é½Šé©—è­‰ E901-E903 + Equipment Constraint Consistency E904 + æ–° Temporal Baseline)
```

---

## 13. Equipment Validation Sync å¯¦æ–½ç´°ç¯€ï¼ˆCleaner æ•´åˆï¼‰

### 13.1 Cleaner æ•´åˆè¦ç¯„ï¼ˆE350 å¯¦ä½œï¼‰

DataCleaner åœ¨æ¸…æ´—éšæ®µåŸ·è¡ŒåŸºç¤è¨­å‚™é‚è¼¯é æª¢ï¼š

```python
# src/etl/cleaner.py
class DataCleaner:
    def __init__(
        self, 
        config, 
        annotation_manager: FeatureAnnotationManager,
        temporal_context: TemporalContext,
        equipment_validator: Optional['EquipmentValidator'] = None
    ):
        self.config = config
        self.annotation_manager = annotation_manager
        self.temporal_context = temporal_context
        self.equipment_validator = equipment_validator
        
        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨è¨­å‚™é©—è­‰åŒæ­¥
        self.enable_equipment_sync = config.get('enforce_equipment_validation_sync', False)
        
        # å„²å­˜ç¨½æ ¸è»Œè·¡
        self._equipment_validation_audit = {
            'validation_enabled': False,
            'constraints_applied': [],
            'violations_detected': 0,
            'violation_details': []
        }

    def clean(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        ä¸»è¦æ¸…æ´—æµç¨‹ï¼ˆå« Equipment Validation Syncï¼‰
        """
        # 1. æ™‚é–“åŸºæº–é©—è­‰ï¼ˆE102ï¼‰
        df = self._validate_temporal_baseline(df)
        
        # 2. è¨­å‚™é‚è¼¯é æª¢ï¼ˆE350ï¼‰
        if self.enable_equipment_sync:
            df = self._apply_equipment_validation_precheck(df)
        
        # 3. æ¨™æº–æ¸…æ´—æµç¨‹...
        df = self._apply_standard_cleaning(df)
        
        # 4. è¨˜éŒ„ç¨½æ ¸è»Œè·¡è‡³ metadata
        self._equipment_validation_audit['validation_enabled'] = self.enable_equipment_sync
        
        return df

    def _validate_temporal_baseline(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        é©—è­‰æ™‚é–“åŸºæº–ï¼ˆE102ï¼‰
        """
        if not self.temporal_context:
            raise ValueError("E000: TemporalContext æœªæä¾›")
        
        # æª¢æŸ¥æ™‚é–“æ¼‚ç§»è­¦å‘Š
        drift_warning = self.temporal_context.check_drift_warning()
        if drift_warning:
            self.logger.warning(drift_warning)
        
        # æª¢æŸ¥æœªä¾†è³‡æ–™
        max_timestamp = df['timestamp'].max()
        if self.temporal_context.is_future(max_timestamp):
            raise ValueError(
                f"E102: è³‡æ–™åŒ…å«æœªä¾†æ™‚é–“æˆ³ {max_timestamp}ï¼Œ"
                f"è¶…éåŸºæº– {self.temporal_context.get_baseline_iso()}"
            )
        
        return df

    def _apply_equipment_validation_precheck(self, df: pl.DataFrame) -> pl.DataFrame:
        """
        è¨­å‚™é‚è¼¯é æª¢ï¼ˆæª¢æŸ¥é» #2 å»¶ä¼¸ - E350ï¼‰
        
        é‚è¼¯ï¼š
        1. å¾ AnnotationManager è®€å– equipment_constraints (phase="precheck")
        2. æª¢æŸ¥æ¯ä¸€æ™‚é–“é»çš„è¨­å‚™ç‹€æ…‹é‚è¼¯
        3. é•åæ™‚æ¨™è¨˜ quality_flagsï¼Œä¸¦è¨˜éŒ„è‡³ metadata
        """
        if not self.equipment_validator:
            self.equipment_validator = EquipmentValidator(self.annotation_manager)
        
        constraints = self.annotation_manager.get_equipment_constraints(phase="precheck")
        violations = []
        
        for constraint in constraints:
            # åŸ·è¡Œæª¢æŸ¥é‚è¼¯
            violated_mask = self.equipment_validator.check_constraint(df, constraint)
            
            if violated_mask.any():
                violation_count = violated_mask.sum()
                violations.append({
                    'constraint_id': constraint.constraint_id,
                    'count': int(violation_count),
                    'severity': constraint.severity
                })
                
                # æ ¹æ“šåš´é‡ç¨‹åº¦æ¨™è¨˜ Quality Flag
                if constraint.severity == 'critical':
                    flag = 'PHYSICAL_IMPOSSIBLE'
                    # å¯é¸ï¼šå°‡ç•°å¸¸å€¼è¨­ç‚º nullï¼ˆä¾ config æ±ºå®šï¼‰
                    df = df.with_columns(
                        pl.when(violated_mask)
                        .then(pl.lit(None))
                        .otherwise(pl.col(constraint.target_column))
                        .alias(constraint.target_column)
                    )
                else:
                    flag = 'EQUIPMENT_VIOLATION'
                
                # æ¨™è¨˜é•è¦æ™‚é–“é»çš„ quality_flags
                current_flags = df['quality_flags'].to_list()
                for i, is_violated in enumerate(violated_mask.to_list()):
                    if is_violated:
                        if isinstance(current_flags[i], list):
                            current_flags[i].append(flag)
                        else:
                            current_flags[i] = [flag]
                
                df = df.with_columns(pl.Series('quality_flags', current_flags))
        
        # æ›´æ–°ç¨½æ ¸è»Œè·¡
        self._equipment_validation_audit['constraints_applied'] = [c.constraint_id for c in constraints]
        self._equipment_validation_audit['violations_detected'] = len(violations)
        self._equipment_validation_audit['violation_details'] = violations
        
        if violations:
            self.logger.warning(f"E350: è¨­å‚™é‚è¼¯é æª¢ç™¼ç¾ {len(violations)} é …é•è¦")
        
        return df

    def get_equipment_validation_audit(self) -> dict:
        """
        å–å¾—è¨­å‚™é©—è­‰ç¨½æ ¸è»Œè·¡ï¼ˆä¾› BatchProcessor å¯«å…¥ Manifestï¼‰
        """
        return self._equipment_validation_audit
```

### 13.2 EquipmentValidator å¯¦ä½œ

```python
# src/equipment/equipment_validator.py
class EquipmentValidator:
    """
    è¨­å‚™é‚è¼¯é©—è­‰å™¨ï¼ˆHVAC å°ˆç”¨ï¼‰
    """
    
    def __init__(self, annotation_manager: FeatureAnnotationManager):
        self.annotation_manager = annotation_manager
    
    def check_constraint(
        self, 
        df: pl.DataFrame, 
        constraint: EquipmentConstraint
    ) -> pl.Series:
        """
        æª¢æŸ¥å–®ä¸€ç´„æŸæ¢ä»¶
        
        Returns:
            pl.Series[bool]: é•åç´„æŸçš„é®ç½©ï¼ˆTrue è¡¨ç¤ºé•åï¼‰
        """
        if constraint.check_type == 'requires':
            return self._check_requires(df, constraint)
        elif constraint.check_type == 'mutex':
            return self._check_mutex(df, constraint)
        elif constraint.check_type == 'range_check':
            return self._check_range(df, constraint)
        elif constraint.check_type == 'sequence':
            # Sequence æª¢æŸ¥é€šå¸¸åœ¨ Optimization éšæ®µï¼Œæ­¤è™•ç•¥éæˆ–åšç°¡å–®æª¢æŸ¥
            return pl.Series([False] * len(df))
        else:
            return pl.Series([False] * len(df))
    
    def _check_requires(self, df: pl.DataFrame, constraint: EquipmentConstraint) -> pl.Series:
        """
        æª¢æŸ¥ Requires ç´„æŸï¼ˆå¦‚ä¸»æ©Ÿé–‹å•Ÿæ™‚å¿…é ˆæœ‰æ°´æ³µé‹è½‰ï¼‰
        """
        # å–å¾—è§¸ç™¼æ¢ä»¶æ¬„ä½ï¼ˆå¦‚ chiller_01_statusï¼‰
        trigger_cols = constraint.trigger_status
        
        # æª¢æŸ¥è§¸ç™¼æ¢ä»¶ï¼ˆä»»ä¸€è§¸ç™¼æ¬„ä½ç‚º 1 æˆ– Trueï¼‰
        trigger_condition = pl.lit(False)
        for col in trigger_cols:
            if col in df.columns:
                trigger_condition = trigger_condition | (pl.col(col) == 1)
        
        # æª¢æŸ¥éœ€æ±‚æ¢ä»¶ï¼ˆè‡³å°‘ä¸€éœ€æ±‚æ¬„ä½ç‚º 1ï¼‰
        required_cols = constraint.required_status or []
        required_condition = pl.lit(False)
        for col in required_cols:
            if col in df.columns:
                required_condition = required_condition | (pl.col(col) == 1)
        
        # é•åæ¢ä»¶ï¼šè§¸ç™¼ç‚ºçœŸä½†éœ€æ±‚ç‚ºå‡
        violated = trigger_condition & ~required_condition
        
        return df.select(violated.alias('violated'))['violated']
    
    def _check_mutex(self, df: pl.DataFrame, constraint: EquipmentConstraint) -> pl.Series:
        """
        æª¢æŸ¥äº’æ–¥ç´„æŸï¼ˆå¦‚ä¸»æ©Ÿèˆ‡å‚™ç”¨ä¸»æ©Ÿä¸å¯åŒæ™‚é–‹å•Ÿï¼‰
        """
        mutex_pairs = constraint.mutex_pairs or []
        violated = pl.lit(False)
        
        for pair in mutex_pairs:
            col1, col2 = pair
            if col1 in df.columns and col2 in df.columns:
                # å…©è€…åŒæ™‚ç‚º 1 å³é•å
                both_on = (pl.col(col1) == 1) & (pl.col(col2) == 1)
                violated = violated | both_on
        
        return df.select(violated.alias('violated'))['violated']
    
    def _check_range(self, df: pl.DataFrame, constraint: EquipmentConstraint) -> pl.Series:
        """
        æª¢æŸ¥ç¯„åœç´„æŸï¼ˆå¦‚æº«åº¦å¿…é ˆåœ¨ 4-15Â°C ä¹‹é–“ï¼‰
        """
        target_col = constraint.target_column
        
        if target_col not in df.columns:
            return pl.Series([False] * len(df))
        
        violated = pl.lit(False)
        
        if constraint.min_value is not None:
            violated = violated | (pl.col(target_col) < constraint.min_value)
        
        if constraint.max_value is not None:
            violated = violated | (pl.col(target_col) > constraint.max_value)
        
        return df.select(violated.alias('violated'))['violated']
```

---

## 14. äº¤ä»˜ç‰©æ¸…å–®ï¼ˆv1.3-Completeï¼‰

### 14.1 é…ç½®æ–‡ä»¶æ›´æ–°
1. `config/features/schema.json` - JSON Schema v1.3ï¼ˆå« HVAC æ“´å……èˆ‡ Equipment IDï¼‰
2. `config/features/physical_types.yaml` - 18 å€‹ç‰©ç†é¡å‹å®Œæ•´å®šç¾©
3. `config/features/equipment_taxonomy.yaml` - è¨­å‚™åˆ†é¡æ³•ï¼ˆHVAC å°ˆç”¨ï¼‰
4. `config/features/header_standardization_rules.yaml` - æ¨™é ­æ­£è¦åŒ–è¦å‰‡ï¼ˆRegex å®šç¾©ï¼‰
5. `config/features/sites/*.yaml` - æ¡ˆå ´æ¨™è¨»ï¼ˆå« equipment_constraints å€æ®µï¼‰

### 14.2 Excel å·¥å…·éˆæ›´æ–°
6. `tools/features/templates/Feature_Template_v1.3.xlsx` - ç•¶å‰ç‰ˆæœ¬ï¼ˆå« 11 æ¬„ä½çµæ§‹èˆ‡ System Sheetï¼‰
7. `tools/features/wizard.py` - Wizard CLIï¼ˆå« Header Standardization é è¦½èˆ‡è‡ªå‹•å‚™ä»½ï¼‰
8. `tools/features/excel_to_yaml.py` - è½‰æ›å™¨ï¼ˆå« Checksum è¨ˆç®—èˆ‡ HVAC é‚è¼¯é©—è­‰ï¼‰
9. `tools/features/yaml_to_excel.py` - é€†å‘è½‰æ›ï¼ˆinit/recovery æ¨¡å¼ï¼‰
10. `tools/features/migrate_excel.py` - ç¯„æœ¬å‡ç´šå·¥å…·ï¼ˆv1.2â†’v1.3ï¼‰
11. `tools/features/validators/sync_checker.py` - Excel/YAML åŒæ­¥æª¢æŸ¥ï¼ˆE406 å¯¦ä½œï¼‰

### 14.3 Python API èˆ‡é©—è­‰å™¨
12. `src/features/annotation_manager.py` - FeatureAnnotationManagerï¼ˆå« TemporalContext æ•´åˆï¼‰
13. `src/features/temporal_context.py` - å…¨åŸŸæ™‚é–“åŸºæº–å–®ä¾‹ï¼ˆE000 é˜²è­·ï¼‰
14. `src/features/feature_manifest.py` - Feature Manifest ç”Ÿæˆèˆ‡é©—è­‰ï¼ˆE901-E904ï¼‰
15. `src/features/hvac_validator.py` - HVAC å°ˆç”¨é©—è­‰å™¨ï¼ˆE350-E357ï¼‰
16. `src/features/yaml_write_guard.py` - Import Hook é˜²è­·ï¼ˆE501ï¼‰
17. `src/features/models.py` - Pydantic æ¨¡å‹ï¼ˆColumnAnnotation, EquipmentConstraintï¼‰
18. `src/etl/header_standardizer.py` - CSV æ¨™é ­æ­£è¦åŒ–å¯¦ä½œï¼ˆE105ï¼‰
19. `src/equipment/equipment_validator.py` - è¨­å‚™é‚è¼¯é©—è­‰å™¨ï¼ˆE350 å¯¦ä½œï¼‰

### 14.4 SSOT å¸¸æ•¸å®šç¾©
20. `src/etl/config_models.py` - æ›´æ–°åŒ…å«ï¼š
    - `VALID_QUALITY_FLAGS` èˆ‡ç‰ˆæœ¬è™Ÿ
    - `HEADER_STANDARDIZATION_RULES`ï¼ˆRegex åˆ—è¡¨ï¼‰
    - `EQUIPMENT_VALIDATION_CONSTRAINTS`ï¼ˆè¨­å‚™é™åˆ¶ SSOTï¼‰
    - `TEMPORAL_BASELINE_CONFIG`ï¼ˆæ™‚é–“åŸºæº–è¨­å®šï¼‰

### 14.5 æ¸¬è©¦èˆ‡æ–‡ä»¶
21. `tests/features/test_temporal_baseline.py` - æ™‚é–“åŸºæº–æ¸¬è©¦ï¼ˆE000, E000-Wï¼‰
22. `tests/features/test_header_standardization.py` - æ¨™é ­æ­£è¦åŒ–æ¸¬è©¦ï¼ˆE105, E409ï¼‰
23. `tests/features/test_feature_alignment.py` - ç‰¹å¾µå°é½Šæ¸¬è©¦ï¼ˆE901-E904ï¼‰
24. `tests/features/test_hvac_constraints.py` - HVAC äº’é–é‚è¼¯æ¸¬è©¦ï¼ˆE350-E357ï¼‰
25. `tests/features/test_equipment_sync.py` - Cleaner èˆ‡ Optimization åŒæ­¥æ¸¬è©¦
26. `docs/features/PRD_Feature_Annotation_v1.3_Complete.md` - æœ¬æ–‡ä»¶

---

## 15. é©—æ”¶ç°½æ ¸ï¼ˆv1.3-Completeï¼‰

### 15.1 åŸºç¤æµç¨‹é©—æ”¶
- [ ] **å–®å‘æµç¨‹**: Wizard åƒ…æ›´æ–° Excelï¼Œç„¡æ³•ç›´æ¥å¯«å…¥ YAMLï¼ˆæŠ€è¡“é˜»æ“‹ E501ï¼‰
- [ ] **ç‰ˆæœ¬æ§åˆ¶**: Excel ä¿®æ”¹å¾Œæœªé‡æ–°ç”Ÿæˆ YAMLï¼ŒåŸ·è¡Œ Pipeline æ™‚æ­£ç¢ºå ±éŒ¯ E406
- [ ] **å‚™ä»½æ©Ÿåˆ¶**: Wizard åŸ·è¡Œæ™‚æ­£ç¢ºç”Ÿæˆ `.backups/` æª”æ¡ˆï¼Œä¿ç•™æœ€è¿‘ 10 å€‹ç‰ˆæœ¬
- [ ] **ç½é›£æ¢å¾©**: å¯é€é `yaml_to_excel --mode recovery` å¾ Git æ­·å²ç‰ˆæœ¬é‡å»º Excel

### 15.2 Header Standardization é©—æ”¶
- [ ] **Regex è¦å‰‡**: `Chiller 1 Temp` æ­£ç¢ºè½‰æ›ç‚º `chiller_1_temp`
- [ ] **é‡è¤‡æª¢æ¸¬**: æ­£è¦åŒ–å¾Œç”¢ç”Ÿé‡è¤‡æ¨™é ­æ™‚æ­£ç¢ºæ‹‹å‡º E105
- [ ] **E409 é©—è­‰**: CSV æ¨™é ­æ­£è¦åŒ–å¾Œèˆ‡ Annotation ä¸åŒ¹é…æ™‚æ­£ç¢ºå ±éŒ¯
- [ ] **Wizard é è¦½**: Wizard é¡¯ç¤ºæ¨™é ­è½‰æ›é è¦½ï¼Œä¾›ä½¿ç”¨è€…ç¢ºèª

### 15.3 Temporal Baseline é©—æ”¶
- [ ] **E000 é˜²è­·**: Pipeline å•Ÿå‹•æ™‚æ­£ç¢ºå»ºç«‹ TemporalContextï¼Œæœªå»ºç«‹æ™‚å ±éŒ¯
- [ ] **E102 é˜²è­·**: è³‡æ–™æ™‚é–“è¶…éåŸºæº–+5åˆ†é˜æ™‚æ­£ç¢ºæ‹’çµ•
- [ ] **E000-W è­¦å‘Š**: Pipeline åŸ·è¡Œè¶…é 1 å°æ™‚æ™‚æ­£ç¢ºç™¼å‡ºæ™‚é–“æ¼‚ç§»è­¦å‘Š
- [ ] **è·¨æ—¥åŸ·è¡Œ**: 00:00 å‰å¾ŒåŸ·è¡Œæ™‚æ™‚é–“è¨ˆç®—æ­£ç¢ºï¼Œç„¡é‚è¼¯éŒ¯èª¤

### 15.4 Feature Alignment é©—æ”¶
- [ ] **E901**: ç‰¹å¾µé †åºéŒ¯èª¤æ™‚æ­£ç¢ºæ‹’çµ•ï¼ˆå«è©³ç´°å·®ç•°è³‡è¨Šï¼‰
- [ ] **E902**: ç‰¹å¾µç¶­åº¦ä¸åŒ¹é…æ™‚æ­£ç¢ºæ‹’çµ•
- [ ] **E903**: Scaler Parameters é †åºä¸ä¸€è‡´æ™‚æ­£ç¢ºæ‹’çµ•
- [ ] **Feature Manifest**: Training éšæ®µæ­£ç¢ºè¼¸å‡º feature_manifest.json
- [ ] **é›œæ¹Šé©—è­‰**: ç‰¹å¾µåˆ—è¡¨é›œæ¹Šå€¼è¨ˆç®—èˆ‡é©—è­‰æ­£ç¢º

### 15.5 HVAC å°ˆç”¨é©—æ”¶
- [ ] **è¨­å‚™äº’é–**: ä¸»æ©Ÿé–‹å•Ÿä½†æ°´æ³µé—œé–‰æ™‚ï¼Œæ­£ç¢ºè§¸ç™¼ E350 ä¸¦æ¨™è¨˜ PHYSICAL_IMPOSSIBLE
- [ ] **å–®èª¿æ€§æª¢æŸ¥**: é›»è¡¨è®€æ•¸éæ¸›æ™‚æ­£ç¢ºè§¸ç™¼ E351ï¼Œå…è¨± 1% ç²¾åº¦èª¤å·®
- [ ] **æ•ˆç‡ç¯„åœ**: COP < 2 æˆ– > 8 æ™‚æ­£ç¢ºè§¸ç™¼ E352ï¼ˆWarningï¼‰
- [ ] **ä½æº«å·®ç—‡å€™ç¾¤**: å†°æ°´é€²å›æ°´æº«å·® < 1Â°C æ™‚æ­£ç¢ºè§¸ç™¼ E353ï¼ˆWarningï¼‰
- [ ] **Equipment ID**: æ¬„ä½èˆ‡è¨­å‚™ ID æ˜ å°„æ­£ç¢ºï¼Œæ”¯æ´äº’é–æŸ¥è©¢
- [ ] **E904**: è¨­å‚™é™åˆ¶ä¸ä¸€è‡´æ™‚æ­£ç¢ºæ‹’çµ•ï¼ˆTraining vs Optimizationï¼‰

### 15.6 éŒ¯èª¤ä»£ç¢¼æ”¶æ–‚é©—æ”¶ï¼ˆå°é½Š Interface Contract v1.1ï¼‰
- [ ] **E000-E000-W**: æ™‚é–“åŸºæº–éŒ¯èª¤æ­£ç¢ºå°æ‡‰
- [ ] **E105**: Header Standardization å¤±æ•—æ­£ç¢ºå°æ‡‰
- [ ] **E350-E357**: Equipment Validation éŒ¯èª¤æ­£ç¢ºå°æ‡‰ï¼ˆE354/E355 ç‚ºé€šç”¨ç´„æŸï¼‰
- [ ] **E400-E409**: Feature Annotation éŒ¯èª¤æ­£ç¢ºå°æ‡‰
- [ ] **E500-E501**: Governance éŒ¯èª¤æ­£ç¢ºå°æ‡‰
- [ ] **E901-E904**: è·¨éšæ®µæ•´åˆéŒ¯èª¤æ­£ç¢ºå°æ‡‰

---

**ç°½æ ¸æ¬„**ï¼š
- [ ] æ¶æ§‹å¸«ç¢ºèªï¼šæª¢æŸ¥é»å®šç¾©æ¶µè“‹æ‰€æœ‰æ¨¡çµ„é–“ä»‹é¢ï¼ˆå« Training-Optimization èˆ‡ Equipment Validation Syncï¼‰
- [ ] æŠ€è¡“è² è²¬äººç¢ºèªï¼šéŒ¯èª¤ä»£ç¢¼åˆ†å±¤ E000-E999 ç„¡è¡çªï¼Œèˆ‡ Interface Contract v1.1 å®Œå…¨ä¸€è‡´
- [ ] HVAC é ˜åŸŸå°ˆå®¶ç¢ºèªï¼šè¨­å‚™äº’é–é‚è¼¯ç¬¦åˆç‰©ç†å¯¦å‹™ï¼Œå‘½åè¦ç¯„ç¬¦åˆæ¥­ç•Œæ…£ä¾‹
- [ ] ç¶­é‹è² è²¬äººç¢ºèªï¼šç‰ˆæœ¬ç›¸å®¹æ€§çŸ©é™£å¯æŒ‡å°éƒ¨ç½²æ±ºç­–ï¼Œæ™‚é–“ä¸€è‡´æ€§æ©Ÿåˆ¶å¯é˜²æ­¢è·¨æ—¥åŸ·è¡ŒéŒ¯èª¤
- [ ] Product Manager ç¢ºèªï¼šå–®å‘æµç¨‹ç®¡æ§ï¼ˆExcelâ†’YAMLï¼‰ç¢ºä¿è³‡æ–™ä¸€è‡´æ€§ï¼Œç½é›£æ¢å¾©æ©Ÿåˆ¶å®Œæ•´

---