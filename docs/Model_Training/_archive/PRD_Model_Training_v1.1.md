# PRD v1.1: æ¨¡å‹è¨“ç·´ç®¡ç·šå¯¦ä½œæŒ‡å— (Model Training Pipeline Implementation Guide)

**æ–‡ä»¶ç‰ˆæœ¬:** v1.1 (Production-Ready Multi-Model Ensemble with Resource Safety)  
**æ—¥æœŸ:** 2026-02-13  
**è² è²¬äºº:** Oscar Chang  
**ç›®æ¨™æ¨¡çµ„:** `src/modeling/training_pipeline.py`, `src/modeling/trainers/`, `src/modeling/hyperparameter/`, `src/modeling/explainability/`  
**ä¸Šæ¸¸å¥‘ç´„:** `src/etl/feature_engineer.py` (v1.3-FA+, æª¢æŸ¥é» #4)  
**ä¸‹æ¸¸å¥‘ç´„:** `src/optimization/engine.py` (v1.0+, è¼¸å…¥æª¢æŸ¥é»)  
**æ”¯æ´æ¨¡å‹:** 
- **XGBoost** (Extreme Gradient Boosting) - é«˜ç²¾åº¦ã€æ­£å‰‡åŒ–å¼·
- **LightGBM** (Light Gradient Boosting Machine) - å¤§è¦æ¨¡è³‡æ–™ã€è¨“ç·´æ¥µé€Ÿ  
- **Random Forest** (Bagging Ensemble) - é«˜é²æ£’æ€§ã€æŠ—éæ“¬åˆã€åŸºæº–æ¨¡å‹  
**é ä¼°å·¥æ™‚:** 8 ~ 9 å€‹å·¥ç¨‹å¤©ï¼ˆå«è³‡æºç®¡ç†ã€è¶…åƒæ•¸æœå°‹æ¶æ§‹ã€å¯è§£é‡‹æ€§é ç•™ï¼‰

---

## 1. åŸ·è¡Œç¸½ç¶±èˆ‡è¨­è¨ˆå“²å­¸

### 1.1 æ ¸å¿ƒç›®æ¨™

å»ºç«‹**ç”Ÿç”¢å°±ç·’ (Production-Ready)**ã€**è³‡æºæ„ŸçŸ¥ (Resource-Aware)**ã€**å¤šæ¨¡å‹å¹³è¡Œè¨“ç·´ (Multi-Model Training)** çš„è¨“ç·´ç®¡ç·šï¼š

1. **å‹•æ…‹è³‡æºç®¡ç†**: è‡ªå‹•æª¢æ¸¬è¨˜æ†¶é«”å®¹é‡ï¼Œé˜²æ­¢å¹³è¡Œè¨“ç·´å°è‡´ OOMï¼Œä¸ç©©å®šç’°å¢ƒè‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´
2. **ä¸‰æ¨¡å‹æ™ºæ…§èª¿åº¦**: ä¾è³‡æ–™è¦æ¨¡è‡ªå‹•ç¯©é¸å¯ç”¨æ¨¡å‹ï¼ˆä¾‹å¦‚å°æ¨£æœ¬æ™‚è‡ªå‹•ç¦ç”¨ LightGBMï¼‰ï¼Œé¿å…éæ“¬åˆ
3. **é›¶è³‡æ–™æ´©æ¼ (Zero Data Leakage)**: åš´æ ¼éµå®ˆ `temporal_cutoff`ï¼Œè¨“ç·´è³‡æ–™çµ•ä¸åŒ…å«é©—è­‰/æ¸¬è©¦æœŸçš„æœªä¾†è³‡è¨Š
4. **åˆ†å±¤è¶…åƒæ•¸å„ªåŒ–**: å€åˆ†ã€Œæ—¥é–“å¿«é€Ÿè¨“ç·´ã€èˆ‡ã€Œå¤œé–“æ·±åº¦å„ªåŒ–ã€æ¨¡å¼ï¼Œæ”¯æ´æ–·é»çºŒå‚³èˆ‡ Trial Pruning
5. **å¯è§£é‡‹æ€§é ç•™ (Explainability Ready)**: v1.1 é ç•™ SHAP æ•´åˆä»‹é¢ï¼Œæ”¯æ´å–®ç­†é æ¸¬æ­¸å› èˆ‡æ™‚é–“åºåˆ—ç‰¹å¾µè²¢ç»è¿½è¹¤
6. **ç‰ˆæœ¬å¯è¿½æº¯ (Version Traceability)**: æ¯å€‹è¨“ç·´ç”¢å‡ºçš„æ¨¡å‹å¿…é ˆç¶å®šç•¶æ™‚çš„ `schema_version`ã€`inheritance_chain` èˆ‡ `yaml_checksum`

### 1.2 ä¸‰æ¨¡å‹ç‰¹æ€§æ¯”è¼ƒèˆ‡é©ç”¨å ´æ™¯

| æ¨¡å‹ | æ¼”ç®—æ³•é¡å‹ | å„ªå‹¢ | æœ€ä½³é©ç”¨å ´æ™¯ | æœ€å°æ¨£æœ¬æ•¸ | ç‰¹å¾µé‡è¦æ€§ |
|:---|:---:|:---|:---|:---:|:---|
| **XGBoost** | Gradient Boosting (Level-wise) | ç²¾åº¦æ¥µé«˜ã€æ­£å‰‡åŒ–å¼·ã€ä¸æ˜“éæ“¬åˆ | ä¸­ç­‰è³‡æ–™é‡ (500~100è¬ç­†)ã€é«˜ç¶­åº¦ç‰¹å¾µ | 500 | Gain-based |
| **LightGBM** | Gradient Boosting (Leaf-wise) | è¨“ç·´é€Ÿåº¦æ¥µå¿«ã€è¨˜æ†¶é«”æ•ˆç‡é«˜ | å¤§è¦æ¨¡è³‡æ–™ (>10,000ç­†)ã€å³æ™‚è¨“ç·´éœ€æ±‚ | 1,000 | Split-based |
| **Random Forest** | Bagging (Parallel Trees) | æ¥µé«˜é²æ£’æ€§ã€å¤©ç„¶æ”¯æ´å¹³è¡Œé‹ç®—ã€å°ç•°å¸¸å€¼ä¸æ•æ„Ÿ | å¿«é€ŸåŸºå‡†æ¸¬è©¦ã€å°æ¨£æœ¬ (<500)ã€å«å™ªéŸ³è³‡æ–™ | 100 | Mean Decrease Impurity |

**å‹•æ…‹é¸æ“‡ç­–ç•¥**: 
- æ¨£æœ¬æ•¸ < 500ï¼šåƒ…å•Ÿç”¨ Random Forest èˆ‡ XGBoostï¼ˆé™åˆ¶æ·±åº¦ï¼‰
- æ¨£æœ¬æ•¸ 500~1,000ï¼šå•Ÿç”¨ XGBoost èˆ‡ Random Forestï¼Œç¦ç”¨ LightGBM
- æ¨£æœ¬æ•¸ > 1,000ï¼šä¸‰æ¨¡å‹å…¨å•Ÿç”¨ï¼Œä¾ Val RÂ² è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹æˆ–ä¿ç•™ Ensemble

---

## 2. ä»‹é¢å¥‘ç´„è¦ç¯„ (Interface Contracts)

### 2.1 è¼¸å…¥å¥‘ç´„ (Input Contract from Feature Engineer v1.3)

**æª¢æŸ¥é» #7: Feature Engineer â†’ Model Training**

```python
class TrainingInputContract(BaseModel):
    """æ¨¡å‹è¨“ç·´è¼¸å…¥è³‡æ–™è¦ç¯„"""
    
    # 1. ç‰¹å¾µçŸ©é™£ (ä¾†è‡ª Feature Engineer)
    feature_matrix: pl.DataFrame
    
    # 2. ç›®æ¨™è®Šæ•¸è³‡è¨Š
    target_variable: str
    target_metadata: FeatureMetadata
    
    # 3. æ™‚é–“æˆ³è¨˜
    timestamp_col: str = "timestamp"
    time_range: Dict[str, str]
    
    # 4. Annotation ä¸Šä¸‹æ–‡ï¼ˆç‰ˆæœ¬ç¶å®šï¼‰
    annotation_context: Dict = {
        "schema_version": "1.2",
        "inheritance_chain": "base -> cgmh_ty",
        "yaml_checksum": "sha256:abc123...",
        "group_policies_applied": ["chillers", "towers"],
        "feature_engineer_version": "1.3-FA"
    }
    
    # 5. ç‰¹å¾µå…ƒè³‡æ–™ï¼ˆä¸å« device_roleï¼‰
    feature_metadata: Dict[str, FeatureMetadata]
    
    # 6. Quality Flag ç‰¹å¾µåˆ—è¡¨
    quality_flag_features: List[str]
    
    # 7. é˜² Data Leakage è³‡è¨Š
    train_test_split_info: Dict = {
        "temporal_cutoff": "2025-10-01T00:00:00Z",
        "strict_past_only": True
    }
    
    # 8. æ¨£æœ¬æ¬Šé‡å»ºè­°ï¼ˆå¯é¸ï¼‰
    suggested_sample_weights: Optional[pl.Series] = None
    
    # 9. è³‡æ–™è¦æ¨¡æ¨™è¨˜ï¼ˆç”¨æ–¼æ¨¡å‹é¸æ“‡å»ºè­°ï¼‰
    n_samples: int
    n_features: int
```

| æª¢æŸ¥é … | è¦æ ¼ | éŒ¯èª¤ä»£ç¢¼ | è™•ç† |
|:---|:---|:---:|:---|
| **Annotation Context å­˜åœ¨æ€§** | å¿…é ˆéç©ºä¸”åŒ…å« `schema_version`, `inheritance_chain`, `yaml_checksum` | E601 | æ‹’çµ•è¨“ç·´ |
| **Schema ç‰ˆæœ¬ç›¸å®¹** | `schema_version` å¿…é ˆç­‰æ–¼ç•¶å‰ `FEATURE_ANNOTATION_CONSTANTS['expected_schema_version']` | E602 | æ‹’çµ•è¨“ç·´ |
| **ç›®æ¨™è®Šæ•¸å­˜åœ¨** | `target_variable` å¿…é ˆå­˜åœ¨æ–¼ `feature_matrix` æ¬„ä½ä¸­ | E603 | æ‹’çµ•è¨“ç·´ |
| **æ™‚é–“æˆ³å‹åˆ¥** | `timestamp` å¿…é ˆç‚º `Datetime(ns, UTC)` | E604 | æ‹’çµ•è¨“ç·´ |
| **è³‡æ–™è¦æ¨¡æª¢æŸ¥** | `n_samples` å¿…é ˆ >= 100ï¼ˆRandom Forest æœ€ä½éœ€æ±‚ï¼‰ | E607 | æ‹’çµ•è¨“ç·´ |

---

## 3. åˆ†éšæ®µå¯¦ä½œè¨ˆç•« (Phase-Based Implementation)

### Phase 0: åŸºç¤å»ºè¨­èˆ‡å¤šæ¨¡å‹æ¶æ§‹ (Day 1-2)

#### Step 0.1: çµ±ä¸€è¨“ç·´é…ç½®æ¨¡å‹ï¼ˆå‹•æ…‹è³‡æºæ„ŸçŸ¥ç‰ˆï¼‰

**æª”æ¡ˆ**: `src/modeling/config_models.py`

**å¯¦ä½œå…§å®¹**:
```python
from typing import Dict, List, Optional, Literal, Final, Union, Tuple
from pydantic import BaseModel, Field, validator, root_validator
from datetime import datetime
import logging

from src.etl.config_models import (
    VALID_QUALITY_FLAGS,
    TIMESTAMP_CONFIG,
    FEATURE_ANNOTATION_CONSTANTS
)

EXPECTED_SCHEMA_VERSION: Final[str] = FEATURE_ANNOTATION_CONSTANTS['expected_schema_version']

# ==========================================
# æ¨¡å‹ç‰¹å®šè¶…åƒæ•¸é…ç½®
# ==========================================

class XGBoostConfig(BaseModel):
    """XGBoost å°ˆå±¬é…ç½® - Level-wise ç”Ÿé•·ç­–ç•¥ï¼Œç²¾åº¦å°å‘"""
    n_estimators: int = 1000
    learning_rate: float = 0.05
    max_depth: int = 6
    min_child_weight: int = 1
    subsample: float = 0.8
    colsample_bytree: float = 0.8
    reg_alpha: float = 0.1  # L1 æ­£å‰‡
    reg_lambda: float = 1.0  # L2 æ­£å‰‡
    gamma: float = 0  # ç¯€é»åˆ†è£‚æœ€å°æå¤±æ¸›å°‘
    early_stopping_rounds: int = 50
    eval_metric: str = "rmse"
    tree_method: str = "hist"  # 'exact', 'approx', 'hist'
    
    # å°æ¨£æœ¬é©æ‡‰ï¼ˆç•¶ n_samples < 500 æ™‚è‡ªå‹•èª¿æ•´ï¼‰
    small_sample_adjustments: Dict[str, Any] = {
        "max_depth": 3,
        "min_child_weight": 5,
        "subsample": 0.9
    }
    
    # é€²éšåŠŸèƒ½
    enable_monotonic_constraints: bool = False
    monotone_constraints: Optional[Dict[str, int]] = None

class LightGBMConfig(BaseModel):
    """LightGBM å°ˆå±¬é…ç½® - Leaf-wise ç”Ÿé•·ç­–ç•¥ï¼Œé€Ÿåº¦å°å‘"""
    n_estimators: int = 1000
    learning_rate: float = 0.05
    num_leaves: int = 31  # æ§åˆ¶æ¨¡å‹è¤‡é›œåº¦ï¼Œç›¸ç•¶æ–¼ 2^max_depth
    max_depth: int = -1  # -1 è¡¨ç¤ºç„¡é™åˆ¶ï¼Œç”± num_leaves æ§åˆ¶
    min_child_samples: int = 20
    subsample: float = 0.8
    colsample_bytree: float = 0.8
    reg_alpha: float = 0.1
    reg_lambda: float = 1.0
    early_stopping_rounds: int = 50
    eval_metric: str = "rmse"
    boosting_type: str = "gbdt"  # 'gbdt', 'dart', 'goss'
    
    # å¤§è¦æ¨¡è³‡æ–™å„ªåŒ–
    feature_pre_filter: bool = False
    histogram_pool_size: Optional[int] = None  # è¨˜æ†¶é«”é™åˆ¶æ™‚è¨­å®š

class RandomForestConfig(BaseModel):
    """Random Forest å°ˆå±¬é…ç½® - Bagging ç­–ç•¥ï¼Œé²æ£’æ€§å°å‘"""
    n_estimators: int = 500
    max_depth: Optional[int] = None  # None è¡¨ç¤ºå®Œå…¨ç”Ÿé•·
    min_samples_split: int = 5
    min_samples_leaf: int = 2
    max_features: str = "sqrt"  # 'sqrt', 'log2', None
    bootstrap: bool = True
    oob_score: bool = True  # Out-of-Bag é©—è­‰
    n_jobs: int = -1  # ä½¿ç”¨æ‰€æœ‰ CPU
    warm_start: bool = False  # å¯å¢é‡è¨“ç·´ï¼ˆv1.2 ä½¿ç”¨ï¼‰
    
    # å€é–“é æ¸¬ï¼ˆä½¿ç”¨æ¨¹çš„è‘‰ç¯€é»çµ±è¨ˆï¼‰
    quantile_regression: bool = False  # è‹¥å•Ÿç”¨ï¼Œè¨“ç·´ä¸‰å€‹æ¨¡å‹ (Q10, Q50, Q90)

# ==========================================
# è³‡æºç®¡ç†é…ç½®
# ==========================================

class ResourceConfig(BaseModel):
    """ç¡¬é«”è³‡æºèˆ‡è¨˜æ†¶é«”ç®¡ç†é…ç½®"""
    
    # è¨˜æ†¶é«”å®‰å…¨é–¾å€¼
    memory_safety_threshold: float = 0.3  # ä¿ç•™ 30% ç³»çµ±è¨˜æ†¶é«”ä½œç‚ºç·©è¡
    parallel_training: bool = True  # æ˜¯å¦å˜—è©¦ä¸¦è¡Œè¨“ç·´
    max_parallel_workers: int = 3  # æœ€å¤§å¹³è¡Œå·¥ä½œé€²ç¨‹
    
    # å‹•æ…‹é™ç´šç­–ç•¥
    auto_fallback_to_sequential: bool = True  # è¨˜æ†¶é«”ä¸è¶³æ™‚è‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´
    memory_check_before_training: bool = True  # è¨“ç·´å‰å¼·åˆ¶æª¢æŸ¥è¨˜æ†¶é«”
    
    # å°æ¨£æœ¬è™•ç†
    small_sample_fallback: Literal['disable_lightgbm', 'use_rf_only', 'abort'] = 'disable_lightgbm'
    
    @validator('memory_safety_threshold')
    def validate_threshold(cls, v):
        if not 0.1 <= v <= 0.8:
            raise ValueError("è¨˜æ†¶é«”å®‰å…¨é–¾å€¼å¿…é ˆåœ¨ 0.1~0.8 ä¹‹é–“")
        return v

# ==========================================
# è¨“ç·´ç®¡ç·šä¸»é…ç½®
# ==========================================

class ModelTrainingConfig(BaseModel):
    """æ¨¡å‹è¨“ç·´çµ±ä¸€é…ç½®ï¼ˆv1.1 è³‡æºæ„ŸçŸ¥ç‰ˆï¼‰"""
    
    # åŸºæœ¬é…ç½®
    random_state: int = 42
    
    # æ™‚åºé…ç½®
    temporal_split: TemporalSplitConfig = TemporalSplitConfig()
    
    # Device Role è™•ç†
    device_role_handling: DeviceRoleHandlingConfig = DeviceRoleHandlingConfig()
    
    # ç‰¹å¾µå·¥ç¨‹ï¼ˆè¨“ç·´æœŸï¼‰
    handle_missing_values: Literal["drop", "impute_mean", "impute_median"] = "impute_median"
    scale_features: bool = True
    
    # Quality Flags è™•ç†
    use_quality_flags_as_features: bool = True
    exclude_bad_quality_samples: bool = True
    
    # ä¸‰æ¨¡å‹é…ç½®
    xgboost: XGBoostConfig = XGBoostConfig()
    lightgbm: LightGBMConfig = LightGBMConfig()
    random_forest: RandomForestConfig = RandomForestConfig()
    
    # è³‡æºç®¡ç†ï¼ˆv1.1 æ–°å¢ï¼‰
    resource: ResourceConfig = ResourceConfig()
    
    # æ¨¡å‹ç‰¹å®šæœ€å°æ¨£æœ¬æ•¸é–¾å€¼ï¼ˆä¾æ¼”ç®—æ³•ç‰¹æ€§å€åˆ†ï¼‰
    min_samples_threshold: Dict[str, int] = {
        'random_forest': 100,
        'xgboost': 500,
        'lightgbm': 1000
    }
    
    # è¶…åƒæ•¸æœå°‹ï¼ˆå¤œé–“æ¨¡å¼ï¼‰
    enable_hyperparameter_search: bool = False
    hyperparameter_mode: Literal['disabled', 'daytime_quick', 'overnight_deep'] = 'disabled'
    hyperparameter_trials: int = 50
    hyperparameter_timeout: int = 3600  # ç§’
    hyperparameter_storage: str = "optuna_studies.db"  # SQLite å„²å­˜è·¯å¾‘
    
    # å¯è§£é‡‹æ€§ï¼ˆv1.1 é ç•™ï¼‰
    enable_explainability: bool = False  # æ˜¯å¦å•Ÿç”¨ SHAP
    shap_background_samples: int = 100   # SHAP èƒŒæ™¯è³‡æ–™å–æ¨£æ•¸
    
    # è¼¸å‡º
    model_output_dir: str = "models/trained"
    metadata_output_dir: str = "models/metadata"
    
    @validator('device_role_handling')
    def validate_no_feature_leakage(cls, v):
        if v.use_as_feature:
            raise ValueError("E701: device_role ç¦æ­¢ä½œç‚ºç›´æ¥ç‰¹å¾µè¼¸å…¥")
        return v
    
    def get_eligible_models(self, n_samples: int) -> List[str]:
        """
        ä¾æ¨£æœ¬æ•¸å‹•æ…‹æ±ºå®šå¯ç”¨æ¨¡å‹åˆ—è¡¨
        å›å‚³: ['random_forest', 'xgboost', 'lightgbm'] çš„å­é›†
        """
        eligible = []
        logger = logging.getLogger(__name__)
        
        for model_name, threshold in self.min_samples_threshold.items():
            if n_samples >= threshold:
                eligible.append(model_name)
            else:
                logger.warning(
                    f"âš ï¸ æ¨£æœ¬æ•¸ {n_samples} ä½æ–¼ {model_name} é–€æª» ({threshold})ï¼Œå·²æ’é™¤"
                )
        
        if not eligible:
            raise ValueError(f"E607: æ¨£æœ¬æ•¸ {n_samples} ä½æ–¼æ‰€æœ‰æ¨¡å‹æœ€ä½è¦æ±‚")
        
        # æ‡‰ç”¨å°æ¨£æœ¬é™ç´šç­–ç•¥
        if n_samples < self.min_samples_threshold['lightgbm']:
            if self.resource.small_sample_fallback == 'disable_lightgbm':
                eligible = [m for m in eligible if m != 'lightgbm']
            elif self.resource.small_sample_fallback == 'use_rf_only':
                eligible = ['random_forest']
        
        return eligible
    
    def adjust_for_small_sample(self, model_name: str, n_samples: int) -> BaseModel:
        """å–å¾—é‡å°å°æ¨£æœ¬èª¿æ•´å¾Œçš„æ¨¡å‹é…ç½®"""
        config = getattr(self, model_name)
        
        if model_name == 'xgboost' and n_samples < 500:
            # æ‡‰ç”¨å°æ¨£æœ¬èª¿æ•´
            adjusted = config.copy()
            for key, val in config.small_sample_adjustments.items():
                setattr(adjusted, key, val)
            return adjusted
        
        return config
```

#### Step 0.2: å¤šæ¨¡å‹è¨“ç·´å™¨åŸºç¤é¡åˆ¥ï¼ˆå¢é‡å­¸ç¿’é ç•™ï¼‰

**æª”æ¡ˆ**: `src/modeling/trainers/base_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Tuple, Optional, List
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

class BaseModelTrainer(ABC):
    """
    æ¨¡å‹è¨“ç·´å™¨æŠ½è±¡åŸºç¤é¡åˆ¥ (v1.1)
    æ”¯æ´å¸¸è¦è¨“ç·´ã€å¢é‡å­¸ç¿’é ç•™ã€ä»¥åŠå¯è§£é‡‹æ€§ä»‹é¢
    """
    
    def __init__(self, config: Any, random_state: int = 42):
        self.config = config
        self.random_state = random_state
        self.model = None
        self.feature_importance = {}
        self.training_history = {}
        self.is_fitted = False
        
        # v1.1 æ–°å¢ï¼šæ¨¡å‹å…ƒè³‡è¨Š
        self.model_metadata = {
            'trainer_version': '1.1',
            'supports_incremental': False,  # å­é¡å¯è¦†å¯«
            'supports_explainability': False  # å­é¡å¯è¦†å¯«
        }
    
    @abstractmethod
    def train(
        self, 
        X_train: np.ndarray, 
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œæ¨¡å‹è¨“ç·´
        
        Returns:
            Dict åŒ…å«:
            - model: è¨“ç·´å¥½çš„æ¨¡å‹ç‰©ä»¶
            - best_iteration: æœ€ä½³è¿­ä»£æ¬¡æ•¸ï¼ˆæ¢¯åº¦æå‡é¡ï¼‰
            - training_history: è¨“ç·´éç¨‹æŒ‡æ¨™
            - feature_importance: ç‰¹å¾µé‡è¦æ€§å­—å…¸
            - oob_score: Out-of-Bag åˆ†æ•¸ï¼ˆè‹¥æœ‰ï¼‰
        """
        pass
    
    def partial_fit(self, X_new: np.ndarray, y_new: np.ndarray, 
                    sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        å¢é‡å­¸ç¿’ä»‹é¢ï¼ˆv1.2 å¯¦ä½œï¼Œv1.1 é ç•™ï¼‰
        
        Raises:
            NotImplementedError: è‹¥æ¨¡å‹ä¸æ”¯æ´å¢é‡å­¸ç¿’
        """
        raise NotImplementedError(
            f"{self.__class__.__name__} ä¸æ”¯æ´å¢é‡å­¸ç¿’ï¼ˆpartial_fitï¼‰"
        )
    
    @abstractmethod
    def predict(self, X: np.ndarray) -> np.ndarray:
        """åŸ·è¡Œé æ¸¬"""
        pass
    
    @abstractmethod
    def get_feature_importance(self) -> Dict[str, float]:
        """å–å¾—æ¨™æº–åŒ–ç‰¹å¾µé‡è¦æ€§ï¼ˆç¸½å’Œç‚º1ï¼‰"""
        pass
    
    def evaluate(self, X: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:
        """çµ±ä¸€è©•ä¼°æŒ‡æ¨™"""
        y_pred = self.predict(X)
        
        # é˜²æ­¢é™¤ä»¥é›¶ï¼ˆMAPEï¼‰
        mape_mask = y_true != 0
        mape = np.mean(np.abs((y_true[mape_mask] - y_pred[mape_mask]) / y_true[mape_mask])) * 100 if np.any(mape_mask) else float('inf')
        
        return {
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'mae': mean_absolute_error(y_true, y_pred),
            'r2': r2_score(y_true, y_pred),
            'mape': mape
        }
    
    def get_model_info(self) -> Dict[str, Any]:
        """å–å¾—æ¨¡å‹å…ƒè³‡è¨Šï¼ˆç”¨æ–¼æ—¥èªŒèˆ‡å„²å­˜ï¼‰"""
        return {
            'trainer_class': self.__class__.__name__,
            'is_fitted': self.is_fitted,
            'supports_incremental': self.model_metadata['supports_incremental'],
            'supports_explainability': self.model_metadata['supports_explainability'],
            'config': self.config.dict() if hasattr(self.config, 'dict') else str(self.config)
        }
```

---

### Phase 1: ä¸‰æ¨¡å‹å…·é«”å¯¦ä½œ (Day 3-4)

#### Step 1.1: XGBoost è¨“ç·´å™¨å¯¦ä½œï¼ˆå°æ¨£æœ¬é©æ‡‰ï¼‰

**æª”æ¡ˆ**: `src/modeling/trainers/xgboost_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
import xgboost as xgb
import numpy as np
from typing import Dict, Any, Optional, List
from src.modeling.trainers.base_trainer import BaseModelTrainer

class XGBoostTrainer(BaseModelTrainer):
    """
    XGBoost è¨“ç·´å™¨å¯¦ä½œ (v1.1)
    
    ç‰¹æ€§:
    - Level-wise æ¨¹ç”Ÿé•·ï¼ˆå¹³è¡¡æ¨¹æ·±åº¦ï¼‰
    - å…§å»ºæ—©åœæ©Ÿåˆ¶ (Early Stopping)
    - æ”¯æ´æ¨£æœ¬æ¬Šé‡ (Sample Weight)
    - å°æ¨£æœ¬è‡ªå‹•èª¿æ•´ï¼ˆmax_depth é™åˆ¶ï¼‰
    - v1.2 é ç•™ï¼šæ”¯æ´ xgb_model æ¥çºŒè¨“ç·´ï¼ˆå¢é‡å­¸ç¿’ï¼‰
    """
    
    def __init__(self, config: XGBoostConfig, random_state: int = 42):
        super().__init__(config, random_state)
        self.model_metadata['supports_explainability'] = True  # TreeSHAP æ”¯æ´
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None,
        xgb_model: Optional[Any] = None  # v1.2 å¢é‡å­¸ç¿’é ç•™
    ) -> Dict[str, Any]:
        """åŸ·è¡Œ XGBoost è¨“ç·´"""
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = xgb.XGBRegressor(
            n_estimators=self.config.n_estimators,
            learning_rate=self.config.learning_rate,
            max_depth=self.config.max_depth,
            min_child_weight=self.config.min_child_weight,
            subsample=self.config.subsample,
            colsample_bytree=self.config.colsample_bytree,
            reg_alpha=self.config.reg_alpha,
            reg_lambda=self.config.reg_lambda,
            gamma=self.config.gamma,
            eval_metric=self.config.eval_metric,
            tree_method=self.config.tree_method,
            random_state=self.random_state,
            n_jobs=-1,
            verbosity=0
        )
        
        # æ‡‰ç”¨å–®èª¿æ€§ç´„æŸ
        if self.config.enable_monotonic_constraints and self.config.monotone_constraints and feature_names:
            mono_constraints = tuple(
                self.config.monotone_constraints.get(f, 0) for f in feature_names
            )
            self.model.set_params(monotone_constraints=mono_constraints)
        
        # è¨“ç·´ï¼ˆå«æ—©åœï¼‰
        eval_set = [(X_train, y_train), (X_val, y_val)]
        
        fit_params = {
            'eval_set': eval_set,
            'early_stopping_rounds': self.config.early_stopping_rounds,
            'verbose': False
        }
        
        if sample_weights is not None:
            fit_params['sample_weight'] = sample_weights
        
        # v1.2 é ç•™ï¼šå¢é‡å­¸ç¿’
        if xgb_model is not None:
            fit_params['xgb_model'] = xgb_model
        
        self.model.fit(X_train, y_train, **fit_params)
        self.is_fitted = True
        
        # æå–è¨“ç·´æ­·å²
        results = self.model.evals_result()
        eval_metric = self.config.eval_metric
        
        self.training_history = {
            'train_rmse': results['validation_0'].get(eval_metric, []),
            'val_rmse': results['validation_1'].get(eval_metric, []),
            'best_iteration': self.model.best_iteration,
            'best_score': self.model.best_score,
            'n_features': X_train.shape[1]
        }
        
        # æå–ç‰¹å¾µé‡è¦æ€§ (Gain-based)
        importance = self.model.feature_importances_
        if feature_names:
            self.feature_importance = dict(zip(feature_names, importance))
        else:
            self.feature_importance = {f"feat_{i}": imp for i, imp in enumerate(importance)}
        
        return {
            'model': self.model,
            'best_iteration': self.model.best_iteration,
            'training_history': self.training_history,
            'feature_importance': self.feature_importance,
            'oob_score': None
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X, iteration_range=(0, self.model.best_iteration + 1))
    
    def get_feature_importance(self) -> Dict[str, float]:
        if not self.feature_importance:
            return {}
        total = sum(self.feature_importance.values())
        return {k: v/total for k, v in self.feature_importance.items()}
    
    def partial_fit(self, X_new: np.ndarray, y_new: np.ndarray, 
                    sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        v1.2 åŠŸèƒ½ï¼šå¢é‡å­¸ç¿’
        ä½¿ç”¨ç¾æœ‰æ¨¡å‹ä½œç‚ºåŸºç¤ï¼Œç¹¼çºŒè¨“ç·´æ–°è³‡æ–™
        """
        if not self.is_fitted:
            raise RuntimeError("å¿…é ˆå…ˆåŸ·è¡Œåˆå§‹è¨“ç·´æ‰èƒ½é€²è¡Œå¢é‡å­¸ç¿’")
        
        # XGBoost æ”¯æ´é€é xgb_model åƒæ•¸æ¥çºŒè¨“ç·´
        return self.train(
            X_train=X_new, y_train=y_new,
            X_val=X_new, y_val=y_new,  # é©—è­‰é›†å¯ç‚ºæ–°è³‡æ–™å­é›†æˆ–æ²¿ç”¨èˆŠé©—è­‰é›†
            sample_weights=sample_weight,
            xgb_model=self.model.get_booster()  # å‚³å…¥ç¾æœ‰æ¨¡å‹
        )
```

#### Step 1.2: LightGBM è¨“ç·´å™¨å¯¦ä½œ

**æª”æ¡ˆ**: `src/modeling/trainers/lightgbm_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
import lightgbm as lgb
import numpy as np
from typing import Dict, Any, Optional, List
from src.modeling.trainers.base_trainer import BaseModelTrainer

class LightGBMTrainer(BaseModelTrainer):
    """
    LightGBM è¨“ç·´å™¨å¯¦ä½œ (v1.1)
    
    ç‰¹æ€§:
    - Leaf-wise æ¨¹ç”Ÿé•·ï¼ˆæ›´é«˜æ•ˆï¼‰
    - åŸç”Ÿ Dataset çµæ§‹ï¼ˆè¨˜æ†¶é«”æ•ˆç‡é«˜ï¼‰
    - è¨“ç·´é€Ÿåº¦æ¥µå¿«
    - v1.2 é ç•™ï¼šinit_model æ¥çºŒè¨“ç·´
    """
    
    def __init__(self, config: LightGBMConfig, random_state: int = 42):
        super().__init__(config, random_state)
        self.model_metadata['supports_explainability'] = True
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None,
        init_model: Optional[Any] = None  # v1.2 å¢é‡å­¸ç¿’é ç•™
    ) -> Dict[str, Any]:
        """åŸ·è¡Œ LightGBM è¨“ç·´"""
        
        # å»ºç«‹ Datasetï¼ˆè¨˜æ†¶é«”æ•ˆç‡é«˜ï¼‰
        train_data = lgb.Dataset(
            X_train, 
            label=y_train, 
            weight=sample_weights,
            feature_name=feature_names or [f"feat_{i}" for i in range(X_train.shape[1])],
            free_raw_data=False  # ä¿ç•™åŸå§‹è³‡æ–™ä»¥ä¾›å¾ŒçºŒåƒè€ƒ
        )
        val_data = lgb.Dataset(
            X_val, 
            label=y_val,
            reference=train_data,
            feature_name=train_data.feature_name
        )
        
        # è¶…åƒæ•¸
        params = {
            'objective': 'regression',
            'metric': self.config.eval_metric,
            'boosting_type': self.config.boosting_type,
            'num_leaves': self.config.num_leaves,
            'max_depth': self.config.max_depth,
            'learning_rate': self.config.learning_rate,
            'feature_fraction': self.config.colsample_bytree,
            'bagging_fraction': self.config.subsample,
            'bagging_freq': 5,
            'lambda_l1': self.config.reg_alpha,
            'lambda_l2': self.config.reg_lambda,
            'min_child_samples': self.config.min_child_samples,
            'verbose': -1,
            'random_state': self.random_state,
            'feature_pre_filter': self.config.feature_pre_filter
        }
        
        if self.config.histogram_pool_size:
            params['histogram_pool_size'] = self.config.histogram_pool_size
        
        # è¨“ç·´ï¼ˆå«æ—©åœï¼‰
        callbacks = [lgb.early_stopping(stopping_rounds=self.config.early_stopping_rounds, verbose=False)]
        
        self.model = lgb.train(
            params,
            train_data,
            num_boost_round=self.config.n_estimators,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'val'],
            callbacks=callbacks,
            init_model=init_model  # v1.2 å¢é‡å­¸ç¿’
        )
        
        self.is_fitted = True
        
        # æå–è¨“ç·´æ­·å²
        self.training_history = {
            'best_iteration': self.model.best_iteration,
            'best_score': self.model.best_score.get('val', {}).get(self.config.eval_metric, None),
            'n_features': X_train.shape[1]
        }
        
        # ç‰¹å¾µé‡è¦æ€§ (Gain-based è¼ƒç©©å®š)
        importance_gain = self.model.feature_importance(importance_type='gain')
        self.feature_importance = dict(zip(train_data.feature_name, importance_gain))
        
        return {
            'model': self.model,
            'best_iteration': self.model.best_iteration,
            'training_history': self.training_history,
            'feature_importance': self.feature_importance,
            'oob_score': None
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X, num_iteration=self.model.best_iteration)
    
    def get_feature_importance(self) -> Dict[str, float]:
        if not self.feature_importance:
            return {}
        total = sum(self.feature_importance.values())
        return {k: v/total for k, v in self.feature_importance.items()}
```

#### Step 1.3: Random Forest è¨“ç·´å™¨å¯¦ä½œ

**æª”æ¡ˆ**: `src/modeling/trainers/random_forest_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
from sklearn.ensemble import RandomForestRegressor
import numpy as np
from typing import Dict, Any, Optional, List
from src.modeling.trainers.base_trainer import BaseModelTrainer

class RandomForestTrainer(BaseModelTrainer):
    """
    Random Forest è¨“ç·´å™¨å¯¦ä½œ (v1.1)
    
    ç‰¹æ€§:
    - Bagging ç­–ç•¥ï¼ˆå¹³è¡Œæ¨¹ï¼‰
    - å¤©ç„¶æ”¯æ´ OOB (Out-of-Bag) é©—è­‰
    - é æ¸¬å€é–“è¼¸å‡ºï¼ˆä½¿ç”¨æ‰€æœ‰æ¨¹çš„é æ¸¬åˆ†ä½ˆï¼‰
    - å°ç•°å¸¸å€¼é²æ£’
    - v1.2 é ç•™ï¼šwarm_start å¢é‡è¨“ç·´
    """
    
    def __init__(self, config: RandomForestConfig, random_state: int = 42):
        super().__init__(config, random_state)
        self.model_metadata['supports_incremental'] = True  # warm_start
        self.model_metadata['supports_explainability'] = True
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray = None,  # RF å¯ä¸ä½¿ç”¨ç¨ç«‹é©—è­‰é›†ï¼ˆä½¿ç”¨ OOBï¼‰
        y_val: np.ndarray = None,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """åŸ·è¡Œ Random Forest è¨“ç·´"""
        
        self.model = RandomForestRegressor(
            n_estimators=self.config.n_estimators,
            max_depth=self.config.max_depth,
            min_samples_split=self.config.min_samples_split,
            min_samples_leaf=self.config.min_samples_leaf,
            max_features=self.config.max_features,
            bootstrap=self.config.bootstrap,
            oob_score=self.config.oob_score,
            n_jobs=self.config.n_jobs,
            random_state=self.random_state,
            warm_start=self.config.warm_start,
            verbose=0
        )
        
        # è¨“ç·´
        self.model.fit(X_train, y_train, sample_weight=sample_weights)
        self.is_fitted = True
        
        # OOB åˆ†æ•¸
        oob_score = None
        if self.config.oob_score and self.config.bootstrap and hasattr(self.model, 'oob_score_'):
            oob_score = self.model.oob_score_
        
        # è¨“ç·´æ­·å²
        train_metrics = self.evaluate(X_train, y_train)
        val_metrics = self.evaluate(X_val, y_val) if X_val is not None else {}
        
        self.training_history = {
            'train_rmse': train_metrics['rmse'],
            'val_rmse': val_metrics.get('rmse'),
            'oob_r2': oob_score,
            'n_estimators': self.config.n_estimators,
            'n_features': X_train.shape[1]
        }
        
        # ç‰¹å¾µé‡è¦æ€§ (MDI)
        importance = self.model.feature_importances_
        if feature_names:
            self.feature_importance = dict(zip(feature_names, importance))
        else:
            self.feature_importance = {f"feat_{i}": imp for i, imp in enumerate(importance)}
        
        return {
            'model': self.model,
            'best_iteration': None,  # RF ç„¡è¿­ä»£æ¦‚å¿µ
            'training_history': self.training_history,
            'feature_importance': self.feature_importance,
            'oob_score': oob_score
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X)
    
    def predict_with_interval(self, X: np.ndarray, confidence: float = 0.9) -> Dict[str, np.ndarray]:
        """
        è¼¸å‡ºé æ¸¬å€é–“ï¼ˆä½¿ç”¨æ‰€æœ‰æ¨¹çš„é æ¸¬åˆ†ä½ˆï¼‰
        
        Args:
            X: ç‰¹å¾µçŸ©é™£
            confidence: ä¿¡å¿ƒæ°´æº–ï¼ˆé è¨­ 90%ï¼Œè¼¸å‡º Q5 èˆ‡ Q95ï¼‰
        
        Returns:
            {
                'mean': å¹³å‡é æ¸¬å€¼,
                'lower': ä¸‹ç•Œ,
                'upper': ä¸Šç•Œ,
                'std': æ¨™æº–å·®
            }
        """
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        
        # å–å¾—æ‰€æœ‰æ¨¹çš„é æ¸¬ (n_samples, n_trees)
        all_predictions = np.array([tree.predict(X) for tree in self.model.estimators_])
        
        mean_pred = np.mean(all_predictions, axis=0)
        std_pred = np.std(all_predictions, axis=0)
        
        # è¨ˆç®—åˆ†ä½æ•¸
        alpha = (1 - confidence) * 100 / 2
        lower = np.percentile(all_predictions, alpha, axis=0)
        upper = np.percentile(all_predictions, 100 - alpha, axis=0)
        
        return {
            'mean': mean_pred,
            'lower': lower,
            'upper': upper,
            'std': std_pred
        }
    
    def get_feature_importance(self) -> Dict[str, float]:
        if not self.feature_importance:
            return {}
        total = sum(self.feature_importance.values())
        return {k: v/total for k, v in self.feature_importance.items()}
    
    def partial_fit(self, X_new: np.ndarray, y_new: np.ndarray,
                    sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        v1.2 åŠŸèƒ½ï¼šå¢é‡å­¸ç¿’
        é€éå¢åŠ  n_estimators å¯¦ç¾å¢é‡è¨“ç·´
        """
        if not self.is_fitted:
            raise RuntimeError("å¿…é ˆå…ˆåŸ·è¡Œåˆå§‹è¨“ç·´")
        
        # å¢åŠ æ¨¹çš„æ•¸é‡
        current_n = self.model.n_estimators
        self.model.n_estimators += 100  # æ¯æ¬¡å¢åŠ  100 æ£µæ¨¹
        self.model.warm_start = True
        
        self.model.fit(X_new, y_new, sample_weight=sample_weight)
        
        return {
            'model': self.model,
            'previous_n_estimators': current_n,
            'new_n_estimators': self.model.n_estimators,
            'oob_score': getattr(self.model, 'oob_score_', None)
        }
```

---

### Phase 2: å¤šæ¨¡å‹è¨“ç·´ç®¡ç·šæ•´åˆ (Day 5)

#### Step 2.1: è³‡æºç®¡ç†èˆ‡å‹•æ…‹èª¿åº¦

**æª”æ¡ˆ**: `src/modeling/resource_manager.py`ï¼ˆv1.1 æ–°å¢ï¼‰

**å¯¦ä½œå…§å®¹**:
```python
import psutil
import numpy as np
from typing import Tuple, Dict, Any
import logging

class ResourceManager:
    """
    è¨“ç·´è³‡æºç®¡ç†å™¨ (v1.1)
    è² è²¬è¨˜æ†¶é«”è©•ä¼°ã€å‹•æ…‹é™ç´šæ±ºç­–ã€ä»¥åŠç¡¬é«”è³‡æºç›£æ§
    """
    
    def __init__(self, config: ResourceConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.initial_memory = psutil.virtual_memory().available
    
    def estimate_memory_requirement(
        self, 
        n_samples: int, 
        n_features: int,
        eligible_models: List[str]
    ) -> Dict[str, float]:
        """
        ä¼°ç®—å„æ¨¡å‹è¨˜æ†¶é«”éœ€æ±‚ï¼ˆä½å…ƒçµ„ï¼‰
        
        ä¼°ç®—å…¬å¼ï¼ˆä¿å®ˆä¼°è¨ˆï¼‰ï¼š
        - XGBoost: ~8 bytes * n_samples * n_features * 1.5 (sparse overhead) * 1.2 (tree storage)
        - LightGBM: ~4 bytes * n_samples * n_features * 0.8 (dense efficiency) * 1.1
        - Random Forest: ~8 bytes * n_samples * n_features * n_trees/5 (æ¯æ£µæ¨¹å„²å­˜éƒ¨åˆ†æ¨£æœ¬ç´¢å¼•)
        """
        base_size = n_samples * n_features
        
        estimates = {}
        
        if 'xgboost' in eligible_models:
            # XGBoost ä½¿ç”¨ç›´æ–¹åœ–ç®—æ³•ï¼Œè¨˜æ†¶é«”éœ€æ±‚è¼ƒç©©å®š
            estimates['xgboost'] = base_size * 8 * 1.5 * 1.2
        
        if 'lightgbm' in eligible_models:
            # LightGBM è¨˜æ†¶é«”æ•ˆç‡æœ€é«˜
            estimates['lightgbm'] = base_size * 4 * 0.8 * 1.1
        
        if 'random_forest' in eligible_models:
            # RF éœ€è¦å„²å­˜æ¯æ£µæ¨¹çš„æ¨£æœ¬ç´¢å¼•ï¼ˆbootstrapï¼‰
            # å‡è¨­æ¯æ£µæ¨¹ä½¿ç”¨ 63.2% æ¨£æœ¬ï¼ˆbootstrap æœŸæœ›å€¤ï¼‰
            n_trees = 500  # é è¨­
            rf_factor = n_trees * 0.632 * 4  # 4 bytes per index (int32)
            estimates['random_forest'] = base_size * rf_factor
        
        return estimates
    
    def check_training_feasibility(
        self, 
        n_samples: int, 
        n_features: int,
        eligible_models: List[str]
    ) -> Tuple[bool, bool, str]:
        """
        æª¢æŸ¥è¨“ç·´å¯è¡Œæ€§
        
        Returns:
            (is_feasible, use_parallel, message)
            - is_feasible: æ˜¯å¦å¯è¡Œ
            - use_parallel: æ˜¯å¦å¯ä½¿ç”¨å¹³è¡Œè¨“ç·´
            - message: èªªæ˜è¨Šæ¯
        """
        if not self.config.memory_check_before_training:
            return True, self.config.parallel_training, "è·³éè¨˜æ†¶é«”æª¢æŸ¥"
        
        estimates = self.estimate_memory_requirement(n_samples, n_features, eligible_models)
        total_required = sum(estimates.values())
        
        available_mem = psutil.virtual_memory().available
        total_mem = psutil.virtual_memory().total
        safety_threshold = total_mem * (1 - self.config.memory_safety_threshold)
        
        # æª¢æŸ¥å–®ä¸€æ¨¡å‹æ˜¯å¦å¯è¡Œ
        if any(est > available_mem for est in estimates.values()):
            problematic = [m for m, est in estimates.items() if est > available_mem]
            return False, False, f"E801: è¨˜æ†¶é«”ä¸è¶³ï¼Œ{problematic} éœ€æ±‚è¶…éå¯ç”¨è¨˜æ†¶é«”"
        
        # æª¢æŸ¥å¹³è¡Œè¨“ç·´å¯è¡Œæ€§
        if total_required < min(available_mem * 0.8, safety_threshold):
            msg = f"âœ… è¨˜æ†¶é«”å……è¶³: éœ€æ±‚ {total_required/1e9:.1f}GB, å¯ç”¨ {available_mem/1e9:.1f}GB"
            return True, True, msg
        else:
            if self.config.auto_fallback_to_sequential:
                msg = (f"âš ï¸ E801: å¹³è¡Œè¨“ç·´è¨˜æ†¶é«”é¢¨éšª (éœ€æ±‚ {total_required/1e9:.1f}GB > "
                       f"å®‰å…¨é–¾å€¼ {safety_threshold/1e9:.1f}GB)ï¼Œè‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´")
                return True, False, msg
            else:
                return False, False, "E801: è¨˜æ†¶é«”ä¸è¶³ä¸”æœªå•Ÿç”¨è‡ªå‹•é™ç´š"
    
    def get_optimal_n_jobs(self, model_name: str) -> int:
        """å–å¾—å»ºè­°çš„å¹³è¡ŒåŸ·è¡Œç·’æ•¸ï¼ˆé¿å…éåº¦è¨‚é–±ï¼‰"""
        cpu_count = psutil.cpu_count(logical=True)
        
        if model_name in ['random_forest']:
            # RF å·²ä¸¦è¡Œï¼Œé™åˆ¶åŸ·è¡Œç·’é¿å…æ¶ä½”
            return max(1, cpu_count // 3)
        else:
            return max(1, cpu_count // 2)
    
    def log_resource_usage(self):
        """è¨˜éŒ„ç•¶å‰è³‡æºä½¿ç”¨ç‹€æ³"""
        mem = psutil.virtual_memory()
        cpu = psutil.cpu_percent(interval=1)
        self.logger.info(
            f"ğŸ“Š è³‡æºç‹€æ…‹: CPU {cpu}%, "
            f"è¨˜æ†¶é«” {mem.used/1e9:.1f}/{mem.total/1e9:.1f}GB ({mem.percent}%)"
        )
```

#### Step 2.2: å¹³è¡Œè¨“ç·´èˆ‡æ¨¡å‹é¸æ“‡é‚è¼¯ï¼ˆè³‡æºæ„ŸçŸ¥ç‰ˆï¼‰

**æª”æ¡ˆ**: `src/modeling/training_pipeline.py`ï¼ˆæ ¸å¿ƒæ›´æ–°ï¼‰

**å¯¦ä½œå…§å®¹**:
```python
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, List, Tuple, Any, Optional
import numpy as np
import logging
from datetime import datetime

from src.modeling.trainers.xgboost_trainer import XGBoostTrainer
from src.modeling.trainers.lightgbm_trainer import LightGBMTrainer
from src.modeling.trainers.random_forest_trainer import RandomForestTrainer
from src.modeling.resource_manager import ResourceManager

class TrainingPipeline:
    """
    å¤šæ¨¡å‹è¨“ç·´ç®¡ç·š v1.1 (Resource-Aware)
    
    åŒæ™‚è¨“ç·´ XGBoostã€LightGBMã€Random Forestï¼Œ
    ä¸¦ä¾é©—è­‰æŒ‡æ¨™è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹æˆ–ä¿ç•™ Ensembleã€‚
    å…·å‚™å‹•æ…‹è¨˜æ†¶é«”ç®¡ç†èˆ‡å°æ¨£æœ¬é©æ‡‰æ©Ÿåˆ¶ã€‚
    """
    
    def __init__(self, config: ModelTrainingConfig, site_id: str, yaml_base_dir: str = "config/features/sites"):
        self.config = config
        self.site_id = site_id
        self.annotation_manager = FeatureAnnotationManager(site_id=site_id, yaml_base_dir=yaml_base_dir)
        self.resource_manager = ResourceManager(config.resource)
        self.logger = logging.getLogger(__name__)
        
        self._validate_annotation_compatibility()
        
        self.trainers = {}
        self.results = {}
        self.best_model_name = None
        self.training_stats = {
            'start_time': None,
            'end_time': None,
            'models_trained': [],
            'resource_events': []
        }
        
    def _validate_annotation_compatibility(self):
        """é©—è­‰ä¸Šæ¸¸ Annotation ç›¸å®¹æ€§"""
        # å¯¦ä½œç´°ç•¥ï¼ˆåŒ v1.0ï¼‰
        pass
    
    def _select_best_model(self) -> str:
        """
        é¸æ“‡æœ€ä½³æ¨¡å‹ï¼ˆv1.1 å¼·åŒ–ç‰ˆï¼‰
        
        ç­–ç•¥:
        1. å„ªå…ˆæ¯”è¼ƒé©—è­‰é›† RÂ² åˆ†æ•¸
        2. è‹¥ RÂ² å·®è· < 0.01ï¼Œæ¯”è¼ƒè¨“ç·´ç©©å®šæ€§ï¼ˆRF çš„ OOB èˆ‡ Val å·®è·ï¼‰
        3. è‹¥ RF çš„ OOB èˆ‡é©—è­‰é›†å·®è·éå¤§ï¼ˆ>0.1ï¼‰ï¼Œå¯èƒ½è¡¨ç¤ºè³‡æ–™æ´©æ¼ï¼Œé™ä½æ’å
        4. é¸æ“‡è¨“ç·´æ™‚é–“è¼ƒçŸ­çš„ï¼ˆåœ¨ç²¾åº¦ç›¸ç•¶æ™‚ï¼‰
        """
        valid_results = {
            name: res for name, res in self.results.items() 
            if 'error' not in res and 'metrics' in res
        }
        
        if not valid_results:
            raise ModelTrainingError("E703: æ‰€æœ‰æ¨¡å‹è¨“ç·´å¤±æ•—")
        
        # è¨ˆç®—ç¶œåˆåˆ†æ•¸
        model_scores = []
        for name, result in valid_results.items():
            val_r2 = result['metrics']['val']['r2']
            train_r2 = result['metrics']['train']['r2']
            overfit_score = train_r2 - val_r2  # éæ“¬åˆç¨‹åº¦
            
            # RF ç‰¹æ®Šæª¢æŸ¥ï¼šOOB èˆ‡ Val å·®è·
            oob_penalty = 0
            if name == 'random_forest' and result.get('oob_score'):
                oob_gap = abs(result['oob_score'] - val_r2)
                if oob_gap > 0.1:
                    oob_penalty = 0.05  # æ‡²ç½°åˆ†æ•¸
            
            # ç¶œåˆåˆ†æ•¸ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
            composite_score = val_r2 - overfit_score * 0.5 - oob_penalty
            
            model_scores.append((name, composite_score, val_r2))
        
        # æ’åº
        model_scores.sort(key=lambda x: x[1], reverse=True)
        best_name = model_scores[0][0]
        
        self.logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_name} (ç¶œåˆåˆ†æ•¸={model_scores[0][1]:.4f}, Val RÂ²={model_scores[0][2]:.4f})")
        
        # è¨˜éŒ„è©³ç´°æ¯”è¼ƒ
        for name, comp_score, val_r2 in model_scores:
            rmse = valid_results[name]['metrics']['val']['rmse']
            self.logger.info(f"   {name}: Val RÂ²={val_r2:.4f}, Composite={comp_score:.4f}, RMSE={rmse:.4f}")
        
        return best_name
    
    def train_all_models(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        è¨“ç·´æ‰€æœ‰ç¬¦åˆè³‡æ ¼çš„æ¨¡å‹ï¼ˆè³‡æºæ„ŸçŸ¥æ’ç¨‹ï¼‰
        """
        # Step 1: æ±ºå®šå¯ç”¨æ¨¡å‹ï¼ˆä¾æ¨£æœ¬æ•¸ï¼‰
        n_samples = len(X_train)
        eligible_models = self.config.get_eligible_models(n_samples)
        self.logger.info(f"ğŸ“‹ ç¬¦åˆè³‡æ ¼çš„æ¨¡å‹ï¼ˆæ¨£æœ¬æ•¸={n_samples}ï¼‰: {eligible_models}")
        
        # Step 2: è³‡æºæª¢æŸ¥èˆ‡æ¨¡å¼æ±ºå®š
        is_feasible, use_parallel, msg = self.resource_manager.check_training_feasibility(
            n_samples, X_train.shape[1], eligible_models
        )
        self.logger.info(msg)
        self.training_stats['resource_events'].append({
            'timestamp': datetime.now().isoformat(),
            'event': 'resource_check',
            'parallel_mode': use_parallel,
            'message': msg
        })
        
        if not is_feasible:
            raise ModelTrainingError(msg)
        
        # Step 3: æº–å‚™è¨“ç·´é…ç½®
        trainers_config = {}
        for name in eligible_models:
            TrainerClass = {
                'xgboost': XGBoostTrainer,
                'lightgbm': LightGBMTrainer,
                'random_forest': RandomForestTrainer
            }[name]
            
            # å–å¾—é…ç½®ï¼ˆå«å°æ¨£æœ¬èª¿æ•´ï¼‰
            model_config = self.config.adjust_for_small_sample(name, n_samples)
            trainers_config[name] = (TrainerClass, model_config)
        
        # Step 4: åŸ·è¡Œè¨“ç·´
        if use_parallel and len(trainers_config) > 1:
            self._train_parallel(trainers_config, X_train, y_train, X_val, y_val, 
                               sample_weights, feature_names)
        else:
            self._train_sequential(trainers_config, X_train, y_train, X_val, y_val,
                                 sample_weights, feature_names)
        
        # Step 5: è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹
        if self.config.resource.auto_select_best:
            self.best_model_name = self._select_best_model()
        
        return self.results
    
    def _train_single_model(
        self,
        name: str,
        TrainerClass,
        model_config,
        X_train, y_train, X_val, y_val,
        sample_weights, feature_names
    ) -> Tuple[str, Dict[str, Any]]:
        """è¨“ç·´å–®ä¸€æ¨¡å‹ï¼ˆåŒ…è£å™¨ä¾›å¹³è¡Œ/åºåˆ—ä½¿ç”¨ï¼‰"""
        try:
            self.logger.info(f"ğŸš€ é–‹å§‹è¨“ç·´ {name}...")
            start_time = datetime.now()
            
            trainer = TrainerClass(config=model_config, random_state=self.config.random_state)
            result = trainer.train(
                X_train=X_train, y_train=y_train,
                X_val=X_val, y_val=y_val,
                sample_weights=sample_weights,
                feature_names=feature_names
            )
            
            # è©•ä¼°
            result['metrics'] = {
                'train': trainer.evaluate(X_train, y_train),
                'val': trainer.evaluate(X_val, y_val)
            }
            
            result['training_time'] = (datetime.now() - start_time).total_seconds()
            result['status'] = 'success'
            
            self.trainers[name] = trainer
            self.training_stats['models_trained'].append(name)
            
            self.logger.info(f"âœ… {name} è¨“ç·´å®Œæˆ ({result['training_time']:.1f}s, Val RÂ²={result['metrics']['val']['r2']:.4f})")
            
            return name, result
            
        except Exception as e:
            self.logger.error(f"âŒ {name} è¨“ç·´å¤±æ•—: {str(e)}")
            return name, {'error': str(e), 'status': 'failed'}
    
    def _train_parallel(self, trainers_config, X_train, y_train, X_val, y_val, 
                       sample_weights, feature_names):
        """å¹³è¡Œè¨“ç·´ï¼ˆProcessPoolExecutorï¼‰"""
        # é™åˆ¶å·¥ä½œé€²ç¨‹æ•¸ï¼Œé¿å…è³‡æºæ¶ä½”
        max_workers = min(len(trainers_config), self.config.resource.max_parallel_workers)
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(
                    self._train_single_model,
                    name, TrainerClass, model_config,
                    X_train, y_train, X_val, y_val,
                    sample_weights, feature_names
                ): name 
                for name, (TrainerClass, model_config) in trainers_config.items()
            }
            
            for future in as_completed(futures):
                name = futures[future]
                try:
                    model_name, result = future.result()
                    self.results[model_name] = result
                except Exception as e:
                    self.logger.error(f"âŒ {name} é€²ç¨‹ç•°å¸¸: {e}")
                    self.results[name] = {'error': str(e), 'status': 'failed'}
    
    def _train_sequential(self, trainers_config, X_train, y_train, X_val, y_val,
                         sample_weights, feature_names):
        """åºåˆ—è¨“ç·´ï¼ˆè¨˜æ†¶é«”å®‰å…¨æ¨¡å¼ï¼‰"""
        for name, (TrainerClass, model_config) in trainers_config.items():
            model_name, result = self._train_single_model(
                name, TrainerClass, model_config,
                X_train, y_train, X_val, y_val,
                sample_weights, feature_names
            )
            self.results[model_name] = result
            
            # ä¸»å‹•æ¸…ç†è¨˜æ†¶é«”ï¼ˆå°¤å…¶åœ¨ RF è¨“ç·´å¾Œï¼‰
            if name == 'random_forest':
                import gc
                gc.collect()
                self.resource_manager.log_resource_usage()
    
    def get_best_model(self) -> Tuple[str, BaseModelTrainer, Dict]:
        """å–å¾—æœ€ä½³æ¨¡å‹åŠå…¶çµæœ"""
        if self.best_model_name is None:
            raise RuntimeError("E706: å°šæœªåŸ·è¡Œæ¨¡å‹é¸æ“‡")
        return (
            self.best_model_name,
            self.trainers[self.best_model_name],
            self.results[self.best_model_name]
        )
    
    def predict_ensemble(self, X: np.ndarray, weights: Optional[Dict[str, float]] = None) -> np.ndarray:
        """
        Ensemble é æ¸¬ï¼ˆåŠ æ¬Šå¹³å‡ï¼Œåƒ…ä½¿ç”¨æˆåŠŸè¨“ç·´çš„æ¨¡å‹ï¼‰
        """
        valid_trainers = {
            name: trainer for name, trainer in self.trainers.items()
            if name in self.results and 'error' not in self.results[name]
        }
        
        if not valid_trainers:
            raise RuntimeError("E707: ç„¡å¯ç”¨æ¨¡å‹é€²è¡Œ Ensemble é æ¸¬")
        
        predictions = []
        model_weights = []
        
        for name, trainer in valid_trainers.items():
            pred = trainer.predict(X)
            predictions.append(pred)
            
            if weights and name in weights:
                model_weights.append(weights[name])
            else:
                # ä½¿ç”¨ Val RÂ² ä½œç‚ºæ¬Šé‡ï¼ˆé¿å…è² å€¼ï¼‰
                r2 = max(0, self.results[name]['metrics']['val']['r2'])
                model_weights.append(r2)
        
        # åŠ æ¬Šå¹³å‡
        weights_arr = np.array(model_weights) / sum(model_weights)
        ensemble_pred = np.average(predictions, axis=0, weights=weights_arr)
        
        return ensemble_pred
```

---

### Phase 3: è¶…åƒæ•¸å„ªåŒ–èˆ‡å¯è§£é‡‹æ€§ (Day 6-7)

#### Step 3.1: å¤œé–“è¶…åƒæ•¸å„ªåŒ–å™¨ï¼ˆOvernight Optimizerï¼‰

**æª”æ¡ˆ**: `src/modeling/hyperparameter/optuna_optimizer.py`ï¼ˆv1.1 æ–°å¢ï¼‰

**å¯¦ä½œå…§å®¹**:
```python
import optuna
import gc
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging

from src.modeling.trainers.xgboost_trainer import XGBoostTrainer
from src.modeling.trainers.lightgbm_trainer import LightGBMTrainer
from src.modeling.trainers.random_forest_trainer import RandomForestTrainer

class SearchSpace:
    """å®šç¾©å„æ¨¡å‹çš„è¶…åƒæ•¸æœå°‹ç©ºé–“"""
    
    @staticmethod
    def xgboost_space(trial: optuna.Trial) -> Dict[str, Any]:
        return {
            'n_estimators': trial.suggest_int('n_estimators', 100, 2000),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        }
    
    @staticmethod
    def lightgbm_space(trial: optuna.Trial) -> Dict[str, Any]:
        return {
            'num_leaves': trial.suggest_int('num_leaves', 20, 150),
            'max_depth': trial.suggest_int('max_depth', -1, 12),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),
            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),
            'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),
            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        }
    
    @staticmethod
    def random_forest_space(trial: optuna.Trial) -> Dict[str, Any]:
        max_depth_choice = trial.suggest_categorical('max_depth_choice', ['fixed', 'none'])
        return {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 5, 50) if max_depth_choice == 'fixed' else None,
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
        }

class OvernightOptimizer:
    """
    å¤œé–“è¶…åƒæ•¸å„ªåŒ–å™¨ (v1.1)
    
    ç‰¹æ€§ï¼š
    1. ä¾åºå„ªåŒ–ï¼ˆéä¸¦è¡Œï¼‰ï¼Œé¿å…è³‡æºçˆ†ç‚¸
    2. æ”¯æ´æ–·é»çºŒå‚³ï¼ˆSQLite å„²å­˜ studyï¼‰
    3. èˆ‡ Early Stopping æ•´åˆï¼ŒåŠ é€Ÿæ¯å€‹ trial
    4. Pruning æ©Ÿåˆ¶ï¼šè‡ªå‹•çµ‚æ­¢ç„¡æœ›çš„ trial
    """
    
    def __init__(self, config: ModelTrainingConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.storage = f"sqlite:///{config.hyperparameter_storage}"
        
    def optimize_model(
        self, 
        model_name: str,
        X_train, y_train, X_val, y_val,
        n_trials: int = 50,
        timeout: int = 3600,
        n_startup_trials: int = 10
    ) -> Dict[str, Any]:
        """
        å–®ä¸€æ¨¡å‹å„ªåŒ–ï¼ˆå»ºè­°å¤œé–“åŸ·è¡Œï¼‰
        """
        study_name = f"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M')}"
        
        # å»ºç«‹æˆ–è¼‰å…¥ studyï¼ˆæ”¯æ´æ–·é»çºŒå‚³ï¼‰
        study = optuna.create_study(
            study_name=study_name,
            storage=self.storage,
            load_if_exists=True,
            direction='maximize',
            sampler=optuna.samplers.TPESampler(n_startup_trials=n_startup_trials),
            pruner=optuna.pruners.MedianPruner()  # å‰ªæç­–ç•¥
        )
        
        def objective(trial):
            # å–å¾—æœå°‹ç©ºé–“
            space_method = getattr(SearchSpace, f"{model_name}_space")
            params = space_method(trial)
            
            # åˆå§‹åŒ– Trainer
            trainer_class = {
                'xgboost': XGBoostTrainer,
                'lightgbm': LightGBMTrainer,
                'random_forest': RandomForestTrainer
            }[model_name]
            
            # å»ºç«‹è‡¨æ™‚ config
            base_config = getattr(self.config, model_name)
            temp_config = base_config.copy()
            for key, val in params.items():
                setattr(temp_config, key, val)
            
            trainer = trainer_class(config=temp_config, random_state=self.config.random_state)
            
            try:
                # è¨“ç·´ä¸¦è©•ä¼°
                trainer.train(X_train, y_train, X_val, y_val)
                val_metrics = trainer.evaluate(X_val, y_val)
                val_r2 = val_metrics['r2']
                
                # å›å ± intermediate value ä¾› pruner åˆ¤æ–·
                trial.report(val_r2, step=0)
                if trial.should_prune():
                    raise optuna.TrialPruned()
                
                return val_r2
                
            except Exception as e:
                self.logger.warning(f"Trial {trial.number} å¤±æ•—: {e}")
                return -float('inf')
        
        # åŸ·è¡Œå„ªåŒ–
        start_time = time.time()
        study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)
        elapsed = time.time() - start_time
        
        # çµ„ç¹”çµæœ
        result = {
            'model_name': model_name,
            'study_name': study_name,
            'best_params': study.best_params,
            'best_value': study.best_value,
            'n_trials_completed': len(study.trials),
            'n_trials_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),
            'optimization_time': elapsed,
            'optimization_history': [
                {
                    'trial': t.number, 
                    'value': t.value, 
                    'params': t.params,
                    'state': t.state.name
                } 
                for t in study.trials 
                if t.state == optuna.trial.TrialState.COMPLETE
            ]
        }
        
        return result
    
    def optimize_all_models_sequentially(self, data: TrainingInputContract) -> Dict[str, Any]:
        """
        ä¾åºå„ªåŒ–ä¸‰æ¨¡å‹ï¼ˆè³‡æºå®‰å…¨æ¨¡å¼ï¼‰
        å»ºè­°åŸ·è¡Œæ™‚æ®µï¼šå¤œé–“ 00:00 - 06:00
        """
        # è³‡æ–™æº–å‚™ï¼ˆèˆ‡ TrainingPipeline ç›¸åŒé‚è¼¯ï¼Œç•¥ï¼‰
        X_train, y_train, X_val, y_val = self._prepare_data(data)
        
        results = {}
        
        # ä¾åºï¼šè¼•é‡åˆ°é‡åº¦ï¼ˆRF -> XGB -> LGBï¼‰
        models = ['random_forest', 'xgboost', 'lightgbm']
        eligible_models = self.config.get_eligible_models(len(X_train))
        models = [m for m in models if m in eligible_models]
        
        total_start = time.time()
        
        for model_name in models:
            self.logger.info(f"ğŸŒ™ é–‹å§‹å¤œé–“å„ªåŒ–: {model_name}")
            
            # æ¯å€‹æ¨¡å‹åˆ†é… 1/3 æ™‚é–“
            timeout_per_model = self.config.hyperparameter_timeout // len(models)
            trials_per_model = self.config.hyperparameter_trials
            
            result = self.optimize_model(
                model_name=model_name,
                X_train=X_train, y_train=y_train,
                X_val=X_val, y_val=y_val,
                n_trials=trials_per_model,
                timeout=timeout_per_model
            )
            
            results[model_name] = result
            
            self.logger.info(
                f"âœ… {model_name} å„ªåŒ–å®Œæˆ: Best RÂ²={result['best_value']:.4f}, "
                f"è€—æ™‚ {result['optimization_time']/60:.1f}åˆ†é˜, "
                f"Pruned={result['n_trials_pruned']}/{result['n_trials_completed']}"
            )
            
            # æ¸…ç†è¨˜æ†¶é«”
            gc.collect()
        
        results['total_time'] = time.time() - total_start
        
        # å„²å­˜æœ€ä½³åƒæ•¸å»ºè­°
        self._save_best_params_recommendation(results)
        
        return results
    
    def _save_best_params_recommendation(self, results: Dict[str, Any]):
        """å„²å­˜æœ€ä½³åƒæ•¸ä¾›æ˜æ—¥æ—¥é–“è¨“ç·´ä½¿ç”¨"""
        recommendation = {
            'timestamp': datetime.now().isoformat(),
            'models': {}
        }
        
        for model_name, result in results.items():
            if 'best_params' in result:
                recommendation['models'][model_name] = {
                    'best_params': result['best_params'],
                    'expected_performance': result['best_value']
                }
        
        # å„²å­˜ç‚º JSONï¼Œä¾› Config è¼‰å…¥
        import json
        with open(f"config/hyperparameter_recommendations_{self.config.site_id}.json", 'w') as f:
            json.dump(recommendation, f, indent=2)
```

#### Step 3.2: å¯è§£é‡‹æ€§å°è£ï¼ˆSHAP Integrationï¼‰

**æª”æ¡ˆ**: `src/modeling/explainability/shap_explainer.py`ï¼ˆv1.1 æ–°å¢ï¼‰

**å¯¦ä½œå…§å®¹**:
```python
from typing import Dict, List, Optional, Any
import numpy as np
import polars as pl

class ModelExplainer:
    """
    æ¨¡å‹å¯è§£é‡‹æ€§å°è£å±¤ (v1.1)
    æ”¯æ´ TreeSHAP (é©ç”¨ XGB/LGB/RF) èˆ‡ HVAC å°ˆç”¨æ™‚é–“åºåˆ—è§£é‡‹
    
    æ³¨æ„ï¼šéœ€å®‰è£ shap: pip install shap
    """
    
    def __init__(self, model: Any, feature_names: List[str], model_type: str):
        self.model = model
        self.feature_names = feature_names
        self.model_type = model_type
        self.explainer = None
        self.background_data = None
        self.is_fitted = False
        
        # å»¶é²è¼‰å…¥ shapï¼ˆé¿å…æœªå®‰è£æ™‚å ±éŒ¯ï¼‰
        try:
            import shap
            self.shap = shap
        except ImportError:
            raise ImportError("E805: ä½¿ç”¨å¯è§£é‡‹æ€§åŠŸèƒ½éœ€å®‰è£ shap: pip install shap")
    
    def fit_background(self, X_background: np.ndarray, sample_size: int = 100):
        """
        å»ºç«‹ SHAP èƒŒæ™¯åˆ†ä½ˆï¼ˆç”¨æ–¼å°æ¯”åŸºæº–ï¼‰
        
        Args:
            X_background: èƒŒæ™¯è³‡æ–™ï¼ˆå»ºè­°ä½¿ç”¨è¨“ç·´é›†å­é›†ï¼‰
            sample_size: èƒŒæ™¯è³‡æ–™å–æ¨£æ•¸ï¼ˆéå¤§æœƒå½±éŸ¿æ•ˆèƒ½ï¼‰
        """
        if len(X_background) > sample_size:
            idx = np.random.choice(len(X_background), sample_size, replace=False)
            self.background_data = X_background[idx]
        else:
            self.background_data = X_background
        
        # ä¾æ¨¡å‹é¡å‹é¸æ“‡æœ€ä½³è§£é‡‹å™¨
        if self.model_type in ['xgboost', 'lightgbm', 'random_forest']:
            self.explainer = self.shap.TreeExplainer(self.model)
        else:
            # é€šç”¨æ¨¡å‹ä½¿ç”¨ KernelExplainerï¼ˆè¼ƒæ…¢ï¼‰
            self.explainer = self.shap.KernelExplainer(
                self.model.predict, 
                self.shap.sample(self.background_data, min(50, sample_size))
            )
        
        self.is_fitted = True
    
    def explain_local(self, X_instance: np.ndarray) -> Dict[str, Any]:
        """
        å–®ç­†é æ¸¬è§£é‡‹ï¼ˆå±€éƒ¨è§£é‡‹ï¼‰
        
        Returns:
            {
                'base_value': åŸºæº–å€¼ï¼ˆè¨“ç·´é›†å¹³å‡é æ¸¬ï¼‰,
                'prediction': å¯¦éš›é æ¸¬å€¼,
                'feature_contributions': {ç‰¹å¾µå: è²¢ç»å€¼},
                'top_positive': [(ç‰¹å¾µå, è²¢ç»å€¼)],  # å‰ä¸‰é«˜æ­£å‘è²¢ç»
                'top_negative': [(ç‰¹å¾µå, è²¢ç»å€¼)],  # å‰ä¸‰é«˜è² å‘è²¢ç»
                'shap_values': åŸå§‹ SHAP å€¼é™£åˆ—
            }
        """
        if not self.is_fitted:
            raise RuntimeError("E804: éœ€å…ˆåŸ·è¡Œ fit_background()")
        
        # ç¢ºä¿æ˜¯ 2D é™£åˆ—
        if X_instance.ndim == 1:
            X_instance = X_instance.reshape(1, -1)
        
        shap_values = self.explainer.shap_values(X_instance)
        
        # è™•ç†å¤šç¶­è¼¸å‡ºï¼ˆå›æ­¸é€šå¸¸ç‚º 1Dï¼‰
        if isinstance(shap_values, list):
            shap_values = shap_values[0]
        
        # è½‰æ›ç‚ºçµæ§‹åŒ–è¼¸å‡º
        feature_contrib = {
            name: float(val) 
            for name, val in zip(self.feature_names, shap_values[0])
        }
        
        # æ’åºå–å¾— Top è²¢ç»
        sorted_contrib = sorted(feature_contrib.items(), key=lambda x: abs(x[1]), reverse=True)
        
        return {
            'base_value': float(self.explainer.expected_value),
            'prediction': float(self.explainer.expected_value + np.sum(shap_values)),
            'feature_contributions': feature_contrib,
            'top_positive': sorted([x for x in feature_contrib.items() if x[1] > 0], 
                                  key=lambda x: x[1], reverse=True)[:3],
            'top_negative': sorted([x for x in feature_contrib.items() if x[1] < 0], 
                                  key=lambda x: x[1])[:3],
            'shap_values': shap_values.tolist()
        }
    
    def explain_batch(self, X: np.ndarray, batch_size: int = 100) -> List[Dict[str, Any]]:
        """æ‰¹æ¬¡è§£é‡‹ï¼ˆè¨˜æ†¶é«”æ•ˆç‡ç‰ˆï¼‰"""
        explanations = []
        for i in range(0, len(X), batch_size):
            batch = X[i:i+batch_size]
            for j in range(len(batch)):
                explanations.append(self.explain_local(batch[j]))
        return explanations
    
    def explain_temporal(self, X_series: np.ndarray, timestamps: List) -> pl.DataFrame:
        """
        HVAC å°ˆç”¨ï¼šæ™‚é–“åºåˆ—ç‰¹å¾µè²¢ç»è¿½è¹¤
        
        ä¾‹å¦‚ï¼šè§£é‡‹ç‚ºä½•ä¸‹åˆ 2 é»é æ¸¬è€—é›»é£†å‡
        ï¼ˆå¯èƒ½æ˜¯ outdoor_temp + chiller_load å…±åŒä½œç”¨ï¼‰
        """
        explanations = self.explain_batch(X_series)
        
        # çµ„ç¹”ç‚º Polars DataFrameï¼ˆé«˜æ•ˆèƒ½ï¼‰
        df_data = {
            'timestamp': timestamps,
            'base_value': [e['base_value'] for e in explanations],
            'prediction': [e['prediction'] for e in explanations],
            'primary_driver': [e['top_positive'][0][0] if e['top_positive'] else 'none' 
                              for e in explanations],
            'primary_contribution': [e['top_positive'][0][1] if e['top_positive'] else 0 
                                    for e in explanations]
        }
        
        # åŠ å…¥å„ç‰¹å¾µçš„ SHAP å€¼ä½œç‚ºæ¬„ä½
        for feat in self.feature_names:
            df_data[f'shap_{feat}'] = [
                e['feature_contributions'].get(feat, 0) for e in explanations
            ]
        
        return pl.DataFrame(df_data)
    
    def generate_summary_plot(self, X_test: np.ndarray, output_path: str):
        """ç”¢ç”Ÿç‰¹å¾µé‡è¦æ€§æ‘˜è¦åœ–ï¼ˆä¾›å·¥ç¨‹å¸«å¯©é–±ï¼‰"""
        import matplotlib.pyplot as plt
        
        shap_values = self.explainer.shap_values(X_test)
        if isinstance(shap_values, list):
            shap_values = shap_values[0]
        
        plt.figure(figsize=(12, 8))
        self.shap.summary_plot(
            shap_values, 
            X_test, 
            feature_names=self.feature_names,
            show=False
        )
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        self.logger.info(f"SHAP æ‘˜è¦åœ–å·²å„²å­˜: {output_path}")
```

---

### Phase 4: å®Œæ•´è¨“ç·´æµç¨‹èˆ‡ç”¢å‡º (Day 8)

#### Step 4.1: å®Œæ•´è¨“ç·´æµç¨‹ï¼ˆæ•´åˆæ‰€æœ‰ v1.1 åŠŸèƒ½ï¼‰

**æª”æ¡ˆ**: `src/modeling/training_pipeline.py`ï¼ˆæ–¹æ³•æ›´æ–°ï¼‰

**å¯¦ä½œå…§å®¹**:
```python
def train(self, data: TrainingInputContract) -> 'MultiModelArtifact':
    """
    åŸ·è¡Œå®Œæ•´å¤šæ¨¡å‹è¨“ç·´æµç¨‹ (v1.1)
    
    æµç¨‹ï¼š
    1. è¼¸å…¥é©—è­‰èˆ‡å¥‘ç´„æª¢æŸ¥
    2. æ™‚åºè³‡æ–™åˆ†å‰²ï¼ˆé›¶æ´©æ¼ï¼‰
    3. Device Role æ¬Šé‡è¨ˆç®—
    4. ç‰¹å¾µå‰è™•ç†ï¼ˆç¸®æ”¾ã€ç¼ºå¤±å€¼ï¼‰
    5. è³‡æ ¼æª¢æŸ¥ï¼ˆæ¨£æœ¬æ•¸ã€è¨˜æ†¶é«”ï¼‰
    6. æ¨¡å‹è¨“ç·´ï¼ˆå¹³è¡Œæˆ–åºåˆ—ï¼‰
    7. æ¸¬è©¦é›†æœ€çµ‚è©•ä¼°
    8. å¯è§£é‡‹æ€§åˆå§‹åŒ–ï¼ˆè‹¥å•Ÿç”¨ï¼‰
    9. ç”¢å‡º MultiModelArtifact
    
    Returns:
        MultiModelArtifact: åŒ…å«ä¸‰æ¨¡å‹çµæœã€æœ€ä½³æ¨¡å‹é¸æ“‡ã€ä»¥åŠå¯è§£é‡‹æ€§ä»‹é¢
    """
    self.training_stats['start_time'] = datetime.now().isoformat()
    
    # Step 1: è¼¸å…¥é©—è­‰
    self._validate_input_contract(data)
    df = data['feature_matrix']
    target_col = data['target_variable']
    n_samples = len(df)
    
    self.logger.info(f"ğŸš€ é–‹å§‹è¨“ç·´æµç¨‹: Site={self.site_id}, Samples={n_samples}, Features={data['n_features']}")
    
    # Step 2: æ™‚åºåˆ†å‰²ï¼ˆç¢ºä¿é›¶æ´©æ¼ï¼‰
    train_df, val_df, test_df, y_train, y_val, y_test = self._temporal_split(df, target_col)
    self.logger.info(f"ğŸ“Š è³‡æ–™åˆ†å‰²: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}")
    
    # Step 3: Device Role è™•ç†
    sample_weights, seasonal_mask = self._compute_sample_weights_and_masks(train_df)
    if np.any(seasonal_mask == False):
        train_df = train_df.filter(pl.Series(seasonal_mask))
        y_train = y_train.filter(pl.Series(seasonal_mask))
        sample_weights = sample_weights[seasonal_mask]
        self.logger.info(f"ğŸ­ Seasonal Mask æ‡‰ç”¨å¾Œ: Train={len(train_df)}")
    
    # Step 4: ç‰¹å¾µå‰è™•ç†
    X_train, X_val, X_test, feature_cols = self._preprocess_features(train_df, val_df, test_df)
    
    # Step 5: å¤šæ¨¡å‹è¨“ç·´ï¼ˆè³‡æºæ„ŸçŸ¥ï¼‰
    self.train_all_models(
        X_train=X_train, y_train=y_train.to_numpy(),
        X_val=X_val, y_val=y_val.to_numpy(),
        sample_weights=sample_weights,
        feature_names=feature_cols
    )
    
    # Step 6: æ¸¬è©¦é›†æœ€çµ‚è©•ä¼°ï¼ˆåƒ…æœ€ä½³æ¨¡å‹ï¼‰
    best_name, best_trainer, best_result = self.get_best_model()
    test_metrics = best_trainer.evaluate(X_test, y_test.to_numpy())
    
    self.logger.info(
        f"ğŸ§ª æœ€ä½³æ¨¡å‹ [{best_name}] æ¸¬è©¦é›†è¡¨ç¾: "
        f"RÂ²={test_metrics['r2']:.4f}, RMSE={test_metrics['rmse']:.4f}, MAPE={test_metrics['mape']:.2f}%"
    )
    
    # Step 7: å¯è§£é‡‹æ€§åˆå§‹åŒ–ï¼ˆè‹¥å•Ÿç”¨ï¼‰
    explainer = None
    if self.config.enable_explainability:
        try:
            from src.modeling.explainability.shap_explainer import ModelExplainer
            
            explainer = ModelExplainer(
                model=best_trainer.model,
                feature_names=feature_cols,
                model_type=best_name
            )
            # ä½¿ç”¨é©—è­‰é›†ä½œç‚ºèƒŒæ™¯ï¼ˆé¿å…ä½¿ç”¨æ¸¬è©¦é›†ï¼‰
            explainer.fit_background(X_val, sample_size=self.config.shap_background_samples)
            self.logger.info("ğŸ” SHAP Explainer åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ å¯è§£é‡‹æ€§åˆå§‹åŒ–å¤±æ•—: {e}")
    
    # Step 8: å»ºç«‹ç”¢å‡ºç‰©
    self.training_stats['end_time'] = datetime.now().isoformat()
    
    artifact = MultiModelArtifact(
        trainers=self.trainers,
        results=self.results,
        best_model_name=best_name,
        test_metrics=test_metrics,
        training_metadata=self._build_training_metadata(data, test_metrics),
        annotation_context=data['annotation_context'],
        feature_names=feature_cols,
        config=self.config,
        explainer=explainer,  # v1.1 æ–°å¢
        training_stats=self.training_stats
    )
    
    return artifact
```

#### Step 4.2: å¤šæ¨¡å‹ç”¢å‡ºç‰©å®šç¾©ï¼ˆv1.1 æ›´æ–°ï¼‰

**æª”æ¡ˆ**: `src/modeling/artifacts.py`

**å¯¦ä½œå…§å®¹**:
```python
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from pathlib import Path
import json
import joblib
from datetime import datetime

@dataclass
class MultiModelArtifact:
    """
    å¤šæ¨¡å‹è¨“ç·´ç”¢å‡ºç‰© (v1.1)
    
    å„²å­˜çµæ§‹:
    models/
    â””â”€â”€ {site_id}/
        â”œâ”€â”€ {timestamp}_ensemble_manifest.json           # çµ±ä¸€å…¥å£
        â”œâ”€â”€ {timestamp}_xgboost_model.joblib
        â”œâ”€â”€ {timestamp}_xgboost_metadata.json
        â”œâ”€â”€ {timestamp}_lightgbm_model.joblib
        â”œâ”€â”€ {timestamp}_lightgbm_metadata.json
        â”œâ”€â”€ {timestamp}_random_forest_model.joblib
        â”œâ”€â”€ {timestamp}_random_forest_metadata.json
        â”œâ”€â”€ {timestamp}_shap_summary.png                 # v1.1 å¯è§£é‡‹æ€§è¼¸å‡ºï¼ˆè‹¥å•Ÿç”¨ï¼‰
        â””â”€â”€ {timestamp}_explainability_metadata.json     # v1.1 SHAP èƒŒæ™¯è³‡æ–™
    """
    
    trainers: Dict[str, BaseModelTrainer]
    results: Dict[str, Dict[str, Any]]
    best_model_name: str
    test_metrics: Dict[str, float]
    training_metadata: Dict[str, Any]
    annotation_context: Dict[str, Any]
    feature_names: List[str]
    config: ModelTrainingConfig
    explainer: Optional[Any] = None  # v1.1 SHAP explainer
    training_stats: Dict[str, Any] = field(default_factory=dict)
    
    def save(self, output_dir: Path) -> Dict[str, Path]:
        """å„²å­˜æ‰€æœ‰æ¨¡å‹ã€å…ƒè³‡æ–™èˆ‡å¯è§£é‡‹æ€§ç‰©ä»¶"""
        output_dir = Path(output_dir) / self.training_metadata['site_id']
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_files = {'ensemble_manifest': output_dir / f"{timestamp}_ensemble_manifest.json"}
        
        ensemble_data = {
            'timestamp': timestamp,
            'best_model': self.best_model_name,
            'test_metrics': self.test_metrics,
            'training_stats': self.training_stats,
            'models': {}
        }
        
        # å„²å­˜æ¯å€‹æ¨¡å‹
        for name, trainer in self.trainers.items():
            if name not in self.results or 'error' in self.results[name]:
                continue
            
            model_path = output_dir / f"{timestamp}_{name}_model.joblib"
            metadata_path = output_dir / f"{timestamp}_{name}_metadata.json"
            
            # å„²å­˜æ¨¡å‹
            joblib.dump({
                'model': trainer.model,
                'scaler': getattr(trainer, 'scaler', None),
                'feature_names': self.feature_names,
                'model_metadata': trainer.get_model_info()
            }, model_path, compress=3)  # å£“ç¸®ä»¥ç¯€çœç©ºé–“
            
            # å„²å­˜è©²æ¨¡å‹å…ƒè³‡æ–™
            model_meta = {
                'name': name,
                'metrics': self.results[name]['metrics'],
                'feature_importance': trainer.get_feature_importance(),
                'training_history': self.results[name].get('training_history', {}),
                'best_iteration': self.results[name].get('best_iteration'),
                'oob_score': self.results[name].get('oob_score'),
                'training_time': self.results[name].get('training_time', 0)
            }
            
            with open(metadata_path, 'w') as f:
                json.dump(model_meta, f, indent=2, default=str)
            
            ensemble_data['models'][name] = {
                'model_file': str(model_path.name),
                'metadata_file': str(metadata_path.name),
                'val_r2': self.results[name]['metrics']['val']['r2'],
                'test_r2': self.test_metrics['r2'] if name == self.best_model_name else None,
                'is_best': name == self.best_model_name
            }
            
            saved_files[f'{name}_model'] = model_path
            saved_files[f'{name}_metadata'] = metadata_path
        
        # å„²å­˜å¯è§£é‡‹æ€§ç‰©ä»¶ï¼ˆv1.1ï¼‰
        if self.explainer is not None and self.config.enable_explainability:
            try:
                explainer_path = output_dir / f"{timestamp}_explainer.joblib"
                joblib.dump({
                    'explainer': self.explainer.explainer,  # åº•å±¤ SHAP è§£é‡‹å™¨
                    'feature_names': self.explainer.feature_names,
                    'model_type': self.explainer.model_type,
                    'background_data': self.explainer.background_data
                }, explainer_path)
                saved_files['explainer'] = explainer_path
                ensemble_data['explainability'] = {
                    'explainer_file': str(explainer_path.name),
                    'shap_available': True
                }
                
                # ç”¢ç”Ÿæ‘˜è¦åœ–
                if hasattr(self.explainer, 'background_data'):
                    summary_path = output_dir / f"{timestamp}_shap_summary.png"
                    self.explainer.generate_summary_plot(
                        self.explainer.background_data, 
                        str(summary_path)
                    )
                    saved_files['shap_summary'] = summary_path
                
            except Exception as e:
                ensemble_data['explainability'] = {'error': str(e)}
        
        # å„²å­˜ Ensemble Manifest
        ensemble_data['training_metadata'] = self.training_metadata
        ensemble_data['annotation_context'] = self.annotation_context
        
        with open(saved_files['ensemble_manifest'], 'w') as f:
            json.dump(ensemble_data, f, indent=2, default=str)
        
        return saved_files
    
    @classmethod
    def load(cls, ensemble_manifest_path: Path, model_name: Optional[str] = None):
        """è¼‰å…¥æŒ‡å®šæ¨¡å‹æˆ–æœ€ä½³æ¨¡å‹ï¼Œä»¥åŠå¯è§£é‡‹æ€§ç‰©ä»¶ï¼ˆè‹¥å­˜åœ¨ï¼‰"""
        with open(ensemble_manifest_path, 'r') as f:
            manifest = json.load(f)
        
        model_dir = ensemble_manifest_path.parent
        
        # æ±ºå®šè¼‰å…¥å“ªå€‹æ¨¡å‹
        target_model = model_name or manifest['best_model']
        model_info = manifest['models'][target_model]
        
        # è¼‰å…¥æ¨¡å‹è³‡æ–™
        model_data = joblib.load(model_dir / model_info['model_file'])
        
        # è¼‰å…¥å¯è§£é‡‹æ€§ï¼ˆè‹¥å­˜åœ¨ï¼‰
        explainer = None
        if 'explainability' in manifest and 'explainer_file' in manifest['explainability']:
            try:
                explainer_data = joblib.load(model_dir / manifest['explainability']['explainer_file'])
                # é‡å»º explainerï¼ˆç°¡åŒ–ç‰ˆï¼Œå¯¦éš›ä½¿ç”¨æ™‚å¯èƒ½éœ€è¦é‡æ–°åˆå§‹åŒ– TreeExplainerï¼‰
                explainer = explainer_data
            except Exception as e:
                print(f"Warning: ç„¡æ³•è¼‰å…¥ explainer: {e}")
        
        return {
            'model_data': model_data,
            'manifest': manifest,
            'explainer': explainer,
            'loaded_model': target_model
        }
    
    def predict_with_explanation(self, X: np.ndarray) -> Dict[str, Any]:
        """
        é æ¸¬ä¸¦æä¾›è§£é‡‹ï¼ˆv1.1 ä¾¿åˆ©æ–¹æ³•ï¼‰
        
        Returns:
            {
                'prediction': é æ¸¬å€¼,
                'explanation': SHAP è§£é‡‹ï¼ˆè‹¥å¯ç”¨ï¼‰,
                'feature_importance': ç‰¹å¾µé‡è¦æ€§
            }
        """
        if self.best_model_name not in self.trainers:
            raise RuntimeError("æœ€ä½³æ¨¡å‹æœªè¨“ç·´")
        
        # å–å¾—é æ¸¬
        trainer = self.trainers[self.best_model_name]
        prediction = trainer.predict(X)
        
        result = {
            'prediction': prediction,
            'model_used': self.best_model_name,
            'explanation': None
        }
        
        # è‹¥å¯è§£é‡‹æ€§å¯ç”¨ï¼Œæä¾›è§£é‡‹
        if self.explainer is not None:
            try:
                explanation = self.explainer.explain_local(X)
                result['explanation'] = explanation
                result['top_drivers'] = explanation['top_positive']
            except Exception as e:
                result['explanation_error'] = str(e)
        
        return result
```

---

## 4. éŒ¯èª¤ä»£ç¢¼å°ç…§è¡¨ (Error Codes) - v1.1 æ›´æ–°

| éŒ¯èª¤ä»£ç¢¼ | åç¨± | ç™¼ç”Ÿéšæ®µ | èªªæ˜ | è™•ç†å»ºè­° |
|:---|:---|:---:|:---|:---|
| **E601** | `ANNOTATION_CONTEXT_MISSING` | Step 1.1 | ç¼ºå°‘ annotation_context | ç¢ºèª Feature Engineer v1.3+ |
| **E602** | `SCHEMA_VERSION_MISMATCH` | Step 1.1 | Annotation ç‰ˆæœ¬ä¸ç¬¦ | é‡æ–°è¨“ç·´æˆ–é™ç´š Annotation |
| **E603** | `TARGET_VARIABLE_MISSING` | Step 1.1 | ç›®æ¨™è®Šæ•¸ä¸å­˜åœ¨ | æª¢æŸ¥ç‰¹å¾µå·¥ç¨‹è¼¸å‡º |
| **E604** | `TIMESTAMP_INVALID` | Step 1.1 | æ™‚é–“æˆ³æ ¼å¼éŒ¯èª¤ | æª¢æŸ¥ Feature Engineer |
| **E607** | `INSUFFICIENT_SAMPLES` | Step 3 | æ¨£æœ¬ä¸è¶³ï¼ˆ<100ï¼‰ | æª¢æŸ¥è³‡æ–™é®ç½©é‚è¼¯ |
| **E701** | `DEVICE_ROLE_AS_FEATURE` | Step 0.1 | è¨­å®šéŒ¯èª¤å˜—è©¦å°‡ device_role ä½œç‚ºç‰¹å¾µ | ä¿®æ”¹è¨­å®š |
| **E702** | `MODEL_NOT_FITTED` | Prediction | é æ¸¬å‰æœªè¨“ç·´ | ç¢ºä¿å·²åŸ·è¡Œ train() |
| **E703** | `ALL_MODELS_FAILED` | Step 5 | ä¸‰æ¨¡å‹å…¨éƒ¨è¨“ç·´å¤±æ•— | æª¢æŸ¥è³‡æ–™å“è³ªæˆ–ç‰¹å¾µå·¥ç¨‹ |
| **E704** | `XGBOOST_IMPORT_ERROR` | Import | XGBoost æœªå®‰è£ | `pip install xgboost` |
| **E705** | `LIGHTGBM_IMPORT_ERROR` | Import | LightGBM æœªå®‰è£ | `pip install lightgbm` |
| **E706** | `SELECTION_NOT_EXECUTED` | Step 6 | å°šæœªåŸ·è¡Œæ¨¡å‹é¸æ“‡ | å…ˆåŸ·è¡Œ train_all_models() |
| **E707** | `ENSEMBLE_NO_VALID_MODEL` | Ensemble | ç„¡å¯ç”¨æ¨¡å‹é€²è¡Œ Ensemble | æª¢æŸ¥è¨“ç·´çµæœ |
| **E801** | `MEMORY_SAFETY_TRIGGERED` | Step 5 | è¨˜æ†¶é«”ä¸è¶³è‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´ | æ­£å¸¸è¡Œç‚ºï¼Œæˆ–å¢åŠ è¨˜æ†¶é«” |
| **E802** | `OPTUNA_PRUNING_EXCESSIVE` | Hyperparam | éå¤š trials è¢«å‰ªæ | æç¤ºæœå°‹ç©ºé–“å¯èƒ½éå¤§ |
| **E803** | `SHAP_BACKGROUND_TOO_LARGE` | Explain | SHAP èƒŒæ™¯è³‡æ–™éå¤§ | å·²è‡ªå‹•å–æ¨£ï¼Œå¯å¿½ç•¥ |
| **E804** | `EXPLAINER_NOT_FITTED` | Explain | æœªå…ˆåŸ·è¡Œ fit_background | å…ˆå‘¼å« fit_background() |
| **E805** | `SHAP_NOT_INSTALLED` | Import | æœªå®‰è£ shap å¥—ä»¶ | `pip install shap` |

---

## 5. æ¸¬è©¦èˆ‡é©—è­‰è¨ˆç•« (Test Plan) - v1.1 æ›´æ–°

### 5.1 å–®å…ƒæ¸¬è©¦ï¼ˆæ¯å€‹æ¨¡å‹ç¨ç«‹æ¸¬è©¦ï¼‰

| æ¸¬è©¦æ¡ˆä¾‹ ID | æè¿° | é©—è­‰ç›®æ¨™ | æ¨¡å‹ |
|:---|:---|:---:|:---:|
| MT-XGB-001 | XGBoost åŸºæœ¬è¨“ç·´ | æ”¶æ•›ã€æ—©åœç”Ÿæ•ˆã€ç‰¹å¾µé‡è¦æ€§åˆç† | XGBoost |
| MT-XGB-002 | XGBoost å°æ¨£æœ¬èª¿æ•´ | n_samples=300 æ™‚è‡ªå‹•é™åˆ¶ max_depth=3 | XGBoost |
| MT-LGB-001 | LightGBM é€Ÿåº¦æ¸¬è©¦ | ç›¸åŒè³‡æ–™è¨“ç·´æ™‚é–“ < XGBoost 50% | LightGBM |
| MT-LGB-002 | LightGBM æ¨£æœ¬é–€æª» | n_samples=500 æ™‚è‡ªå‹•è¢«æ’é™¤ | LightGBM |
| MT-RF-001 | OOB åˆ†æ•¸é©—è­‰ | OOB â‰ˆ Val Scoreï¼ˆå·®è· < 5%ï¼‰ | Random Forest |
| MT-RF-002 | é æ¸¬å€é–“è¼¸å‡º | lower < mean < upperï¼Œstd > 0 | Random Forest |
| MT-RF-003 | RF å¢é‡å­¸ç¿’ | warm_start å¢åŠ æ¨¹æ•¸é‡å¾Œæ€§èƒ½æå‡ | Random Forest |
| MT-RES-001 | è¨˜æ†¶é«”æª¢æŸ¥ | æ¨¡æ“¬ä½è¨˜æ†¶é«”ç’°å¢ƒè‡ªå‹•åˆ‡æ›åºåˆ—æ¨¡å¼ | ResourceManager |
| MT-RES-002 | æ¨£æœ¬åˆ†ç´š | n_samples=200 æ™‚åƒ… RF è¢«å•Ÿç”¨ | Config |

### 5.2 æ•´åˆæ¸¬è©¦ï¼ˆv1.1 å¼·åŒ–ï¼‰

| æ¸¬è©¦æ¡ˆä¾‹ ID | æè¿° | é©—è­‰ç›®æ¨™ |
|:---|:---|:---|
| INT-MT-001 | ä¸‰æ¨¡å‹å¹³è¡Œè¨“ç·´ | åŒæ™‚å®Œæˆï¼Œç„¡è¨˜æ†¶é«”è¡çªï¼ŒResourceManager æ­£ç¢ºä¼°ç®— |
| INT-MT-002 | HVAC çœŸå¯¦è³‡æ–™æ¸¬è©¦ | è‡³å°‘ä¸€æ¨¡å‹é”åˆ° RÂ² > 0.85 |
| INT-MT-003 | Device Role æ¬Šé‡å½±éŸ¿ | Backup æ¨£æœ¬æ¬Šé‡èª¿æ•´å¾Œï¼Œæ¨¡å‹é æ¸¬ç©©å®š |
| INT-MT-004 | ç‰ˆæœ¬ç¶å®šé©—è­‰ | å„²å­˜çš„ Manifest åŒ…å«æ­£ç¢º yaml_checksum |
| INT-MT-005 | OOM é˜²è­·æ¸¬è©¦ | é™åˆ¶å®¹å™¨è¨˜æ†¶é«” 2GBï¼Œç¢ºèªè‡ªå‹•é™ç´šä¸å´©æ½° |
| INT-MT-006 | å¤œé–“å„ªåŒ–æ¨¡å¼ | åŸ·è¡Œ OvernightOptimizerï¼Œç¢ºèªæ–·é»çºŒå‚³èˆ‡ Pruning |
| INT-MT-007 | SHAP å¯è§£é‡‹æ€§ | ç”¢ç”Ÿè§£é‡‹ä¸¦é©—è­‰ top driver åˆç†æ€§ |

---

## 6. ç‰ˆæœ¬ç›¸å®¹æ€§èˆ‡ä¾è³´

### 6.1 Python å¥—ä»¶ä¾è³´

```toml
[project.optional-dependencies]
modeling = [
    "xgboost>=1.7.0",      # æ”¯æ´ early stopping callback
    "lightgbm>=4.0.0",     # æ–°ç‰ˆ API
    "scikit-learn>=1.3.0", # Random Forest, è©•ä¼°æŒ‡æ¨™
    "optuna>=3.0.0",       # è¶…åƒæ•¸æœå°‹ï¼ˆå¤œé–“æ¨¡å¼ï¼‰
    "joblib>=1.3.0",       # æ¨¡å‹å„²å­˜
    "psutil>=5.9.0",       # v1.1 æ–°å¢ï¼šè¨˜æ†¶é«”ç›£æ§
    "shap>=0.42.0",        # v1.1 å¯é¸ï¼šå¯è§£é‡‹æ€§
    "matplotlib>=3.7.0",   # v1.1 å¯é¸ï¼šSHAP ç¹ªåœ–
]
```

### 6.2 ç¡¬é«”å»ºè­°èˆ‡è³‡æºé…ç½®

| è¨“ç·´æ¨¡å¼ | è¨˜æ†¶é«”éœ€æ±‚ | CPU æ ¸å¿ƒ | å»ºè­°æ™‚æ®µ | é©ç”¨å ´æ™¯ |
|:---|:---:|:---:|:---:|:---|
| **æ—¥é–“å¿«é€Ÿ** | 4GB+ | 4-8 | ä»»ä½•æ™‚é–“ | ä¾‹è¡Œæ¨¡å‹æ›´æ–°ã€å°æ¨£æœ¬èª¿è©¦ |
| **å¹³è¡Œå…¨æ¨¡å‹** | 16GB+ | 8+ | é›¢å³°æ™‚æ®µ | å¤§è¦æ¨¡è³‡æ–™å…¨é‡é‡è¨“ |
| **å¤œé–“æ·±åº¦å„ªåŒ–** | 8GB+ | 4+ | 00:00-06:00 | è¶…åƒæ•¸æœå°‹ã€æ¨¡å‹èª¿æ•™ |

---

## 7. é©—æ”¶ç°½æ ¸ (Sign-off Checklist) - v1.1

- [ ] **ä¸‰æ¨¡å‹å¯¦ä½œ**: XGBoostã€LightGBMã€Random Forest çš†å¯ç¨ç«‹è¨“ç·´
- [ ] **å‹•æ…‹è³‡æ ¼æª¢æŸ¥**: æ¨£æœ¬æ•¸ 300 æ™‚åƒ…å•Ÿç”¨ RF èˆ‡ XGBï¼ˆé™åˆ¶æ·±åº¦ï¼‰
- [ ] **è¨˜æ†¶é«”ä¿è­·**: åœ¨ 4GB é™åˆ¶ä¸‹è‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´ï¼Œç„¡ OOM
- [ ] **æ¨£æœ¬æ¬Šé‡**: ä¸‰æ¨¡å‹çš†æ­£ç¢ºè™•ç† Device Role æ¬Šé‡ï¼ˆBackup=0.3ï¼‰
- [ ] **ç‰¹å¾µé‡è¦æ€§**: æ¯å€‹æ¨¡å‹è¼¸å‡ºæ¨™æº–åŒ–é‡è¦æ€§ï¼ˆç¸½å’Œç‚º1ï¼‰
- [ ] **RF å€é–“é æ¸¬**: Random Forest æ”¯æ´ `predict_with_interval()` è¼¸å‡º Q10/Q90
- [ ] **è‡ªå‹•æ¨¡å‹é¸æ“‡**: ä¾ Val RÂ² èˆ‡ OOB å·®è·ç¶œåˆè©•åˆ†é¸æ“‡æœ€ä½³æ¨¡å‹
- [ ] **éŒ¯èª¤éš”é›¢**: å–®ä¸€æ¨¡å‹å¤±æ•—ä¸å½±éŸ¿å…¶ä»–æ¨¡å‹è¨“ç·´èˆ‡æœ€çµ‚ç”¢å‡º
- [ ] **ç‰ˆæœ¬ç¶å®š**: å„²å­˜çš„ Manifest åŒ…å« Annotation yaml_checksum
- [ ] **å¤œé–“å„ªåŒ–å™¨**: OvernightOptimizer æ”¯æ´æ–·é»çºŒå‚³èˆ‡ Trial Pruning
- [ ] **å¯è§£é‡‹æ€§é ç•™**: MultiModelArtifact æ”¯æ´ `predict_with_explanation()`ï¼ˆè‹¥å•Ÿç”¨ SHAPï¼‰
- [ ] **å¢é‡å­¸ç¿’é ç•™**: BaseModelTrainer åŒ…å« `partial_fit()` ä»‹é¢ï¼ˆRF å·²å¯¦ä½œï¼‰

---

## 8. é™„éŒ„

### Appendix A: è³‡æºç®¡ç†æ±ºç­–æµç¨‹åœ–

```
é–‹å§‹è¨“ç·´
    â†“
æª¢æŸ¥æ¨£æœ¬æ•¸ n_samples
    â†“
ä¾ min_samples_threshold ç¯©é¸å¯ç”¨æ¨¡å‹
    â†“
ä¼°ç®—è¨˜æ†¶é«”éœ€æ±‚ï¼ˆä¾æ¨¡å‹é¡å‹ï¼‰
    â†“
æª¢æŸ¥å¯ç”¨è¨˜æ†¶é«” < éœ€æ±‚ Ã— 1.5ï¼Ÿ
    â”œâ”€ æ˜¯ â†’ parallel_training = True â†’ å¹³è¡Œè¨“ç·´
    â””â”€ å¦ â†’ auto_fallback = Trueï¼Ÿ
              â”œâ”€ æ˜¯ â†’ parallel_training = False â†’ åºåˆ—è¨“ç·´
              â””â”€ å¦ â†’ æ‹‹å‡º E801 éŒ¯èª¤
```

### Appendix B: è¶…åƒæ•¸æœå°‹ä½¿ç”¨æŒ‡å—

```python
# æ—¥é–“å¿«é€Ÿæ¨¡å¼ï¼ˆä½¿ç”¨é è¨­åƒæ•¸ï¼‰
config = ModelTrainingConfig(
    enable_hyperparameter_search=False,
    parallel_training=True
)

# å¤œé–“æ·±åº¦å„ªåŒ–æ¨¡å¼
config = ModelTrainingConfig(
    enable_hyperparameter_search=True,
    hyperparameter_mode='overnight_deep',
    hyperparameter_trials=100,
    hyperparameter_timeout=7200  # 2 å°æ™‚
)

# åŸ·è¡Œå„ªåŒ–ï¼ˆå»ºè­°ä½¿ç”¨æ’ç¨‹ä»»å‹™æ–¼å‡Œæ™¨åŸ·è¡Œï¼‰
optimizer = OvernightOptimizer(config)
results = optimizer.optimize_all_models_sequentially(data)

# æ‡‰ç”¨æœ€ä½³åƒæ•¸åˆ°æ—¥é–“é…ç½®
for model_name, result in results['models'].items():
    if 'best_params' in result:
        setattr(config, model_name, result['best_params'])
```

---

**é—œéµè¨­è¨ˆç¢ºèª (v1.1)**:
1. **é˜²ç¦¦æ€§ç¨‹å¼è¨­è¨ˆ**: å‹•æ…‹è¨˜æ†¶é«”æª¢æŸ¥èˆ‡å°æ¨£æœ¬é–€æª»é˜²æ­¢ Runtime Crash
2. **è³‡æºåˆ†å±¤**: å€åˆ†æ—¥é–“å¿«é€Ÿèˆ‡å¤œé–“æ·±åº¦å„ªåŒ–ï¼Œé¿å…å½±éŸ¿æ—¥é–“æœå‹™
3. **å¯è§£é‡‹æ€§å°±ç·’**: SHAP æ•´åˆæ¶æ§‹é ç•™ï¼Œæ»¿è¶³ HVAC å·¥ç¨‹å¸«æ¥­å‹™éœ€æ±‚
4. **æ¼”ç®—æ³•é©é…**: ä¾ Leaf-wise/Level-wise ç‰¹æ€§è¨­å®šä¸åŒé–€æª»ï¼Œé¿å… LightGBM éæ“¬åˆ
5. **ç”Ÿç”¢ç©©å®šæ€§**: åºåˆ—é™ç´šã€éŒ¯èª¤éš”é›¢ã€æ–·é»çºŒå‚³ç¢ºä¿ 24/7 é‹ä½œ