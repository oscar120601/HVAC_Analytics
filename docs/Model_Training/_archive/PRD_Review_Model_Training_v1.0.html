<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>PRD_Review_Model_Training_v1.0</title>

<style>
body {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
    font-size: 16px;
    line-height: 1.5;
    word-wrap: break-word;
    color: #24292e;
    background-color: #fff;
    max-width: 900px;
    margin: 0 auto;
    padding: 2rem;
}
h1, h2, h3, h4, h5, h6 {
    margin-top: 24px;
    margin-bottom: 16px;
    font-weight: 600;
    line-height: 1.25;
}
h1 { font-size: 2em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
h2 { font-size: 1.5em; border-bottom: 1px solid #eaecef; padding-bottom: 0.3em; }
h3 { font-size: 1.25em; }
code {
    padding: 0.2em 0.4em;
    margin: 0;
    font-size: 85%;
    background-color: #f6f8fa;
    border-radius: 6px;
    font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, monospace;
}
pre {
    padding: 16px;
    overflow: auto;
    font-size: 85%;
    line-height: 1.45;
    background-color: #f6f8fa;
    border-radius: 6px;
}
pre code {
    display: inline;
    padding: 0;
    margin: 0;
    overflow: visible;
    line-height: inherit;
    word-wrap: normal;
    background-color: initial;
    border: 0;
}
blockquote {
    padding: 0 1em;
    color: #6a737d;
    border-left: 0.25em solid #dfe2e5;
    margin: 0;
}
table {
    display: block;
    width: 100%;
    margin-top: 0;
    margin-bottom: 16px;
    overflow: auto;
    border-spacing: 0;
    border-collapse: collapse;
}
table th, table td {
    padding: 6px 13px;
    border: 1px solid #dfe2e5;
}
table tr {
    background-color: #fff;
    border-top: 1px solid #c6cbd1;
}
table tr:nth-child(2n) {
    background-color: #f6f8fa;
}
a { color: #0366d6; text-decoration: none; }
a:hover { text-decoration: underline; }
hr {
    height: 0.25em;
    padding: 0;
    margin: 24px 0;
    background-color: #e1e4e8;
    border: 0;
}
</style>

</head>
<body>
<h1 id="model-training-prd-v10">Model Training PRD (v1.0) 審查與評鑑報告</h1>
<p><strong>審查對象</strong>: <code>docs/MODEL_TRAINING/PRD_MODEL_TRAINING_v1.0.md</code><br />
<strong>審查者</strong>: Senior Data Architect / AI Lead<br />
<strong>日期</strong>: 2026-02-13<br />
<strong>總體評級</strong>: <strong>S (Excellent)</strong> - 架構嚴謹，與上游整合度極高，適合大規模部署。</p>
<hr />
<h2 id="1-overall-assessment">1. 總體評鑑 (Overall Assessment)</h2>
<p>這份 PRD 展示了極高水準的系統架構設計，完美地將機器學習的最佳實踐（Best Practices）與本專案的特殊需求（HVAC 物理特性、SSOT 架構）結合。</p>
<h3 id="key-strengths">✅ 核心優勢 (Key Strengths)</h3>
<ol>
<li><strong>多模型競賽架構 (Champion-Challenger Strategy)</strong>:<ul>
<li>同時支援 XGBoost (精度)、LightGBM (速度)、Random Forest (鲁棒性)，並自動選擇最佳模型。這對於 HVAC 領域非常關鍵，因為不同案場的資料特性差異巨大，單一模型往往難以通吃。</li>
</ul>
</li>
<li><strong>與 Feature Annotation 深度整合</strong>:<ul>
<li>不僅是被動接收資料，更主動利用 <code>device_role</code> 進行樣本加權 (Sample Weighting) 與分層，這是領域知識 (Domain Knowledge) 結合 AI 的典範。</li>
<li>嚴格的版本綁定 (<code>annotation_context</code>) 確保了模型的可追溯性 (Reproducibility)。</li>
</ul>
</li>
<li><strong>零資料洩漏 (Zero Data Leakage)</strong>:<ul>
<li>嚴格的 <code>temporal_cutoff</code> 檢查與輸入契約驗證，從源頭杜絕了由未來資料導致的模型虛高 (Look-ahead Bias)。</li>
</ul>
</li>
<li><strong>工程化思維</strong>:<ul>
<li>包含 <code>ProcessPoolExecutor</code> 平行訓練、記憶體優化 (LightGBM Dataset)、以及完整的錯誤代碼體系 (E6xx/E7xx)，展現了對生產環境穩定性的重視。</li>
</ul>
</li>
</ol>
<h3 id="risks-challenges">⚠️ 潛在風險與挑戰 (Risks &amp; Challenges)</h3>
<p>雖然架構優秀，但在實際落地時仍有以下挑戰：</p>
<table>
<thead>
<tr>
<th style="text-align: left;">風險項目</th>
<th style="text-align: left;">影響</th>
<th style="text-align: left;">建議緩解措施</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>記憶體爆炸 (OOM)</strong></td>
<td style="text-align: left;">平行訓練 3 個模型（尤其是 Random Forest 與 XGBoost）極耗記憶體，可能導致 Container 崩潰。</td>
<td style="text-align: left;">1. 實作動態資源檢測，記憶體不足時自動降級為序列訓練。<br>2. 限制 <code>n_jobs</code>，避免 CPU 搶佔。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>可解釋性不足</strong></td>
<td style="text-align: left;">目前僅輸出 Feature Importance (Gain/Split)，這對於現場工程師來說不夠直觀（他們想知道"為什麼預測這台主機耗電高？"）。</td>
<td style="text-align: left;"><strong>建議 v1.1 加入 SHAP (SHapley Additive exPlanations)</strong> 整合，提供單筆預測的歸因分析。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>超參數搜尋複雜度</strong></td>
<td style="text-align: left;">PRD 雖提及 Optuna，但在 Phase 2 實作細節中較少著墨。若開啟搜尋，訓練時間將從分鐘級暴增至小時級。</td>
<td style="text-align: left;">建議將 Hyperparameter Search 獨立為一個可選的 "這一夜訓練 (Overnight Training)" 模式，日常開發使用預設參數。</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="2-detailed-review">2. 細部審查 (Detailed Review)</h2>
<h3 id="21-interface-alignment">2.1 介面契約 (Interface Alignment)</h3>
<ul>
<li><strong>輸入契約</strong>: 與 <code>FeatureEngineer v1.3-FA</code> 的輸出高度一致。特別是 <code>annotation_context</code> 的傳遞路徑（Cleaner -&gt; BP -&gt; FE -&gt; Model）非常清晰。</li>
<li><strong>錯誤處理</strong>: E6xx 系列錯誤代碼定義明確，能有效攔截上游問題。</li>
</ul>
<h3 id="22-model-configuration">2.2 模型配置 (Model Configuration)</h3>
<ul>
<li><strong>XGBoost</strong>: 預設 <code>tree_method="hist"</code> 是正確選擇，對大數據更友善。</li>
<li><strong>LightGBM</strong>: 預設 <code>boosting_type="gbdt"</code> 穩健，參數設置合理。</li>
<li><strong>Random Forest</strong>: 預設啟動 <code>oob_score</code> 是亮點，提供了額外的驗證指標。</li>
</ul>
<h3 id="23-implementation-plan">2.3 程式碼實作 (Implementation Plan)</h3>
<ul>
<li><strong>BaseModelTrainer</strong>: 抽象層設計良好，強制實作 <code>train</code>, <code>predict</code>, <code>get_feature_importance</code>，便於未來擴充其他模型（如 Neural Networks）。</li>
<li><strong>TrainingPipeline</strong>: 邏輯清晰，包含完整的訓練-評估-選擇迴圈。</li>
</ul>
<hr />
<h2 id="3-recommendations">3. 修正建議 (Recommendations)</h2>
<h3 id="31-v10">3.1 短期修正 (v1.0 實作階段)</h3>
<ol>
<li><strong>資源保護機制</strong>:<ul>
<li>在 <code>train_all_models</code> 中加入簡單的 <code>psutil</code> 檢查，若可用記憶體 &lt; 總記憶體 30%，強制切換為序列訓練 (<code>parallel_training=False</code>)。</li>
</ul>
</li>
<li><strong>資料量防護</strong>:<ul>
<li>將 E607 (n_samples &gt;= 100) 的閾值對應不同模型調整。例如 LightGBM 通常需要 &gt;1000 筆資料才能發揮優勢，否則易過擬合；RF 對小樣本較友善。</li>
</ul>
</li>
</ol>
<h3 id="32-v11">3.2 長期規劃 (v1.1+)</h3>
<ol>
<li><strong>SHAP 整合</strong>: 產出 <code>shap_summary_plot.png</code> 與 <code>shap_values.npy</code>，作為模型交付物的一部分。</li>
<li><strong>增量學習 (Incremental Learning)</strong>: 利用 XGBoost/LightGBM 的 <code>init_model</code> 或 RF 的 <code>warm_start</code>，支援新資料的快速迭代。</li>
</ol>
<hr />
<h2 id="4-conclusion">4. 結論 (Conclusion)</h2>
<p>這份文件<strong>完全適合 (Highly Suitable)</strong> 本專案。它不僅是一個執行腳本的規格書，更是一個具備容錯、稽核與自動化能力的 ML 系統藍圖。</p>
<p><strong>批准狀態</strong>: <strong>✅ APPROVED (建議採納)</strong></p>
<p>請依據此 PRD 進入開發階段，並優先實作 <code>BaseModelTrainer</code> 與 <code>TrainingPipeline</code> 骨架。</p>
</body>
</html>