# PRD v1.2: æ¨¡å‹è¨“ç·´ç®¡ç·šå¯¦ä½œæŒ‡å— (Model Training Pipeline Implementation Guide)

**æ–‡ä»¶ç‰ˆæœ¬:** v1.2 (Multi-Target Training & Optimization-Ready Architecture)  
**æ—¥æœŸ:** 2026-02-13  
**è² è²¬äºº:** Oscar Chang  
**ç›®æ¨™æ¨¡çµ„:** `src/modeling/training_pipeline.py`, `src/modeling/trainers/`, `src/modeling/coordinators/`, `src/modeling/registry/`  
**ä¸Šæ¸¸å¥‘ç´„:** `src/etl/feature_engineer.py` (v1.3-FA+, æª¢æŸ¥é» #4)  
**ä¸‹æ¸¸å¥‘ç´„:** `src/optimization/engine.py` (v1.0+, æ¨¡å‹è¨»å†Šè¡¨ä»‹é¢)  
**é—œéµæ›´æ–°:** 
- æ”¯æ´ System-Level èˆ‡ Component-Level é›™æ¨¡å¼è¨“ç·´
- æ–°å¢ BatchTrainingCoordinator è™•ç†å¤šç›®æ¨™æ‰¹æ¬¡è¨“ç·´
- æ¨™æº–åŒ– Model Registry Index æ ¼å¼ä¾› Optimization Engine è¼‰å…¥
- æ˜ç¢ºå®šç¾©èˆ‡ Optimization v1.0+ çš„ä»‹é¢å¥‘ç´„

**æ”¯æ´æ¨¡å‹:** 
- **XGBoost** (Extreme Gradient Boosting) - é«˜ç²¾åº¦ã€æ­£å‰‡åŒ–å¼·
- **LightGBM** (Light Gradient Boosting Machine) - å¤§è¦æ¨¡è³‡æ–™ã€è¨“ç·´æ¥µé€Ÿ  
- **Random Forest** (Bagging Ensemble) - é«˜é²æ£’æ€§ã€æŠ—éæ“¬åˆã€åŸºæº–æ¨¡å‹  
**é ä¼°å·¥æ™‚:** 10 ~ 12 å€‹å·¥ç¨‹å¤©ï¼ˆå« v1.1 åŸºç¤ + v1.2 å¤šç›®æ¨™å”èª¿èˆ‡è¨»å†Šè¡¨å¯¦ä½œï¼‰

---

## 1. åŸ·è¡Œç¸½ç¶±èˆ‡è¨­è¨ˆå“²å­¸

### 1.1 æ ¸å¿ƒç›®æ¨™

å»ºç«‹**ç”Ÿç”¢å°±ç·’ (Production-Ready)**ã€**è³‡æºæ„ŸçŸ¥ (Resource-Aware)**ã€**å¤šæ¨¡å‹å¹³è¡Œè¨“ç·´ (Multi-Model Training)** ä¸”**å„ªåŒ–å¼•æ“å°±ç·’ (Optimization-Ready)** çš„è¨“ç·´ç®¡ç·šï¼š

1. **é›™æ¨¡å¼è¨“ç·´æ¶æ§‹**: æ”¯æ´ System-Levelï¼ˆç³»çµ±ç¸½è€—é›»é æ¸¬ï¼‰èˆ‡ Component-Levelï¼ˆè¨­å‚™ç´šè€—é›»é æ¸¬ï¼‰å…©ç¨®æ¨¡å¼ï¼Œæ˜ç¢ºå®šç¾©èˆ‡ Optimization Engine çš„éŠœæ¥ä»‹é¢
2. **å‹•æ…‹è³‡æºç®¡ç†**: è‡ªå‹•æª¢æ¸¬è¨˜æ†¶é«”å®¹é‡ï¼Œé˜²æ­¢å¹³è¡Œè¨“ç·´å°è‡´ OOMï¼Œä¸ç©©å®šç’°å¢ƒè‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´
3. **å¤šç›®æ¨™æ‰¹æ¬¡å”èª¿**: ç•¶ Optimization Engine éœ€è¦å¤šè¨­å‚™æ¨¡å‹æ™‚ï¼Œé€é BatchTrainingCoordinator çµ±ä¸€ç®¡ç†è¨“ç·´æµç¨‹ï¼Œç¢ºä¿ç‰ˆæœ¬ä¸€è‡´æ€§
4. **é›¶è³‡æ–™æ´©æ¼ (Zero Data Leakage)**: åš´æ ¼éµå®ˆ `temporal_cutoff`ï¼Œè¨“ç·´è³‡æ–™çµ•ä¸åŒ…å«é©—è­‰/æ¸¬è©¦æœŸçš„æœªä¾†è³‡è¨Š
5. **æ¨¡å‹è¨»å†Šè¡¨æ¨™æº–åŒ–**: ç”¢å‡ºçµ±ä¸€çš„ `model_registry_index.json`ï¼Œä¾› Optimization Engine è‡ªå‹•ç™¼ç¾èˆ‡è¼‰å…¥æ¨¡å‹
6. **åˆ†å±¤è¶…åƒæ•¸å„ªåŒ–**: å€åˆ†ã€Œæ—¥é–“å¿«é€Ÿè¨“ç·´ã€èˆ‡ã€Œå¤œé–“æ·±åº¦å„ªåŒ–ã€æ¨¡å¼ï¼Œæ”¯æ´æ–·é»çºŒå‚³èˆ‡ Trial Pruning
7. **å¯è§£é‡‹æ€§é ç•™ (Explainability Ready)**: v1.2 é ç•™ SHAP æ•´åˆä»‹é¢ï¼Œæ”¯æ´å–®ç­†é æ¸¬æ­¸å› èˆ‡æ™‚é–“åºåˆ—ç‰¹å¾µè²¢ç»è¿½è¹¤
8. **ç‰ˆæœ¬å¯è¿½æº¯ (Version Traceability)**: æ¯å€‹è¨“ç·´ç”¢å‡ºçš„æ¨¡å‹å¿…é ˆç¶å®šç•¶æ™‚çš„ `schema_version`ã€`inheritance_chain` èˆ‡ `yaml_checksum`

### 1.2 è¨“ç·´æ¨¡å¼å®šç¾©ï¼ˆv1.2 æ–°å¢ï¼‰

ç‚ºäº†èˆ‡ Optimization Engine v1.0+ ç„¡ç¸«éŠœæ¥ï¼Œæœ¬ç®¡ç·šæ”¯æ´å…©ç¨®è¨“ç·´æ¨¡å¼ï¼š

#### æ¨¡å¼ Aï¼šç³»çµ±ç´šå»ºæ¨¡ (System-Level Modeling) - é è¨­æ¨è–¦
- **ç›®æ¨™è®Šæ•¸**: `system_total_kw`ï¼ˆå†°æ°´ä¸»æ©Ÿæˆ¿ç¸½è€—é›»ï¼‰
- **ç‰¹å¾µåŒ…å«**: æ‰€æœ‰è¨­å‚™ç‹€æ…‹ï¼ˆå•Ÿåœã€é »ç‡ã€è½‰é€Ÿï¼‰ã€ç’°å¢ƒæ¢ä»¶ã€ç³»çµ±ç´šç‰¹å¾µï¼ˆç¸½æµé‡ã€æº«å·®ï¼‰
- **Optimization ç”¨é€”**: ä½œç‚ºé»‘ç›’é æ¸¬å™¨ï¼Œè¼¸å…¥è¨­å‚™çµ„åˆèˆ‡åƒæ•¸ï¼Œè¼¸å‡ºç¸½è€—é›»
- **å„ªå‹¢**: è€ƒæ…®è¨­å‚™é–“è€¦åˆæ•ˆæ‡‰ï¼ˆCopula effectï¼‰ï¼Œç²¾åº¦æœ€é«˜ï¼Œç¶­è­·ç°¡å–®ï¼ˆå–®ä¸€æ¨¡å‹ï¼‰
- **æ¨¡å‹æª”æ¡ˆ**: `system_total_kw/{timestamp}_xgboost_model.joblib`

#### æ¨¡å¼ Bï¼šçµ„ä»¶ç´šå»ºæ¨¡ (Component-Level Modeling) - å¯é¸æ“´å……
- **ç›®æ¨™è®Šæ•¸**: å„è¨­å‚™è€—é›»ï¼ˆ`chiller_1_kw`, `chiller_2_kw`, `chw_pump_1_kw`, `ct_1_kw`...ï¼‰
- **ç‰¹å¾µåŒ…å«**: è¨­å‚™è‡ªèº«ç‹€æ…‹ + å±€éƒ¨ç’°å¢ƒç‰¹å¾µï¼ˆé¿å…ç‰¹å¾µæ´©æ¼ï¼‰
- **Optimization ç”¨é€”**: è¨­å‚™ç´šæ•…éšœè¨ºæ–·ã€è€—é›»ä½”æ¯”åˆ†æã€èˆ‡ç³»çµ±ç´šæ¨¡å‹äº¤å‰é©—è­‰
- **é™åˆ¶**: ç„¡æ³•æ•æ‰è¨­å‚™é–“äº¤äº’ä½œç”¨ï¼ˆå¦‚å…©å°ä¸»æ©ŸåŒæ™‚é‹è½‰çš„ç³»çµ±æ•ˆç‡æå¤±ï¼‰
- **æ¨¡å‹æª”æ¡ˆ**: `{component_id}/{timestamp}_xgboost_model.joblib`

#### æ¨¡å¼ Cï¼šæ··åˆæ¨¡å¼ (Hybrid Mode) - v1.2 æ¨è–¦æ¶æ§‹
- **System Model**: ä¸»è¦ç”¨æ–¼ Optimization Engine çš„é æ¸¬ï¼ˆç²¾åº¦å„ªå…ˆï¼‰
- **Component Models**: è¼”åŠ©ç”¨æ–¼è§£é‡‹æ€§å ±å‘Šï¼ˆé€æ˜åº¦å„ªå…ˆï¼‰ï¼Œä¸ç›´æ¥åƒèˆ‡å„ªåŒ–æ±ºç­–
- **ä¸€è‡´æ€§ç´„æŸ**: Component Models çš„åŠ ç¸½æ‡‰èˆ‡ System Model é æ¸¬å·®è· < 5%ï¼Œå¦å‰‡è§¸ç™¼è­¦å‘Š

### 1.3 ä¸‰æ¨¡å‹ç‰¹æ€§æ¯”è¼ƒèˆ‡é©ç”¨å ´æ™¯

| æ¨¡å‹ | æ¼”ç®—æ³•é¡å‹ | å„ªå‹¢ | æœ€ä½³é©ç”¨å ´æ™¯ | æœ€å°æ¨£æœ¬æ•¸ | ç‰¹å¾µé‡è¦æ€§ |
|:---|:---:|:---|:---|:---:|:---|
| **XGBoost** | Gradient Boosting (Level-wise) | ç²¾åº¦æ¥µé«˜ã€æ­£å‰‡åŒ–å¼·ã€ä¸æ˜“éæ“¬åˆ | ä¸­ç­‰è³‡æ–™é‡ (500~100è¬ç­†)ã€é«˜ç¶­åº¦ç‰¹å¾µ | 500 | Gain-based |
| **LightGBM** | Gradient Boosting (Leaf-wise) | è¨“ç·´é€Ÿåº¦æ¥µå¿«ã€è¨˜æ†¶é«”æ•ˆç‡é«˜ | å¤§è¦æ¨¡è³‡æ–™ (>10,000ç­†)ã€å³æ™‚è¨“ç·´éœ€æ±‚ | 1,000 | Split-based |
| **Random Forest** | Bagging (Parallel Trees) | æ¥µé«˜é²æ£’æ€§ã€å¤©ç„¶æ”¯æ´å¹³è¡Œé‹ç®—ã€å°ç•°å¸¸å€¼ä¸æ•æ„Ÿ | å¿«é€ŸåŸºå‡†æ¸¬è©¦ã€å°æ¨£æœ¬ (<500)ã€å«å™ªéŸ³è³‡æ–™ | 100 | Mean Decrease Impurity |

**å‹•æ…‹é¸æ“‡ç­–ç•¥**: 
- æ¨£æœ¬æ•¸ < 500ï¼šåƒ…å•Ÿç”¨ Random Forest èˆ‡ XGBoostï¼ˆé™åˆ¶æ·±åº¦ï¼‰
- æ¨£æœ¬æ•¸ 500~1,000ï¼šå•Ÿç”¨ XGBoost èˆ‡ Random Forestï¼Œç¦ç”¨ LightGBM
- æ¨£æœ¬æ•¸ > 1,000ï¼šä¸‰æ¨¡å‹å…¨å•Ÿç”¨ï¼Œä¾ Val RÂ² è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹æˆ–ä¿ç•™ Ensemble

---

## 2. ä»‹é¢å¥‘ç´„è¦ç¯„ (Interface Contracts)

### 2.1 è¼¸å…¥å¥‘ç´„ (Input Contract from Feature Engineer v1.3)

**æª¢æŸ¥é» #7: Feature Engineer â†’ Model Training**

```python
class TrainingInputContract(BaseModel):
    """æ¨¡å‹è¨“ç·´è¼¸å…¥è³‡æ–™è¦ç¯„"""
    
    # 1. ç‰¹å¾µçŸ©é™£ (ä¾†è‡ª Feature Engineer)
    feature_matrix: pl.DataFrame
    
    # 2. ç›®æ¨™è®Šæ•¸è³‡è¨Šï¼ˆv1.2 æ“´å……ç‚ºå¤šç›®æ¨™æ”¯æ´ï¼‰
    target_variable: str  # å‘å¾Œç›¸å®¹ï¼šå–®ç›®æ¨™æ™‚ä½¿ç”¨
    target_variables: Optional[List[str]] = None  # v1.2 æ–°å¢ï¼šå¤šç›®æ¨™æ‰¹æ¬¡è¨“ç·´
    target_metadata: Dict[str, FeatureMetadata]  # v1.2 ä¿®æ”¹ï¼šæ”¹ç‚º Dict æ”¯æ´å¤šç›®æ¨™
    
    # 3. æ™‚é–“æˆ³è¨˜
    timestamp_col: str = "timestamp"
    time_range: Dict[str, str]
    
    # 4. Annotation ä¸Šä¸‹æ–‡ï¼ˆç‰ˆæœ¬ç¶å®šï¼‰
    annotation_context: Dict = {
        "schema_version": "1.2",
        "inheritance_chain": "base -> cgmh_ty",
        "yaml_checksum": "sha256:abc123...",
        "group_policies_applied": ["chillers", "towers"],
        "feature_engineer_version": "1.3-FA"
    }
    
    # 5. ç‰¹å¾µå…ƒè³‡æ–™ï¼ˆä¸å« device_roleï¼‰
    feature_metadata: Dict[str, FeatureMetadata]
    
    # 6. Quality Flag ç‰¹å¾µåˆ—è¡¨
    quality_flag_features: List[str]
    
    # 7. é˜² Data Leakage è³‡è¨Š
    train_test_split_info: Dict = {
        "temporal_cutoff": "2025-10-01T00:00:00Z",
        "strict_past_only": True
    }
    
    # 8. æ¨£æœ¬æ¬Šé‡å»ºè­°ï¼ˆå¯é¸ï¼‰
    suggested_sample_weights: Optional[pl.Series] = None
    
    # 9. è³‡æ–™è¦æ¨¡æ¨™è¨˜ï¼ˆç”¨æ–¼æ¨¡å‹é¸æ“‡å»ºè­°ï¼‰
    n_samples: int
    n_features: int
    
    # 10. è¨“ç·´æ¨¡å¼æ§åˆ¶ï¼ˆv1.2 æ–°å¢ï¼‰
    training_mode: Literal["single_target", "multi_target", "hybrid"] = "single_target"
    model_naming_map: Optional[Dict[str, str]] = None  # {"chiller_1_kw": "chiller_1_model"}
    output_structure: Literal["flat", "hierarchical"] = "hierarchical"  # v1.2 é è¨­æ”¹ç‚º hierarchical
```

| æª¢æŸ¥é … | è¦æ ¼ | éŒ¯èª¤ä»£ç¢¼ | è™•ç† |
|:---|:---|:---:|:---|
| **Annotation Context å­˜åœ¨æ€§** | å¿…é ˆéç©ºä¸”åŒ…å« `schema_version`, `inheritance_chain`, `yaml_checksum` | E601 | æ‹’çµ•è¨“ç·´ |
| **Schema ç‰ˆæœ¬ç›¸å®¹** | `schema_version` å¿…é ˆç­‰æ–¼ç•¶å‰ `FEATURE_ANNOTATION_CONSTANTS['expected_schema_version']` | E602 | æ‹’çµ•è¨“ç·´ |
| **ç›®æ¨™è®Šæ•¸å­˜åœ¨** | `target_variable` å¿…é ˆå­˜åœ¨æ–¼ `feature_matrix` æ¬„ä½ä¸­ | E603 | æ‹’çµ•è¨“ç·´ |
| **æ™‚é–“æˆ³å‹åˆ¥** | `timestamp` å¿…é ˆç‚º `Datetime(ns, UTC)` | E604 | æ‹’çµ•è¨“ç·´ |
| **è³‡æ–™è¦æ¨¡æª¢æŸ¥** | `n_samples` å¿…é ˆ >= 100ï¼ˆRandom Forest æœ€ä½éœ€æ±‚ï¼‰ | E607 | æ‹’çµ•è¨“ç·´ |
| **å¤šç›®æ¨™ä¸€è‡´æ€§** (v1.2 æ–°å¢) | `multi_target` æ¨¡å¼ä¸‹æ‰€æœ‰ targets å¿…é ˆä½¿ç”¨ç›¸åŒçš„ `annotation_context` | E901 | æ‹’çµ•è¨“ç·´ |

### 2.2 è¼¸å‡ºå¥‘ç´„ (Output Contract to Optimization Engine v1.0+)

**æª¢æŸ¥é» #9: Model Training â†’ Optimization Engine**

ç‚ºç¢ºä¿ Optimization Engine èƒ½æ­£ç¢ºè¼‰å…¥èˆ‡ä½¿ç”¨æ¨¡å‹ï¼Œv1.2 æ¨™æº–åŒ–ä»¥ä¸‹è¼¸å‡ºçµæ§‹ï¼š

```python
class ModelRegistryIndex(BaseModel):
    """
    æ¨¡å‹è¨»å†Šè¡¨ç´¢å¼•ï¼ˆv1.2 æ–°å¢ï¼‰
    å„²å­˜æ–¼ models/{site_id}/model_registry_index.json
    ä¾› Optimization Engine è‡ªå‹•ç™¼ç¾æ¨¡å‹
    """
    
    schema_version: str = "1.2"
    site_id: str
    training_timestamp: str  # ISO 8601
    annotation_checksum: str  # èˆ‡ Feature Annotation ç¶å®š
    
    # è¨“ç·´æ¨¡å¼æ¨™è¨˜
    training_mode: Literal["system_level", "component_level", "hybrid"]
    
    # å¯ç”¨æ¨¡å‹åˆ—è¡¨
    available_models: Dict[str, ModelEntry] = {
        "system_total_kw": {
            "type": "system_level",
            "path": "system_total_kw/20260213_120000_xgboost_model.joblib",
            "manifest_path": "system_total_kw/20260213_120000_ensemble_manifest.json",
            "target_variable": "total_kw",
            "feature_count": 42,
            "best_algorithm": "xgboost",
            "metrics": {"val_r2": 0.92, "test_r2": 0.89},
            "checksum": "sha256:def456..."
        },
        "chiller_1_kw": {
            "type": "component_level",
            "path": "chiller_1_kw/20260213_120000_xgboost_model.joblib",
            "optional": True,  # è‹¥ç‚º hybrid æ¨¡å¼ï¼Œcomponent models æ¨™è¨˜ç‚º optional
            "parent_system_model": "system_total_kw"  # é—œè¯çš„ç³»çµ±ç´šæ¨¡å‹
        }
    }
    
    # ç›¸å®¹æ€§è³‡è¨Š
    compatibility: Dict = {
        "optimization_engine_min_version": "1.0",
        "feature_annotation_version": "1.2",
        "python_version": "3.10+",
        "required_packages": ["xgboost>=1.7", "lightgbm>=4.0", "scikit-learn>=1.3"]
    }

class ModelEntry(BaseModel):
    """å–®ä¸€æ¨¡å‹æ¢ç›®"""
    type: Literal["system_level", "component_level"]
    path: str  # ç›¸å°æ–¼ site_id æ ¹ç›®éŒ„çš„è·¯å¾‘
    manifest_path: Optional[str] = None  # Ensemble manifest è·¯å¾‘ï¼ˆè‹¥ç‚º ensembleï¼‰
    target_variable: str
    feature_count: int
    best_algorithm: str
    metrics: Dict[str, float]  # val_r2, test_r2, rmse, mape
    checksum: str  # æ¨¡å‹æª”æ¡ˆ SHA256
    optional: bool = False  # è‹¥ç‚º Trueï¼ŒOptimization Engine å¯é¸æ“‡æ€§è¼‰å…¥
    parent_system_model: Optional[str] = None  # ç”¨æ–¼ hybrid æ¨¡å¼çš„é—œè¯
```

**æ¨¡å‹å„²å­˜çµæ§‹ï¼ˆv1.2 æ¨™æº–åŒ–ï¼‰**ï¼š
```
models/
â””â”€â”€ {site_id}/
    â”œâ”€â”€ model_registry_index.json          # ç¸½ç´¢å¼•ï¼ˆOptimization Engine å…¥å£ï¼‰
    â”œâ”€â”€ system_total_kw/                   # System-Level æ¨¡å‹ç›®éŒ„
    â”‚   â”œâ”€â”€ 20260213_120000_xgboost_model.joblib
    â”‚   â”œâ”€â”€ 20260213_120000_lightgbm_model.joblib
    â”‚   â”œâ”€â”€ 20260213_120000_random_forest_model.joblib
    â”‚   â”œâ”€â”€ 20260213_120000_ensemble_manifest.json
    â”‚   â”œâ”€â”€ 20260213_120000_shap_summary.png
    â”‚   â””â”€â”€ 20260213_120000_metadata.json
    â”œâ”€â”€ chiller_1_kw/                      # Component-Level æ¨¡å‹ç›®éŒ„ï¼ˆå¯é¸ï¼‰
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ chiller_2_kw/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ chw_pump_1_kw/
        â””â”€â”€ ...
```

---

## 3. åˆ†éšæ®µå¯¦ä½œè¨ˆç•« (Phase-Based Implementation)

### Phase 0: åŸºç¤å»ºè¨­èˆ‡å¤šæ¨¡å‹æ¶æ§‹ (Day 1-2)

#### Step 0.1: çµ±ä¸€è¨“ç·´é…ç½®æ¨¡å‹ï¼ˆv1.2 æ“´å……ç‰ˆï¼‰

**æª”æ¡ˆ**: `src/modeling/config_models.py`

**å¯¦ä½œå…§å®¹**:
```python
from typing import Dict, List, Optional, Literal, Final, Union, Tuple, Any
from pydantic import BaseModel, Field, validator, root_validator
from datetime import datetime
import logging

from src.etl.config_models import (
    VALID_QUALITY_FLAGS,
    TIMESTAMP_CONFIG,
    FEATURE_ANNOTATION_CONSTANTS
)

EXPECTED_SCHEMA_VERSION: Final[str] = FEATURE_ANNOTATION_CONSTANTS['expected_schema_version']

# ==========================================
# æ¨¡å‹ç‰¹å®šè¶…åƒæ•¸é…ç½®ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼‰
# ==========================================

class XGBoostConfig(BaseModel):
    """XGBoost å°ˆå±¬é…ç½® - Level-wise ç”Ÿé•·ç­–ç•¥ï¼Œç²¾åº¦å°å‘"""
    n_estimators: int = 1000
    learning_rate: float = 0.05
    max_depth: int = 6
    min_child_weight: int = 1
    subsample: float = 0.8
    colsample_bytree: float = 0.8
    reg_alpha: float = 0.1  # L1 æ­£å‰‡
    reg_lambda: float = 1.0  # L2 æ­£å‰‡
    gamma: float = 0  # ç¯€é»åˆ†è£‚æœ€å°æå¤±æ¸›å°‘
    early_stopping_rounds: int = 50
    eval_metric: str = "rmse"
    tree_method: str = "hist"  # 'exact', 'approx', 'hist'
    
    # å°æ¨£æœ¬é©æ‡‰ï¼ˆç•¶ n_samples < 500 æ™‚è‡ªå‹•èª¿æ•´ï¼‰
    small_sample_adjustments: Dict[str, Any] = {
        "max_depth": 3,
        "min_child_weight": 5,
        "subsample": 0.9
    }
    
    # é€²éšåŠŸèƒ½
    enable_monotonic_constraints: bool = False
    monotone_constraints: Optional[Dict[str, int]] = None

class LightGBMConfig(BaseModel):
    """LightGBM å°ˆå±¬é…ç½® - Leaf-wise ç”Ÿé•·ç­–ç•¥ï¼Œé€Ÿåº¦å°å‘"""
    n_estimators: int = 1000
    learning_rate: float = 0.05
    num_leaves: int = 31  # æ§åˆ¶æ¨¡å‹è¤‡é›œåº¦ï¼Œç›¸ç•¶æ–¼ 2^max_depth
    max_depth: int = -1  # -1 è¡¨ç¤ºç„¡é™åˆ¶ï¼Œç”± num_leaves æ§åˆ¶
    min_child_samples: int = 20
    subsample: float = 0.8
    colsample_bytree: float = 0.8
    reg_alpha: float = 0.1
    reg_lambda: float = 1.0
    early_stopping_rounds: int = 50
    eval_metric: str = "rmse"
    boosting_type: str = "gbdt"  # 'gbdt', 'dart', 'goss'
    
    # å¤§è¦æ¨¡è³‡æ–™å„ªåŒ–
    feature_pre_filter: bool = False
    histogram_pool_size: Optional[int] = None  # è¨˜æ†¶é«”é™åˆ¶æ™‚è¨­å®š

class RandomForestConfig(BaseModel):
    """Random Forest å°ˆå±¬é…ç½® - Bagging ç­–ç•¥ï¼Œé²æ£’æ€§å°å‘"""
    n_estimators: int = 500
    max_depth: Optional[int] = None  # None è¡¨ç¤ºå®Œå…¨ç”Ÿé•·
    min_samples_split: int = 5
    min_samples_leaf: int = 2
    max_features: str = "sqrt"  # 'sqrt', 'log2', None
    bootstrap: bool = True
    oob_score: bool = True  # Out-of-Bag é©—è­‰
    n_jobs: int = -1  # ä½¿ç”¨æ‰€æœ‰ CPU
    warm_start: bool = False  # å¯å¢é‡è¨“ç·´ï¼ˆv1.2 ä½¿ç”¨ï¼‰
    
    # å€é–“é æ¸¬ï¼ˆä½¿ç”¨æ¨¹çš„è‘‰ç¯€é»çµ±è¨ˆï¼‰
    quantile_regression: bool = False  # è‹¥å•Ÿç”¨ï¼Œè¨“ç·´ä¸‰å€‹æ¨¡å‹ (Q10, Q50, Q90)

# ==========================================
# è³‡æºç®¡ç†é…ç½®ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼‰
# ==========================================

class ResourceConfig(BaseModel):
    """ç¡¬é«”è³‡æºèˆ‡è¨˜æ†¶é«”ç®¡ç†é…ç½®"""
    
    # è¨˜æ†¶é«”å®‰å…¨é–¾å€¼
    memory_safety_threshold: float = 0.3  # ä¿ç•™ 30% ç³»çµ±è¨˜æ†¶é«”ä½œç‚ºç·©è¡
    parallel_training: bool = True  # æ˜¯å¦å˜—è©¦ä¸¦è¡Œè¨“ç·´
    max_parallel_workers: int = 3  # æœ€å¤§å¹³è¡Œå·¥ä½œé€²ç¨‹
    
    # å‹•æ…‹é™ç´šç­–ç•¥
    auto_fallback_to_sequential: bool = True  # è¨˜æ†¶é«”ä¸è¶³æ™‚è‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´
    memory_check_before_training: bool = True  # è¨“ç·´å‰å¼·åˆ¶æª¢æŸ¥è¨˜æ†¶é«”
    
    # å°æ¨£æœ¬è™•ç†
    small_sample_fallback: Literal['disable_lightgbm', 'use_rf_only', 'abort'] = 'disable_lightgbm'
    
    # v1.2 æ–°å¢ï¼šæ‰¹æ¬¡è¨“ç·´è³‡æºæ§åˆ¶
    batch_training_memory_limit: float = 0.8  # æ‰¹æ¬¡è¨“ç·´æ™‚å–®ä¸€æ¨¡å‹è¨˜æ†¶é«”ä¸Šé™
    max_concurrent_targets: int = 2  # åŒæ™‚è¨“ç·´çš„æœ€å¤§ç›®æ¨™æ•¸ï¼ˆé˜²æ­¢ OOMï¼‰
    
    @validator('memory_safety_threshold')
    def validate_threshold(cls, v):
        if not 0.1 <= v <= 0.8:
            raise ValueError("è¨˜æ†¶é«”å®‰å…¨é–¾å€¼å¿…é ˆåœ¨ 0.1~0.8 ä¹‹é–“")
        return v

# ==========================================
# è¨“ç·´ç®¡ç·šä¸»é…ç½®ï¼ˆv1.2 æ“´å……ï¼‰
# ==========================================

class ModelTrainingConfig(BaseModel):
    """æ¨¡å‹è¨“ç·´çµ±ä¸€é…ç½®ï¼ˆv1.2 å¤šç›®æ¨™ç‰ˆï¼‰"""
    
    # åŸºæœ¬é…ç½®
    random_state: int = 42
    site_id: str = "default"  # v1.2 æ–°å¢ï¼šæ˜ç¢ºç¶å®šæ¡ˆå ´
    
    # æ™‚åºé…ç½®
    temporal_split: TemporalSplitConfig = TemporalSplitConfig()
    
    # Device Role è™•ç†
    device_role_handling: DeviceRoleHandlingConfig = DeviceRoleHandlingConfig()
    
    # ç‰¹å¾µå·¥ç¨‹ï¼ˆè¨“ç·´æœŸï¼‰
    handle_missing_values: Literal["drop", "impute_mean", "impute_median"] = "impute_median"
    scale_features: bool = True
    
    # Quality Flags è™•ç†
    use_quality_flags_as_features: bool = True
    exclude_bad_quality_samples: bool = True
    
    # ä¸‰æ¨¡å‹é…ç½®
    xgboost: XGBoostConfig = XGBoostConfig()
    lightgbm: LightGBMConfig = LightGBMConfig()
    random_forest: RandomForestConfig = RandomForestConfig()
    
    # è³‡æºç®¡ç†ï¼ˆv1.1 + v1.2ï¼‰
    resource: ResourceConfig = ResourceConfig()
    
    # æ¨¡å‹ç‰¹å®šæœ€å°æ¨£æœ¬æ•¸é–¾å€¼ï¼ˆä¾æ¼”ç®—æ³•ç‰¹æ€§å€åˆ†ï¼‰
    min_samples_threshold: Dict[str, int] = {
        'random_forest': 100,
        'xgboost': 500,
        'lightgbm': 1000
    }
    
    # è¶…åƒæ•¸æœå°‹ï¼ˆå¤œé–“æ¨¡å¼ï¼‰
    enable_hyperparameter_search: bool = False
    hyperparameter_mode: Literal['disabled', 'daytime_quick', 'overnight_deep'] = 'disabled'
    hyperparameter_trials: int = 50
    hyperparameter_timeout: int = 3600  # ç§’
    hyperparameter_storage: str = "optuna_studies.db"  # SQLite å„²å­˜è·¯å¾‘
    
    # å¯è§£é‡‹æ€§ï¼ˆv1.1 é ç•™ï¼‰
    enable_explainability: bool = False  # æ˜¯å¦å•Ÿç”¨ SHAP
    shap_background_samples: int = 100   # SHAP èƒŒæ™¯è³‡æ–™å–æ¨£æ•¸
    
    # v1.2 æ–°å¢ï¼šå¤šç›®æ¨™èˆ‡è¼¸å‡ºæ§åˆ¶
    training_mode: Literal["single_target", "multi_target", "hybrid"] = "single_target"
    output_structure: Literal["flat", "hierarchical"] = "hierarchical"
    generate_registry_index: bool = True  # è‡ªå‹•ç”¢ç”Ÿ model_registry_index.json
    
    # è¼¸å‡º
    model_output_dir: str = "models/trained"
    metadata_output_dir: str = "models/metadata"
    
    @validator('device_role_handling')
    def validate_no_feature_leakage(cls, v):
        if v.use_as_feature:
            raise ValueError("E701: device_role ç¦æ­¢ä½œç‚ºç›´æ¥ç‰¹å¾µè¼¸å…¥")
        return v
    
    def get_eligible_models(self, n_samples: int) -> List[str]:
        """
        ä¾æ¨£æœ¬æ•¸å‹•æ…‹æ±ºå®šå¯ç”¨æ¨¡å‹åˆ—è¡¨
        å›å‚³: ['random_forest', 'xgboost', 'lightgbm'] çš„å­é›†
        """
        eligible = []
        logger = logging.getLogger(__name__)
        
        for model_name, threshold in self.min_samples_threshold.items():
            if n_samples >= threshold:
                eligible.append(model_name)
            else:
                logger.warning(
                    f"âš ï¸ æ¨£æœ¬æ•¸ {n_samples} ä½æ–¼ {model_name} é–€æª» ({threshold})ï¼Œå·²æ’é™¤"
                )
        
        if not eligible:
            raise ValueError(f"E607: æ¨£æœ¬æ•¸ {n_samples} ä½æ–¼æ‰€æœ‰æ¨¡å‹æœ€ä½è¦æ±‚")
        
        # æ‡‰ç”¨å°æ¨£æœ¬é™ç´šç­–ç•¥
        if n_samples < self.min_samples_threshold['lightgbm']:
            if self.resource.small_sample_fallback == 'disable_lightgbm':
                eligible = [m for m in eligible if m != 'lightgbm']
            elif self.resource.small_sample_fallback == 'use_rf_only':
                eligible = ['random_forest']
        
        return eligible
    
    def adjust_for_small_sample(self, model_name: str, n_samples: int) -> BaseModel:
        """å–å¾—é‡å°å°æ¨£æœ¬èª¿æ•´å¾Œçš„æ¨¡å‹é…ç½®"""
        config = getattr(self, model_name)
        
        if model_name == 'xgboost' and n_samples < 500:
            # æ‡‰ç”¨å°æ¨£æœ¬èª¿æ•´
            adjusted = config.copy()
            for key, val in config.small_sample_adjustments.items():
                setattr(adjusted, key, val)
            return adjusted
        
        return config
```

#### Step 0.2: å¤šæ¨¡å‹è¨“ç·´å™¨åŸºç¤é¡åˆ¥ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼Œå¢åŠ  v1.2 è¨»è§£ï¼‰

**æª”æ¡ˆ**: `src/modeling/trainers/base_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Tuple, Optional, List
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

class BaseModelTrainer(ABC):
    """
    æ¨¡å‹è¨“ç·´å™¨æŠ½è±¡åŸºç¤é¡åˆ¥ (v1.2)
    æ”¯æ´å¸¸è¦è¨“ç·´ã€å¢é‡å­¸ç¿’é ç•™ã€ä»¥åŠå¯è§£é‡‹æ€§ä»‹é¢
    
    v1.2 æ›´æ–°:
    - å¢åŠ  target_id æ¨™è¨˜ï¼Œæ”¯æ´å¤šç›®æ¨™è¿½è¹¤
    - å¢åŠ  model_family æ¨™è¨˜ï¼ˆsystem/componentï¼‰
    """
    
    def __init__(self, config: Any, random_state: int = 42, target_id: str = "default"):
        self.config = config
        self.random_state = random_state
        self.target_id = target_id  # v1.2 æ–°å¢ï¼šæ¨™è¨˜æ­¤ trainer å°æ‡‰çš„ç›®æ¨™
        self.model = None
        self.feature_importance = {}
        self.training_history = {}
        self.is_fitted = False
        
        # v1.2 æ–°å¢ï¼šæ¨¡å‹å…ƒè³‡è¨Šæ“´å……
        self.model_metadata = {
            'trainer_version': '1.2',
            'supports_incremental': False,
            'supports_explainability': False,
            'target_id': target_id,
            'model_family': 'unknown'  # 'system' æˆ– 'component'ï¼Œç”±å¤–éƒ¨è¨­å®š
        }
    
    @abstractmethod
    def train(
        self, 
        X_train: np.ndarray, 
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œæ¨¡å‹è¨“ç·´
        
        Returns:
            Dict åŒ…å«:
            - model: è¨“ç·´å¥½çš„æ¨¡å‹ç‰©ä»¶
            - best_iteration: æœ€ä½³è¿­ä»£æ¬¡æ•¸ï¼ˆæ¢¯åº¦æå‡é¡ï¼‰
            - training_history: è¨“ç·´éç¨‹æŒ‡æ¨™
            - feature_importance: ç‰¹å¾µé‡è¦æ€§å­—å…¸
            - oob_score: Out-of-Bag åˆ†æ•¸ï¼ˆè‹¥æœ‰ï¼‰
        """
        pass
    
    def partial_fit(self, X_new: np.ndarray, y_new: np.ndarray, 
                    sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        å¢é‡å­¸ç¿’ä»‹é¢ï¼ˆv1.2 å¯¦ä½œï¼Œv1.1 é ç•™ï¼‰
        
        Raises:
            NotImplementedError: è‹¥æ¨¡å‹ä¸æ”¯æ´å¢é‡å­¸ç¿’
        """
        raise NotImplementedError(
            f"{self.__class__.__name__} ä¸æ”¯æ´å¢é‡å­¸ç¿’ï¼ˆpartial_fitï¼‰"
        )
    
    @abstractmethod
    def predict(self, X: np.ndarray) -> np.ndarray:
        """åŸ·è¡Œé æ¸¬"""
        pass
    
    @abstractmethod
    def get_feature_importance(self) -> Dict[str, float]:
        """å–å¾—æ¨™æº–åŒ–ç‰¹å¾µé‡è¦æ€§ï¼ˆç¸½å’Œç‚º1ï¼‰"""
        pass
    
    def evaluate(self, X: np.ndarray, y_true: np.ndarray) -> Dict[str, float]:
        """çµ±ä¸€è©•ä¼°æŒ‡æ¨™"""
        y_pred = self.predict(X)
        
        # é˜²æ­¢é™¤ä»¥é›¶ï¼ˆMAPEï¼‰
        mape_mask = y_true != 0
        mape = np.mean(np.abs((y_true[mape_mask] - y_pred[mape_mask]) / y_true[mape_mask])) * 100 if np.any(mape_mask) else float('inf')
        
        return {
            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
            'mae': mean_absolute_error(y_true, y_pred),
            'r2': r2_score(y_true, y_pred),
            'mape': mape
        }
    
    def get_model_info(self) -> Dict[str, Any]:
        """å–å¾—æ¨¡å‹å…ƒè³‡è¨Šï¼ˆç”¨æ–¼æ—¥èªŒèˆ‡å„²å­˜ï¼‰"""
        return {
            'trainer_class': self.__class__.__name__,
            'is_fitted': self.is_fitted,
            'supports_incremental': self.model_metadata['supports_incremental'],
            'supports_explainability': self.model_metadata['supports_explainability'],
            'target_id': self.target_id,
            'model_family': self.model_metadata['model_family'],
            'config': self.config.dict() if hasattr(self.config, 'dict') else str(self.config)
        }
```

---

### Phase 1: ä¸‰æ¨¡å‹å…·é«”å¯¦ä½œ (Day 3-4)

**ï¼ˆä»¥ä¸‹ç‚º v1.1 å…§å®¹ï¼Œä¿æŒä¸è®Šï¼Œåƒ…æ›´æ–°æ¨™é¡Œèˆ‡ç‰ˆæœ¬æ¨™è¨˜ï¼‰**

#### Step 1.1: XGBoost è¨“ç·´å™¨å¯¦ä½œ

**æª”æ¡ˆ**: `src/modeling/trainers/xgboost_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
import xgboost as xgb
import numpy as np
from typing import Dict, Any, Optional, List
from src.modeling.trainers.base_trainer import BaseModelTrainer

class XGBoostTrainer(BaseModelTrainer):
    """
    XGBoost è¨“ç·´å™¨å¯¦ä½œ (v1.2)
    
    ç‰¹æ€§:
    - Level-wise æ¨¹ç”Ÿé•·ï¼ˆå¹³è¡¡æ¨¹æ·±åº¦ï¼‰
    - å…§å»ºæ—©åœæ©Ÿåˆ¶ (Early Stopping)
    - æ”¯æ´æ¨£æœ¬æ¬Šé‡ (Sample Weight)
    - å°æ¨£æœ¬è‡ªå‹•èª¿æ•´ï¼ˆmax_depth é™åˆ¶ï¼‰
    - v1.2 æ”¯æ´ï¼šå¤šç›®æ¨™è¿½è¹¤ï¼ˆé€é target_idï¼‰
    """
    
    def __init__(self, config: XGBoostConfig, random_state: int = 42, target_id: str = "default"):
        super().__init__(config, random_state, target_id)
        self.model_metadata['supports_explainability'] = True  # TreeSHAP æ”¯æ´
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None,
        xgb_model: Optional[Any] = None  # v1.2 å¢é‡å­¸ç¿’é ç•™
    ) -> Dict[str, Any]:
        """åŸ·è¡Œ XGBoost è¨“ç·´"""
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = xgb.XGBRegressor(
            n_estimators=self.config.n_estimators,
            learning_rate=self.config.learning_rate,
            max_depth=self.config.max_depth,
            min_child_weight=self.config.min_child_weight,
            subsample=self.config.subsample,
            colsample_bytree=self.config.colsample_bytree,
            reg_alpha=self.config.reg_alpha,
            reg_lambda=self.config.reg_lambda,
            gamma=self.config.gamma,
            eval_metric=self.config.eval_metric,
            tree_method=self.config.tree_method,
            random_state=self.random_state,
            n_jobs=-1,
            verbosity=0
        )
        
        # æ‡‰ç”¨å–®èª¿æ€§ç´„æŸ
        if self.config.enable_monotonic_constraints and self.config.monotone_constraints and feature_names:
            mono_constraints = tuple(
                self.config.monotone_constraints.get(f, 0) for f in feature_names
            )
            self.model.set_params(monotone_constraints=mono_constraints)
        
        # è¨“ç·´ï¼ˆå«æ—©åœï¼‰
        eval_set = [(X_train, y_train), (X_val, y_val)]
        
        fit_params = {
            'eval_set': eval_set,
            'early_stopping_rounds': self.config.early_stopping_rounds,
            'verbose': False
        }
        
        if sample_weights is not None:
            fit_params['sample_weight'] = sample_weights
        
        # v1.2 é ç•™ï¼šå¢é‡å­¸ç¿’
        if xgb_model is not None:
            fit_params['xgb_model'] = xgb_model
        
        self.model.fit(X_train, y_train, **fit_params)
        self.is_fitted = True
        
        # æå–è¨“ç·´æ­·å²
        results = self.model.evals_result()
        eval_metric = self.config.eval_metric
        
        self.training_history = {
            'train_rmse': results['validation_0'].get(eval_metric, []),
            'val_rmse': results['validation_1'].get(eval_metric, []),
            'best_iteration': self.model.best_iteration,
            'best_score': self.model.best_score,
            'n_features': X_train.shape[1]
        }
        
        # æå–ç‰¹å¾µé‡è¦æ€§ (Gain-based)
        importance = self.model.feature_importances_
        if feature_names:
            self.feature_importance = dict(zip(feature_names, importance))
        else:
            self.feature_importance = {f"feat_{i}": imp for i, imp in enumerate(importance)}
        
        return {
            'model': self.model,
            'best_iteration': self.model.best_iteration,
            'training_history': self.training_history,
            'feature_importance': self.feature_importance,
            'oob_score': None
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X, iteration_range=(0, self.model.best_iteration + 1))
    
    def get_feature_importance(self) -> Dict[str, float]:
        if not self.feature_importance:
            return {}
        total = sum(self.feature_importance.values())
        return {k: v/total for k, v in self.feature_importance.items()}
    
    def partial_fit(self, X_new: np.ndarray, y_new: np.ndarray, 
                    sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        v1.2 åŠŸèƒ½ï¼šå¢é‡å­¸ç¿’
        ä½¿ç”¨ç¾æœ‰æ¨¡å‹ä½œç‚ºåŸºç¤ï¼Œç¹¼çºŒè¨“ç·´æ–°è³‡æ–™
        """
        if not self.is_fitted:
            raise RuntimeError("å¿…é ˆå…ˆåŸ·è¡Œåˆå§‹è¨“ç·´æ‰èƒ½é€²è¡Œå¢é‡å­¸ç¿’")
        
        # XGBoost æ”¯æ´é€é xgb_model åƒæ•¸æ¥çºŒè¨“ç·´
        return self.train(
            X_train=X_new, y_train=y_new,
            X_val=X_new, y_val=y_new,  # é©—è­‰é›†å¯ç‚ºæ–°è³‡æ–™å­é›†æˆ–æ²¿ç”¨èˆŠé©—è­‰é›†
            sample_weights=sample_weight,
            xgb_model=self.model.get_booster()  # å‚³å…¥ç¾æœ‰æ¨¡å‹
        )
```

#### Step 1.2: LightGBM è¨“ç·´å™¨å¯¦ä½œ

**æª”æ¡ˆ**: `src/modeling/trainers/lightgbm_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
import lightgbm as lgb
import numpy as np
from typing import Dict, Any, Optional, List
from src.modeling.trainers.base_trainer import BaseModelTrainer

class LightGBMTrainer(BaseModelTrainer):
    """
    LightGBM è¨“ç·´å™¨å¯¦ä½œ (v1.2)
    
    ç‰¹æ€§:
    - Leaf-wise æ¨¹ç”Ÿé•·ï¼ˆæ›´é«˜æ•ˆï¼‰
    - åŸç”Ÿ Dataset çµæ§‹ï¼ˆè¨˜æ†¶é«”æ•ˆç‡é«˜ï¼‰
    - è¨“ç·´é€Ÿåº¦æ¥µå¿«
    - v1.2 æ”¯æ´ï¼šinit_model æ¥çºŒè¨“ç·´
    """
    
    def __init__(self, config: LightGBMConfig, random_state: int = 42, target_id: str = "default"):
        super().__init__(config, random_state, target_id)
        self.model_metadata['supports_explainability'] = True
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None,
        init_model: Optional[Any] = None  # v1.2 å¢é‡å­¸ç¿’é ç•™
    ) -> Dict[str, Any]:
        """åŸ·è¡Œ LightGBM è¨“ç·´"""
        
        # å»ºç«‹ Datasetï¼ˆè¨˜æ†¶é«”æ•ˆç‡é«˜ï¼‰
        train_data = lgb.Dataset(
            X_train, 
            label=y_train, 
            weight=sample_weights,
            feature_name=feature_names or [f"feat_{i}" for i in range(X_train.shape[1])],
            free_raw_data=False  # ä¿ç•™åŸå§‹è³‡æ–™ä»¥ä¾›å¾ŒçºŒåƒè€ƒ
        )
        val_data = lgb.Dataset(
            X_val, 
            label=y_val,
            reference=train_data,
            feature_name=train_data.feature_name
        )
        
        # è¶…åƒæ•¸
        params = {
            'objective': 'regression',
            'metric': self.config.eval_metric,
            'boosting_type': self.config.boosting_type,
            'num_leaves': self.config.num_leaves,
            'max_depth': self.config.max_depth,
            'learning_rate': self.config.learning_rate,
            'feature_fraction': self.config.colsample_bytree,
            'bagging_fraction': self.config.subsample,
            'bagging_freq': 5,
            'lambda_l1': self.config.reg_alpha,
            'lambda_l2': self.config.reg_lambda,
            'min_child_samples': self.config.min_child_samples,
            'verbose': -1,
            'random_state': self.random_state,
            'feature_pre_filter': self.config.feature_pre_filter
        }
        
        if self.config.histogram_pool_size:
            params['histogram_pool_size'] = self.config.histogram_pool_size
        
        # è¨“ç·´ï¼ˆå«æ—©åœï¼‰
        callbacks = [lgb.early_stopping(stopping_rounds=self.config.early_stopping_rounds, verbose=False)]
        
        self.model = lgb.train(
            params,
            train_data,
            num_boost_round=self.config.n_estimators,
            valid_sets=[train_data, val_data],
            valid_names=['train', 'val'],
            callbacks=callbacks,
            init_model=init_model  # v1.2 å¢é‡å­¸ç¿’
        )
        
        self.is_fitted = True
        
        # æå–è¨“ç·´æ­·å²
        self.training_history = {
            'best_iteration': self.model.best_iteration,
            'best_score': self.model.best_score.get('val', {}).get(self.config.eval_metric, None),
            'n_features': X_train.shape[1]
        }
        
        # ç‰¹å¾µé‡è¦æ€§ (Gain-based è¼ƒç©©å®š)
        importance_gain = self.model.feature_importance(importance_type='gain')
        self.feature_importance = dict(zip(train_data.feature_name, importance_gain))
        
        return {
            'model': self.model,
            'best_iteration': self.model.best_iteration,
            'training_history': self.training_history,
            'feature_importance': self.feature_importance,
            'oob_score': None
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X, num_iteration=self.model.best_iteration)
    
    def get_feature_importance(self) -> Dict[str, float]:
        if not self.feature_importance:
            return {}
        total = sum(self.feature_importance.values())
        return {k: v/total for k, v in self.feature_importance.items()}
```

#### Step 1.3: Random Forest è¨“ç·´å™¨å¯¦ä½œ

**æª”æ¡ˆ**: `src/modeling/trainers/random_forest_trainer.py`

**å¯¦ä½œå…§å®¹**:
```python
from sklearn.ensemble import RandomForestRegressor
import numpy as np
from typing import Dict, Any, Optional, List
from src.modeling.trainers.base_trainer import BaseModelTrainer

class RandomForestTrainer(BaseModelTrainer):
    """
    Random Forest è¨“ç·´å™¨å¯¦ä½œ (v1.2)
    
    ç‰¹æ€§:
    - Bagging ç­–ç•¥ï¼ˆå¹³è¡Œæ¨¹ï¼‰
    - å¤©ç„¶æ”¯æ´ OOB (Out-of-Bag) é©—è­‰
    - é æ¸¬å€é–“è¼¸å‡ºï¼ˆä½¿ç”¨æ‰€æœ‰æ¨¹çš„é æ¸¬åˆ†ä½ˆï¼‰
    - å°ç•°å¸¸å€¼é²æ£’
    - v1.2 å¯¦ä½œï¼šwarm_start å¢é‡è¨“ç·´
    """
    
    def __init__(self, config: RandomForestConfig, random_state: int = 42, target_id: str = "default"):
        super().__init__(config, random_state, target_id)
        self.model_metadata['supports_incremental'] = True  # warm_start
        self.model_metadata['supports_explainability'] = True
    
    def train(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray = None,  # RF å¯ä¸ä½¿ç”¨ç¨ç«‹é©—è­‰é›†ï¼ˆä½¿ç”¨ OOBï¼‰
        y_val: np.ndarray = None,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """åŸ·è¡Œ Random Forest è¨“ç·´"""
        
        self.model = RandomForestRegressor(
            n_estimators=self.config.n_estimators,
            max_depth=self.config.max_depth,
            min_samples_split=self.config.min_samples_split,
            min_samples_leaf=self.config.min_samples_leaf,
            max_features=self.config.max_features,
            bootstrap=self.config.bootstrap,
            oob_score=self.config.oob_score,
            n_jobs=self.config.n_jobs,
            random_state=self.random_state,
            warm_start=self.config.warm_start,
            verbose=0
        )
        
        # è¨“ç·´
        self.model.fit(X_train, y_train, sample_weight=sample_weights)
        self.is_fitted = True
        
        # OOB åˆ†æ•¸
        oob_score = None
        if self.config.oob_score and self.config.bootstrap and hasattr(self.model, 'oob_score_'):
            oob_score = self.model.oob_score_
        
        # è¨“ç·´æ­·å²
        train_metrics = self.evaluate(X_train, y_train)
        val_metrics = self.evaluate(X_val, y_val) if X_val is not None else {}
        
        self.training_history = {
            'train_rmse': train_metrics['rmse'],
            'val_rmse': val_metrics.get('rmse'),
            'oob_r2': oob_score,
            'n_estimators': self.config.n_estimators,
            'n_features': X_train.shape[1]
        }
        
        # ç‰¹å¾µé‡è¦æ€§ (MDI)
        importance = self.model.feature_importances_
        if feature_names:
            self.feature_importance = dict(zip(feature_names, importance))
        else:
            self.feature_importance = {f"feat_{i}": imp for i, imp in enumerate(importance)}
        
        return {
            'model': self.model,
            'best_iteration': None,  # RF ç„¡è¿­ä»£æ¦‚å¿µ
            'training_history': self.training_history,
            'feature_importance': self.feature_importance,
            'oob_score': oob_score
        }
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        return self.model.predict(X)
    
    def predict_with_interval(self, X: np.ndarray, confidence: float = 0.9) -> Dict[str, np.ndarray]:
        """
        è¼¸å‡ºé æ¸¬å€é–“ï¼ˆä½¿ç”¨æ‰€æœ‰æ¨¹çš„é æ¸¬åˆ†ä½ˆï¼‰
        
        Args:
            X: ç‰¹å¾µçŸ©é™£
            confidence: ä¿¡å¿ƒæ°´æº–ï¼ˆé è¨­ 90%ï¼Œè¼¸å‡º Q5 èˆ‡ Q95ï¼‰
        
        Returns:
            {
                'mean': å¹³å‡é æ¸¬å€¼,
                'lower': ä¸‹ç•Œ,
                'upper': ä¸Šç•Œ,
                'std': æ¨™æº–å·®
            }
        """
        if not self.is_fitted:
            raise RuntimeError("E702: æ¨¡å‹å°šæœªè¨“ç·´")
        
        # å–å¾—æ‰€æœ‰æ¨¹çš„é æ¸¬ (n_samples, n_trees)
        all_predictions = np.array([tree.predict(X) for tree in self.model.estimators_])
        
        mean_pred = np.mean(all_predictions, axis=0)
        std_pred = np.std(all_predictions, axis=0)
        
        # è¨ˆç®—åˆ†ä½æ•¸
        alpha = (1 - confidence) * 100 / 2
        lower = np.percentile(all_predictions, alpha, axis=0)
        upper = np.percentile(all_predictions, 100 - alpha, axis=0)
        
        return {
            'mean': mean_pred,
            'lower': lower,
            'upper': upper,
            'std': std_pred
        }
    
    def get_feature_importance(self) -> Dict[str, float]:
        if not self.feature_importance:
            return {}
        total = sum(self.feature_importance.values())
        return {k: v/total for k, v in self.feature_importance.items()}
    
    def partial_fit(self, X_new: np.ndarray, y_new: np.ndarray,
                    sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
        """
        v1.2 åŠŸèƒ½ï¼šå¢é‡å­¸ç¿’
        é€éå¢åŠ  n_estimators å¯¦ç¾å¢é‡è¨“ç·´
        """
        if not self.is_fitted:
            raise RuntimeError("å¿…é ˆå…ˆåŸ·è¡Œåˆå§‹è¨“ç·´")
        
        # å¢åŠ æ¨¹çš„æ•¸é‡
        current_n = self.model.n_estimators
        self.model.n_estimators += 100  # æ¯æ¬¡å¢åŠ  100 æ£µæ¨¹
        self.model.warm_start = True
        
        self.model.fit(X_new, y_new, sample_weight=sample_weight)
        
        return {
            'model': self.model,
            'previous_n_estimators': current_n,
            'new_n_estimators': self.model.n_estimators,
            'oob_score': getattr(self.model, 'oob_score_', None)
        }
```

---

### Phase 2: å¤šæ¨¡å‹è¨“ç·´ç®¡ç·šæ•´åˆ (Day 5)

#### Step 2.1: è³‡æºç®¡ç†èˆ‡å‹•æ…‹èª¿åº¦ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼‰

**æª”æ¡ˆ**: `src/modeling/resource_manager.py`

**å¯¦ä½œå…§å®¹**:
```python
import psutil
import numpy as np
from typing import Tuple, Dict, Any, List
import logging

class ResourceManager:
    """
    è¨“ç·´è³‡æºç®¡ç†å™¨ (v1.2)
    è² è²¬è¨˜æ†¶é«”è©•ä¼°ã€å‹•æ…‹é™ç´šæ±ºç­–ã€ä»¥åŠç¡¬é«”è³‡æºç›£æ§
    
    v1.2 æ›´æ–°:
    - å¢åŠ æ‰¹æ¬¡è¨“ç·´è¨˜æ†¶é«”ä¼°ç®—ï¼ˆå¤šç›®æ¨™æƒ…å¢ƒï¼‰
    - å¢åŠ ä¸¦è¡Œç›®æ¨™æ•¸é™åˆ¶
    """
    
    def __init__(self, config: ResourceConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.initial_memory = psutil.virtual_memory().available
    
    def estimate_memory_requirement(
        self, 
        n_samples: int, 
        n_features: int,
        eligible_models: List[str]
    ) -> Dict[str, float]:
        """
        ä¼°ç®—å„æ¨¡å‹è¨˜æ†¶é«”éœ€æ±‚ï¼ˆä½å…ƒçµ„ï¼‰
        
        ä¼°ç®—å…¬å¼ï¼ˆä¿å®ˆä¼°è¨ˆï¼‰ï¼š
        - XGBoost: ~8 bytes * n_samples * n_features * 1.5 (sparse overhead) * 1.2 (tree storage)
        - LightGBM: ~4 bytes * n_samples * n_features * 0.8 (dense efficiency) * 1.1
        - Random Forest: ~8 bytes * n_samples * n_features * n_trees/5 (æ¯æ£µæ¨¹å„²å­˜éƒ¨åˆ†æ¨£æœ¬ç´¢å¼•)
        """
        base_size = n_samples * n_features
        
        estimates = {}
        
        if 'xgboost' in eligible_models:
            estimates['xgboost'] = base_size * 8 * 1.5 * 1.2
        
        if 'lightgbm' in eligible_models:
            estimates['lightgbm'] = base_size * 4 * 0.8 * 1.1
        
        if 'random_forest' in eligible_models:
            n_trees = 500  # é è¨­
            rf_factor = n_trees * 0.632 * 4  # 4 bytes per index (int32)
            estimates['random_forest'] = base_size * rf_factor
        
        return estimates
    
    def check_training_feasibility(
        self, 
        n_samples: int, 
        n_features: int,
        eligible_models: List[str],
        n_concurrent_targets: int = 1  # v1.2 æ–°å¢ï¼šä¸¦è¡Œç›®æ¨™æ•¸
    ) -> Tuple[bool, bool, str]:
        """
        æª¢æŸ¥è¨“ç·´å¯è¡Œæ€§
        
        Returns:
            (is_feasible, use_parallel, message)
            - is_feasible: æ˜¯å¦å¯è¡Œ
            - use_parallel: æ˜¯å¦å¯ä½¿ç”¨å¹³è¡Œè¨“ç·´
            - message: èªªæ˜è¨Šæ¯
        """
        if not self.config.memory_check_before_training:
            return True, self.config.parallel_training, "è·³éè¨˜æ†¶é«”æª¢æŸ¥"
        
        estimates = self.estimate_memory_requirement(n_samples, n_features, eligible_models)
        total_required = sum(estimates.values()) * n_concurrent_targets  # v1.2ï¼šä¹˜ä»¥ä¸¦è¡Œç›®æ¨™æ•¸
        
        available_mem = psutil.virtual_memory().available
        total_mem = psutil.virtual_memory().total
        safety_threshold = total_mem * (1 - self.config.memory_safety_threshold)
        
        # æª¢æŸ¥å–®ä¸€æ¨¡å‹æ˜¯å¦å¯è¡Œ
        if any(est > available_mem for est in estimates.values()):
            problematic = [m for m, est in estimates.items() if est > available_mem]
            return False, False, f"E801: è¨˜æ†¶é«”ä¸è¶³ï¼Œ{problematic} éœ€æ±‚è¶…éå¯ç”¨è¨˜æ†¶é«”"
        
        # æª¢æŸ¥å¹³è¡Œè¨“ç·´å¯è¡Œæ€§
        if total_required < min(available_mem * 0.8, safety_threshold):
            msg = f"âœ… è¨˜æ†¶é«”å……è¶³: éœ€æ±‚ {total_required/1e9:.1f}GB, å¯ç”¨ {available_mem/1e9:.1f}GB"
            return True, True, msg
        else:
            if self.config.auto_fallback_to_sequential:
                msg = (f"âš ï¸ E801: å¹³è¡Œè¨“ç·´è¨˜æ†¶é«”é¢¨éšª (éœ€æ±‚ {total_required/1e9:.1f}GB > "
                       f"å®‰å…¨é–¾å€¼ {safety_threshold/1e9:.1f}GB)ï¼Œè‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´")
                return True, False, msg
            else:
                return False, False, "E801: è¨˜æ†¶é«”ä¸è¶³ä¸”æœªå•Ÿç”¨è‡ªå‹•é™ç´š"
    
    def get_optimal_n_jobs(self, model_name: str) -> int:
        """å–å¾—å»ºè­°çš„å¹³è¡ŒåŸ·è¡Œç·’æ•¸ï¼ˆé¿å…éåº¦è¨‚é–±ï¼‰"""
        cpu_count = psutil.cpu_count(logical=True)
        
        if model_name in ['random_forest']:
            return max(1, cpu_count // 3)
        else:
            return max(1, cpu_count // 2)
    
    def log_resource_usage(self):
        """è¨˜éŒ„ç•¶å‰è³‡æºä½¿ç”¨ç‹€æ³"""
        mem = psutil.virtual_memory()
        cpu = psutil.cpu_percent(interval=1)
        self.logger.info(
            f"ğŸ“Š è³‡æºç‹€æ…‹: CPU {cpu}%, "
            f"è¨˜æ†¶é«” {mem.used/1e9:.1f}/{mem.total/1e9:.1f}GB ({mem.percent}%)"
        )
```

#### Step 2.2: å¹³è¡Œè¨“ç·´èˆ‡æ¨¡å‹é¸æ“‡é‚è¼¯

**æª”æ¡ˆ**: `src/modeling/training_pipeline.py`

**å¯¦ä½œå…§å®¹**:
```python
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Dict, List, Tuple, Any, Optional
import numpy as np
import logging
from datetime import datetime

from src.modeling.trainers.xgboost_trainer import XGBoostTrainer
from src.modeling.trainers.lightgbm_trainer import LightGBMTrainer
from src.modeling.trainers.random_forest_trainer import RandomForestTrainer
from src.modeling.resource_manager import ResourceManager

class TrainingPipeline:
    """
    å¤šæ¨¡å‹è¨“ç·´ç®¡ç·š v1.2 (Resource-Aware + Multi-Target Ready)
    
    åŒæ™‚è¨“ç·´ XGBoostã€LightGBMã€Random Forestï¼Œ
    ä¸¦ä¾é©—è­‰æŒ‡æ¨™è‡ªå‹•é¸æ“‡æœ€ä½³æ¨¡å‹æˆ–ä¿ç•™ Ensembleã€‚
    å…·å‚™å‹•æ…‹è¨˜æ†¶é«”ç®¡ç†èˆ‡å°æ¨£æœ¬é©æ‡‰æ©Ÿåˆ¶ã€‚
    
    v1.2 æ›´æ–°:
    - æ”¯æ´ target_id æ¨™è¨˜ï¼Œç”¨æ–¼å¤šç›®æ¨™è¿½è¹¤
    - èˆ‡ BatchTrainingCoordinator æ•´åˆä»‹é¢
    """
    
    def __init__(self, config: ModelTrainingConfig, site_id: str, target_id: str = "default"):
        self.config = config
        self.site_id = site_id
        self.target_id = target_id  # v1.2 æ–°å¢
        self.annotation_manager = FeatureAnnotationManager(site_id=site_id)
        self.resource_manager = ResourceManager(config.resource)
        self.logger = logging.getLogger(__name__)
        
        self._validate_annotation_compatibility()
        
        self.trainers = {}
        self.results = {}
        self.best_model_name = None
        self.training_stats = {
            'start_time': None,
            'end_time': None,
            'models_trained': [],
            'resource_events': []
        }
        
    def _validate_annotation_compatibility(self):
        """é©—è­‰ä¸Šæ¸¸ Annotation ç›¸å®¹æ€§"""
        pass  # å¯¦ä½œç´°ç•¥
    
    def _select_best_model(self) -> str:
        """
        é¸æ“‡æœ€ä½³æ¨¡å‹ï¼ˆv1.2 å¼·åŒ–ç‰ˆï¼‰
        
        ç­–ç•¥:
        1. å„ªå…ˆæ¯”è¼ƒé©—è­‰é›† RÂ² åˆ†æ•¸
        2. è‹¥ RÂ² å·®è· < 0.01ï¼Œæ¯”è¼ƒè¨“ç·´ç©©å®šæ€§ï¼ˆRF çš„ OOB èˆ‡ Val å·®è·ï¼‰
        3. è‹¥ RF çš„ OOB èˆ‡é©—è­‰é›†å·®è·éå¤§ï¼ˆ>0.1ï¼‰ï¼Œå¯èƒ½è¡¨ç¤ºè³‡æ–™æ´©æ¼ï¼Œé™ä½æ’å
        4. é¸æ“‡è¨“ç·´æ™‚é–“è¼ƒçŸ­çš„ï¼ˆåœ¨ç²¾åº¦ç›¸ç•¶æ™‚ï¼‰
        """
        valid_results = {
            name: res for name, res in self.results.items() 
            if 'error' not in res and 'metrics' in res
        }
        
        if not valid_results:
            raise ModelTrainingError("E703: æ‰€æœ‰æ¨¡å‹è¨“ç·´å¤±æ•—")
        
        model_scores = []
        for name, result in valid_results.items():
            val_r2 = result['metrics']['val']['r2']
            train_r2 = result['metrics']['train']['r2']
            overfit_score = train_r2 - val_r2
            
            oob_penalty = 0
            if name == 'random_forest' and result.get('oob_score'):
                oob_gap = abs(result['oob_score'] - val_r2)
                if oob_gap > 0.1:
                    oob_penalty = 0.05
            
            composite_score = val_r2 - overfit_score * 0.5 - oob_penalty
            
            model_scores.append((name, composite_score, val_r2))
        
        model_scores.sort(key=lambda x: x[1], reverse=True)
        best_name = model_scores[0][0]
        
        self.logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_name} (target={self.target_id})")
        
        return best_name
    
    def train_all_models(
        self,
        X_train: np.ndarray,
        y_train: np.ndarray,
        X_val: np.ndarray,
        y_val: np.ndarray,
        sample_weights: Optional[np.ndarray] = None,
        feature_names: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        è¨“ç·´æ‰€æœ‰ç¬¦åˆè³‡æ ¼çš„æ¨¡å‹ï¼ˆè³‡æºæ„ŸçŸ¥æ’ç¨‹ï¼‰
        """
        n_samples = len(X_train)
        eligible_models = self.config.get_eligible_models(n_samples)
        self.logger.info(f"ğŸ“‹ ç›®æ¨™={self.target_id}, æ¨£æœ¬æ•¸={n_samples}, æ¨¡å‹={eligible_models}")
        
        is_feasible, use_parallel, msg = self.resource_manager.check_training_feasibility(
            n_samples, X_train.shape[1], eligible_models
        )
        self.logger.info(msg)
        
        if not is_feasible:
            raise ModelTrainingError(msg)
        
        trainers_config = {}
        for name in eligible_models:
            TrainerClass = {
                'xgboost': XGBoostTrainer,
                'lightgbm': LightGBMTrainer,
                'random_forest': RandomForestTrainer
            }[name]
            
            model_config = self.config.adjust_for_small_sample(name, n_samples)
            trainers_config[name] = (TrainerClass, model_config)
        
        if use_parallel and len(trainers_config) > 1:
            self._train_parallel(trainers_config, X_train, y_train, X_val, y_val, 
                               sample_weights, feature_names)
        else:
            self._train_sequential(trainers_config, X_train, y_train, X_val, y_val,
                                 sample_weights, feature_names)
        
        if self.config.resource.auto_select_best:
            self.best_model_name = self._select_best_model()
        
        return self.results
    
    def _train_single_model(self, name, TrainerClass, model_config, X_train, y_train, 
                           X_val, y_val, sample_weights, feature_names):
        """è¨“ç·´å–®ä¸€æ¨¡å‹"""
        try:
            self.logger.info(f"ğŸš€ [{self.target_id}] è¨“ç·´ {name}...")
            start_time = datetime.now()
            
            trainer = TrainerClass(
                config=model_config, 
                random_state=self.config.random_state,
                target_id=self.target_id  # v1.2 å‚³é target_id
            )
            
            result = trainer.train(X_train, y_train, X_val, y_val, sample_weights, feature_names)
            
            result['metrics'] = {
                'train': trainer.evaluate(X_train, y_train),
                'val': trainer.evaluate(X_val, y_val)
            }
            
            result['training_time'] = (datetime.now() - start_time).total_seconds()
            result['status'] = 'success'
            
            self.trainers[name] = trainer
            self.training_stats['models_trained'].append(name)
            
            return name, result
            
        except Exception as e:
            self.logger.error(f"âŒ [{self.target_id}] {name} è¨“ç·´å¤±æ•—: {str(e)}")
            return name, {'error': str(e), 'status': 'failed'}
    
    def _train_parallel(self, trainers_config, X_train, y_train, X_val, y_val, 
                       sample_weights, feature_names):
        """å¹³è¡Œè¨“ç·´"""
        max_workers = min(len(trainers_config), self.config.resource.max_parallel_workers)
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(
                    self._train_single_model, name, TrainerClass, model_config,
                    X_train, y_train, X_val, y_val, sample_weights, feature_names
                ): name 
                for name, (TrainerClass, model_config) in trainers_config.items()
            }
            
            for future in as_completed(futures):
                name = futures[future]
                try:
                    model_name, result = future.result()
                    self.results[model_name] = result
                except Exception as e:
                    self.logger.error(f"âŒ {name} é€²ç¨‹ç•°å¸¸: {e}")
                    self.results[name] = {'error': str(e), 'status': 'failed'}
    
    def _train_sequential(self, trainers_config, X_train, y_train, X_val, y_val,
                         sample_weights, feature_names):
        """åºåˆ—è¨“ç·´"""
        for name, (TrainerClass, model_config) in trainers_config.items():
            model_name, result = self._train_single_model(
                name, TrainerClass, model_config, X_train, y_train, X_val, y_val,
                sample_weights, feature_names
            )
            self.results[model_name] = result
            
            if name == 'random_forest':
                import gc
                gc.collect()
                self.resource_manager.log_resource_usage()
    
    def get_best_model(self) -> Tuple[str, BaseModelTrainer, Dict]:
        """å–å¾—æœ€ä½³æ¨¡å‹"""
        if self.best_model_name is None:
            raise RuntimeError("E706: å°šæœªåŸ·è¡Œæ¨¡å‹é¸æ“‡")
        return (
            self.best_model_name,
            self.trainers[self.best_model_name],
            self.results[self.best_model_name]
        )
    
    def predict_ensemble(self, X: np.ndarray, weights: Optional[Dict[str, float]] = None) -> np.ndarray:
        """
        Ensemble é æ¸¬ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
        """
        valid_trainers = {
            name: trainer for name, trainer in self.trainers.items()
            if name in self.results and 'error' not in self.results[name]
        }
        
        if not valid_trainers:
            raise RuntimeError("E707: ç„¡å¯ç”¨æ¨¡å‹é€²è¡Œ Ensemble é æ¸¬")
        
        predictions = []
        model_weights = []
        
        for name, trainer in valid_trainers.items():
            pred = trainer.predict(X)
            predictions.append(pred)
            
            if weights and name in weights:
                model_weights.append(weights[name])
            else:
                r2 = max(0, self.results[name]['metrics']['val']['r2'])
                model_weights.append(r2)
        
        weights_arr = np.array(model_weights) / sum(model_weights)
        ensemble_pred = np.average(predictions, axis=0, weights=weights_arr)
        
        return ensemble_pred
```

---

### Phase 3: è¶…åƒæ•¸å„ªåŒ–èˆ‡å¯è§£é‡‹æ€§ (Day 6-7)

**ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼Œä¿æŒä¸è®Šï¼‰**

#### Step 3.1: å¤œé–“è¶…åƒæ•¸å„ªåŒ–å™¨

**æª”æ¡ˆ**: `src/modeling/hyperparameter/optuna_optimizer.py`

**å¯¦ä½œå…§å®¹**:
```python
import optuna
import gc
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
import logging

from src.modeling.trainers.xgboost_trainer import XGBoostTrainer
from src.modeling.trainers.lightgbm_trainer import LightGBMTrainer
from src.modeling.trainers.random_forest_trainer import RandomForestTrainer

class SearchSpace:
    """å®šç¾©å„æ¨¡å‹çš„è¶…åƒæ•¸æœå°‹ç©ºé–“"""
    
    @staticmethod
    def xgboost_space(trial: optuna.Trial) -> Dict[str, Any]:
        return {
            'n_estimators': trial.suggest_int('n_estimators', 100, 2000),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'max_depth': trial.suggest_int('max_depth', 3, 10),
            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
            'subsample': trial.suggest_float('subsample', 0.6, 1.0),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        }
    
    @staticmethod
    def lightgbm_space(trial: optuna.Trial) -> Dict[str, Any]:
        return {
            'num_leaves': trial.suggest_int('num_leaves', 20, 150),
            'max_depth': trial.suggest_int('max_depth', -1, 12),
            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
            'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),
            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),
            'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),
            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
        }
    
    @staticmethod
    def random_forest_space(trial: optuna.Trial) -> Dict[str, Any]:
        max_depth_choice = trial.suggest_categorical('max_depth_choice', ['fixed', 'none'])
        return {
            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
            'max_depth': trial.suggest_int('max_depth', 5, 50) if max_depth_choice == 'fixed' else None,
            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),
        }

class OvernightOptimizer:
    """
    å¤œé–“è¶…åƒæ•¸å„ªåŒ–å™¨ (v1.2)
    
    ç‰¹æ€§ï¼š
    1. ä¾åºå„ªåŒ–ï¼ˆéä¸¦è¡Œï¼‰ï¼Œé¿å…è³‡æºçˆ†ç‚¸
    2. æ”¯æ´æ–·é»çºŒå‚³ï¼ˆSQLite å„²å­˜ studyï¼‰
    3. èˆ‡ Early Stopping æ•´åˆï¼ŒåŠ é€Ÿæ¯å€‹ trial
    4. Pruning æ©Ÿåˆ¶ï¼šè‡ªå‹•çµ‚æ­¢ç„¡æœ›çš„ trial
    
    v1.2 æ›´æ–°:
    - æ”¯æ´å¤šç›®æ¨™æ‰¹æ¬¡å„ªåŒ–ï¼ˆé€é BatchTrainingCoordinator å‘¼å«ï¼‰
    """
    
    def __init__(self, config: ModelTrainingConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.storage = f"sqlite:///{config.hyperparameter_storage}"
        
    def optimize_model(
        self, 
        model_name: str,
        X_train, y_train, X_val, y_val,
        n_trials: int = 50,
        timeout: int = 3600,
        n_startup_trials: int = 10,
        target_id: str = "default"  # v1.2 æ–°å¢
    ) -> Dict[str, Any]:
        """
        å–®ä¸€æ¨¡å‹å„ªåŒ–ï¼ˆå»ºè­°å¤œé–“åŸ·è¡Œï¼‰
        """
        study_name = f"{target_id}_{model_name}_{datetime.now().strftime('%Y%m%d_%H%M')}"
        
        study = optuna.create_study(
            study_name=study_name,
            storage=self.storage,
            load_if_exists=True,
            direction='maximize',
            sampler=optuna.samplers.TPESampler(n_startup_trials=n_startup_trials),
            pruner=optuna.pruners.MedianPruner()
        )
        
        def objective(trial):
            space_method = getattr(SearchSpace, f"{model_name}_space")
            params = space_method(trial)
            
            trainer_class = {
                'xgboost': XGBoostTrainer,
                'lightgbm': LightGBMTrainer,
                'random_forest': RandomForestTrainer
            }[model_name]
            
            base_config = getattr(self.config, model_name)
            temp_config = base_config.copy()
            for key, val in params.items():
                setattr(temp_config, key, val)
            
            trainer = trainer_class(
                config=temp_config, 
                random_state=self.config.random_state,
                target_id=target_id
            )
            
            try:
                trainer.train(X_train, y_train, X_val, y_val)
                val_metrics = trainer.evaluate(X_val, y_val)
                val_r2 = val_metrics['r2']
                
                trial.report(val_r2, step=0)
                if trial.should_prune():
                    raise optuna.TrialPruned()
                
                return val_r2
                
            except Exception as e:
                self.logger.warning(f"Trial {trial.number} å¤±æ•—: {e}")
                return -float('inf')
        
        start_time = time.time()
        study.optimize(objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)
        elapsed = time.time() - start_time
        
        return {
            'model_name': model_name,
            'target_id': target_id,
            'study_name': study_name,
            'best_params': study.best_params,
            'best_value': study.best_value,
            'n_trials_completed': len(study.trials),
            'n_trials_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),
            'optimization_time': elapsed,
        }
    
    def optimize_all_models_sequentially(self, data: TrainingInputContract, target_id: str = "default") -> Dict[str, Any]:
        """
        ä¾åºå„ªåŒ–ä¸‰æ¨¡å‹ï¼ˆè³‡æºå®‰å…¨æ¨¡å¼ï¼‰
        å»ºè­°åŸ·è¡Œæ™‚æ®µï¼šå¤œé–“ 00:00 - 06:00
        """
        # è³‡æ–™æº–å‚™ï¼ˆç•¥ï¼‰
        X_train, y_train, X_val, y_val = self._prepare_data(data)
        
        results = {}
        
        models = ['random_forest', 'xgboost', 'lightgbm']
        eligible_models = self.config.get_eligible_models(len(X_train))
        models = [m for m in models if m in eligible_models]
        
        total_start = time.time()
        
        for model_name in models:
            self.logger.info(f"ğŸŒ™ é–‹å§‹å¤œé–“å„ªåŒ–: {target_id}/{model_name}")
            
            timeout_per_model = self.config.hyperparameter_timeout // len(models)
            
            result = self.optimize_model(
                model_name=model_name,
                X_train=X_train, y_train=y_train,
                X_val=X_val, y_val=y_val,
                n_trials=self.config.hyperparameter_trials,
                timeout=timeout_per_model,
                target_id=target_id
            )
            
            results[model_name] = result
            
            self.logger.info(
                f"âœ… {model_name} å„ªåŒ–å®Œæˆ: Best RÂ²={result['best_value']:.4f}"
            )
            
            gc.collect()
        
        results['total_time'] = time.time() - total_start
        self._save_best_params_recommendation(results, target_id)
        
        return results
    
    def _save_best_params_recommendation(self, results: Dict[str, Any], target_id: str):
        """å„²å­˜æœ€ä½³åƒæ•¸ä¾›æ˜æ—¥æ—¥é–“è¨“ç·´ä½¿ç”¨"""
        recommendation = {
            'timestamp': datetime.now().isoformat(),
            'target_id': target_id,
            'models': {}
        }
        
        for model_name, result in results.items():
            if 'best_params' in result:
                recommendation['models'][model_name] = {
                    'best_params': result['best_params'],
                    'expected_performance': result['best_value']
                }
        
        import json
        with open(f"config/hyperparameter_recommendations_{target_id}.json", 'w') as f:
            json.dump(recommendation, f, indent=2)
```

#### Step 3.2: å¯è§£é‡‹æ€§å°è£ï¼ˆSHAP Integrationï¼‰

**æª”æ¡ˆ**: `src/modeling/explainability/shap_explainer.py`

**å¯¦ä½œå…§å®¹**:
```python
from typing import Dict, List, Optional, Any
import numpy as np
import polars as pl

class ModelExplainer:
    """
    æ¨¡å‹å¯è§£é‡‹æ€§å°è£å±¤ (v1.2)
    æ”¯æ´ TreeSHAP (é©ç”¨ XGB/LGB/RF) èˆ‡ HVAC å°ˆç”¨æ™‚é–“åºåˆ—è§£é‡‹
    
    æ³¨æ„ï¼šéœ€å®‰è£ shap: pip install shap
    """
    
    def __init__(self, model: Any, feature_names: List[str], model_type: str, target_id: str = "default"):
        self.model = model
        self.feature_names = feature_names
        self.model_type = model_type
        self.target_id = target_id  # v1.2 æ–°å¢
        self.explainer = None
        self.background_data = None
        self.is_fitted = False
        
        try:
            import shap
            self.shap = shap
        except ImportError:
            raise ImportError("E805: ä½¿ç”¨å¯è§£é‡‹æ€§åŠŸèƒ½éœ€å®‰è£ shap: pip install shap")
    
    def fit_background(self, X_background: np.ndarray, sample_size: int = 100):
        """
        å»ºç«‹ SHAP èƒŒæ™¯åˆ†ä½ˆï¼ˆç”¨æ–¼å°æ¯”åŸºæº–ï¼‰
        """
        if len(X_background) > sample_size:
            idx = np.random.choice(len(X_background), sample_size, replace=False)
            self.background_data = X_background[idx]
        else:
            self.background_data = X_background
        
        if self.model_type in ['xgboost', 'lightgbm', 'random_forest']:
            self.explainer = self.shap.TreeExplainer(self.model)
        else:
            self.explainer = self.shap.KernelExplainer(
                self.model.predict, 
                self.shap.sample(self.background_data, min(50, sample_size))
            )
        
        self.is_fitted = True
    
    def explain_local(self, X_instance: np.ndarray) -> Dict[str, Any]:
        """
        å–®ç­†é æ¸¬è§£é‡‹ï¼ˆå±€éƒ¨è§£é‡‹ï¼‰
        """
        if not self.is_fitted:
            raise RuntimeError("E804: éœ€å…ˆåŸ·è¡Œ fit_background()")
        
        if X_instance.ndim == 1:
            X_instance = X_instance.reshape(1, -1)
        
        shap_values = self.explainer.shap_values(X_instance)
        
        if isinstance(shap_values, list):
            shap_values = shap_values[0]
        
        feature_contrib = {
            name: float(val) 
            for name, val in zip(self.feature_names, shap_values[0])
        }
        
        sorted_contrib = sorted(feature_contrib.items(), key=lambda x: abs(x[1]), reverse=True)
        
        return {
            'target_id': self.target_id,
            'base_value': float(self.explainer.expected_value),
            'prediction': float(self.explainer.expected_value + np.sum(shap_values)),
            'feature_contributions': feature_contrib,
            'top_positive': sorted([x for x in feature_contrib.items() if x[1] > 0], 
                                  key=lambda x: x[1], reverse=True)[:3],
            'top_negative': sorted([x for x in feature_contrib.items() if x[1] < 0], 
                                  key=lambda x: x[1])[:3],
            'shap_values': shap_values.tolist()
        }
    
    def explain_batch(self, X: np.ndarray, batch_size: int = 100) -> List[Dict[str, Any]]:
        """æ‰¹æ¬¡è§£é‡‹ï¼ˆè¨˜æ†¶é«”æ•ˆç‡ç‰ˆï¼‰"""
        explanations = []
        for i in range(0, len(X), batch_size):
            batch = X[i:i+batch_size]
            for j in range(len(batch)):
                explanations.append(self.explain_local(batch[j]))
        return explanations
    
    def explain_temporal(self, X_series: np.ndarray, timestamps: List) -> pl.DataFrame:
        """
        HVAC å°ˆç”¨ï¼šæ™‚é–“åºåˆ—ç‰¹å¾µè²¢ç»è¿½è¹¤
        """
        explanations = self.explain_batch(X_series)
        
        df_data = {
            'timestamp': timestamps,
            'target_id': self.target_id,
            'base_value': [e['base_value'] for e in explanations],
            'prediction': [e['prediction'] for e in explanations],
            'primary_driver': [e['top_positive'][0][0] if e['top_positive'] else 'none' 
                              for e in explanations],
            'primary_contribution': [e['top_positive'][0][1] if e['top_positive'] else 0 
                                    for e in explanations]
        }
        
        for feat in self.feature_names:
            df_data[f'shap_{feat}'] = [
                e['feature_contributions'].get(feat, 0) for e in explanations
            ]
        
        return pl.DataFrame(df_data)
    
    def generate_summary_plot(self, X_test: np.ndarray, output_path: str):
        """ç”¢ç”Ÿç‰¹å¾µé‡è¦æ€§æ‘˜è¦åœ–ï¼ˆä¾›å·¥ç¨‹å¸«å¯©é–±ï¼‰"""
        import matplotlib.pyplot as plt
        
        shap_values = self.explainer.shap_values(X_test)
        if isinstance(shap_values, list):
            shap_values = shap_values[0]
        
        plt.figure(figsize=(12, 8))
        self.shap.summary_plot(
            shap_values, 
            X_test, 
            feature_names=self.feature_names,
            show=False
        )
        plt.tight_layout()
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        self.logger.info(f"SHAP æ‘˜è¦åœ–å·²å„²å­˜: {output_path}")
```

---

### Phase 4: å®Œæ•´è¨“ç·´æµç¨‹èˆ‡ç”¢å‡º (Day 8)

#### Step 4.1: å®Œæ•´è¨“ç·´æµç¨‹

**æª”æ¡ˆ**: `src/modeling/training_pipeline.py`ï¼ˆæ–¹æ³•æ›´æ–°ï¼‰

**å¯¦ä½œå…§å®¹**:
```python
def train(self, data: TrainingInputContract) -> 'MultiModelArtifact':
    """
    åŸ·è¡Œå®Œæ•´å¤šæ¨¡å‹è¨“ç·´æµç¨‹ (v1.2)
    
    æµç¨‹ï¼š
    1. è¼¸å…¥é©—è­‰èˆ‡å¥‘ç´„æª¢æŸ¥
    2. æ™‚åºè³‡æ–™åˆ†å‰²ï¼ˆé›¶æ´©æ¼ï¼‰
    3. Device Role æ¬Šé‡è¨ˆç®—
    4. ç‰¹å¾µå‰è™•ç†ï¼ˆç¸®æ”¾ã€ç¼ºå¤±å€¼ï¼‰
    5. è³‡æ ¼æª¢æŸ¥ï¼ˆæ¨£æœ¬æ•¸ã€è¨˜æ†¶é«”ï¼‰
    6. æ¨¡å‹è¨“ç·´ï¼ˆå¹³è¡Œæˆ–åºåˆ—ï¼‰
    7. æ¸¬è©¦é›†æœ€çµ‚è©•ä¼°
    8. å¯è§£é‡‹æ€§åˆå§‹åŒ–ï¼ˆè‹¥å•Ÿç”¨ï¼‰
    9. ç”¢å‡º MultiModelArtifactï¼ˆå« target_id æ¨™è¨˜ï¼‰
    
    Returns:
        MultiModelArtifact: åŒ…å«ä¸‰æ¨¡å‹çµæœã€æœ€ä½³æ¨¡å‹é¸æ“‡ã€ä»¥åŠå¯è§£é‡‹æ€§ä»‹é¢
    """
    self.training_stats['start_time'] = datetime.now().isoformat()
    
    # Step 1: è¼¸å…¥é©—è­‰
    self._validate_input_contract(data)
    df = data['feature_matrix']
    target_col = data['target_variable']
    n_samples = len(df)
    
    self.logger.info(f"ğŸš€ é–‹å§‹è¨“ç·´æµç¨‹: site={self.site_id}, target={self.target_id}, samples={n_samples}")
    
    # Step 2: æ™‚åºåˆ†å‰²
    train_df, val_df, test_df, y_train, y_val, y_test = self._temporal_split(df, target_col)
    
    # Step 3: Device Role è™•ç†
    sample_weights, seasonal_mask = self._compute_sample_weights_and_masks(train_df)
    if np.any(seasonal_mask == False):
        train_df = train_df.filter(pl.Series(seasonal_mask))
        y_train = y_train.filter(pl.Series(seasonal_mask))
        sample_weights = sample_weights[seasonal_mask]
    
    # Step 4: ç‰¹å¾µå‰è™•ç†
    X_train, X_val, X_test, feature_cols = self._preprocess_features(train_df, val_df, test_df)
    
    # Step 5: å¤šæ¨¡å‹è¨“ç·´
    self.train_all_models(
        X_train=X_train, y_train=y_train.to_numpy(),
        X_val=X_val, y_val=y_val.to_numpy(),
        sample_weights=sample_weights,
        feature_names=feature_cols
    )
    
    # Step 6: æ¸¬è©¦é›†æœ€çµ‚è©•ä¼°
    best_name, best_trainer, best_result = self.get_best_model()
    test_metrics = best_trainer.evaluate(X_test, y_test.to_numpy())
    
    self.logger.info(
        f"ğŸ§ª [{self.target_id}] æœ€ä½³æ¨¡å‹ [{best_name}] æ¸¬è©¦é›†: RÂ²={test_metrics['r2']:.4f}"
    )
    
    # Step 7: å¯è§£é‡‹æ€§åˆå§‹åŒ–
    explainer = None
    if self.config.enable_explainability:
        try:
            from src.modeling.explainability.shap_explainer import ModelExplainer
            
            explainer = ModelExplainer(
                model=best_trainer.model,
                feature_names=feature_cols,
                model_type=best_name,
                target_id=self.target_id
            )
            explainer.fit_background(X_val, sample_size=self.config.shap_background_samples)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ å¯è§£é‡‹æ€§åˆå§‹åŒ–å¤±æ•—: {e}")
    
    # Step 8: å»ºç«‹ç”¢å‡ºç‰©
    self.training_stats['end_time'] = datetime.now().isoformat()
    
    artifact = MultiModelArtifact(
        target_id=self.target_id,
        site_id=self.site_id,
        trainers=self.trainers,
        results=self.results,
        best_model_name=best_name,
        test_metrics=test_metrics,
        training_metadata=self._build_training_metadata(data, test_metrics),
        annotation_context=data['annotation_context'],
        feature_names=feature_cols,
        config=self.config,
        explainer=explainer,
        training_stats=self.training_stats
    )
    
    return artifact
```

#### Step 4.2: å¤šæ¨¡å‹ç”¢å‡ºç‰©å®šç¾©ï¼ˆv1.2 æ“´å……ï¼‰

**æª”æ¡ˆ**: `src/modeling/artifacts.py`

**å¯¦ä½œå…§å®¹**:
```python
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from pathlib import Path
import json
import joblib
from datetime import datetime
import hashlib

@dataclass
class MultiModelArtifact:
    """
    å¤šæ¨¡å‹è¨“ç·´ç”¢å‡ºç‰© (v1.2)
    
    å„²å­˜çµæ§‹:
    models/
    â””â”€â”€ {site_id}/
        â”œâ”€â”€ model_registry_index.json           # ç¸½ç´¢å¼•ï¼ˆOptimization Engine å…¥å£ï¼‰
        â”œâ”€â”€ {target_id}/                        # ç›®æ¨™å°ˆå±¬ç›®éŒ„ï¼ˆv1.2 æ¨™æº–åŒ–ï¼‰
        â”‚   â”œâ”€â”€ {timestamp}_ensemble_manifest.json
        â”‚   â”œâ”€â”€ {timestamp}_xgboost_model.joblib
        â”‚   â”œâ”€â”€ {timestamp}_lightgbm_model.joblib
        â”‚   â”œâ”€â”€ {timestamp}_random_forest_model.joblib
        â”‚   â”œâ”€â”€ {timestamp}_shap_summary.png
        â”‚   â””â”€â”€ {timestamp}_explainability_metadata.json
        â””â”€â”€ ...
    """
    
    target_id: str  # v1.2 æ–°å¢
    site_id: str    # v1.2 æ–°å¢
    trainers: Dict[str, BaseModelTrainer]
    results: Dict[str, Dict[str, Any]]
    best_model_name: str
    test_metrics: Dict[str, float]
    training_metadata: Dict[str, Any]
    annotation_context: Dict[str, Any]
    feature_names: List[str]
    config: ModelTrainingConfig
    explainer: Optional[Any] = None
    training_stats: Dict[str, Any] = field(default_factory=dict)
    
    def _calculate_checksum(self, file_path: Path) -> str:
        """è¨ˆç®—æª”æ¡ˆ SHA256 checksum"""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return f"sha256:{sha256_hash.hexdigest()}"
    
    def save(self, output_dir: Path) -> Dict[str, Path]:
        """
        å„²å­˜æ‰€æœ‰æ¨¡å‹ã€å…ƒè³‡æ–™èˆ‡å¯è§£é‡‹æ€§ç‰©ä»¶
        å›å‚³å„²å­˜çš„æª”æ¡ˆè·¯å¾‘å­—å…¸
        """
        output_dir = Path(output_dir) / self.site_id / self.target_id
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        saved_files = {}
        
        # å„²å­˜æ¯å€‹æ¨¡å‹
        for name, trainer in self.trainers.items():
            if name not in self.results or 'error' in self.results[name]:
                continue
            
            model_path = output_dir / f"{timestamp}_{name}_model.joblib"
            metadata_path = output_dir / f"{timestamp}_{name}_metadata.json"
            
            # å„²å­˜æ¨¡å‹
            joblib.dump({
                'model': trainer.model,
                'scaler': getattr(trainer, 'scaler', None),
                'feature_names': self.feature_names,
                'model_metadata': trainer.get_model_info(),
                'target_id': self.target_id,
                'site_id': self.site_id
            }, model_path, compress=3)
            
            # è¨ˆç®— checksum
            model_checksum = self._calculate_checksum(model_path)
            
            # å„²å­˜è©²æ¨¡å‹å…ƒè³‡æ–™
            model_meta = {
                'name': name,
                'target_id': self.target_id,
                'metrics': self.results[name]['metrics'],
                'feature_importance': trainer.get_feature_importance(),
                'training_history': self.results[name].get('training_history', {}),
                'best_iteration': self.results[name].get('best_iteration'),
                'oob_score': self.results[name].get('oob_score'),
                'training_time': self.results[name].get('training_time', 0),
                'file_checksum': model_checksum
            }
            
            with open(metadata_path, 'w') as f:
                json.dump(model_meta, f, indent=2, default=str)
            
            saved_files[f'{name}_model'] = model_path
            saved_files[f'{name}_metadata'] = metadata_path
        
        # å„²å­˜ Ensemble Manifestï¼ˆè©² target çš„ç¸½è¦½ï¼‰
        manifest_data = {
            'timestamp': timestamp,
            'target_id': self.target_id,
            'site_id': self.site_id,
            'best_model': self.best_model_name,
            'test_metrics': self.test_metrics,
            'training_stats': self.training_stats,
            'models': {}
        }
        
        for name in self.trainers.keys():
            if name in self.results and 'error' not in self.results[name]:
                manifest_data['models'][name] = {
                    'model_file': f"{timestamp}_{name}_model.joblib",
                    'metadata_file': f"{timestamp}_{name}_metadata.json",
                    'val_r2': self.results[name]['metrics']['val']['r2'],
                    'test_r2': self.test_metrics['r2'] if name == self.best_model_name else None,
                    'is_best': name == self.best_model_name
                }
        
        manifest_data['training_metadata'] = self.training_metadata
        manifest_data['annotation_context'] = self.annotation_context
        
        manifest_path = output_dir / f"{timestamp}_ensemble_manifest.json"
        with open(manifest_path, 'w') as f:
            json.dump(manifest_data, f, indent=2, default=str)
        saved_files['ensemble_manifest'] = manifest_path
        
        # å„²å­˜å¯è§£é‡‹æ€§ç‰©ä»¶
        if self.explainer is not None and self.config.enable_explainability:
            try:
                explainer_path = output_dir / f"{timestamp}_explainer.joblib"
                joblib.dump({
                    'explainer': self.explainer.explainer,
                    'feature_names': self.explainer.feature_names,
                    'model_type': self.explainer.model_type,
                    'target_id': self.target_id,
                    'background_data': self.explainer.background_data
                }, explainer_path)
                saved_files['explainer'] = explainer_path
                
                # ç”¢ç”Ÿæ‘˜è¦åœ–
                if hasattr(self.explainer, 'background_data'):
                    summary_path = output_dir / f"{timestamp}_shap_summary.png"
                    self.explainer.generate_summary_plot(
                        self.explainer.background_data, 
                        str(summary_path)
                    )
                    saved_files['shap_summary'] = summary_path
                
            except Exception as e:
                manifest_data['explainability_error'] = str(e)
        
        return saved_files
    
    @classmethod
    def load(cls, manifest_path: Path, model_name: Optional[str] = None):
        """
        è¼‰å…¥æŒ‡å®šæ¨¡å‹æˆ–æœ€ä½³æ¨¡å‹
        æ”¯æ´ target_id æ¨™è¨˜
        """
        with open(manifest_path, 'r') as f:
            manifest = json.load(f)
        
        model_dir = manifest_path.parent
        
        target_model = model_name or manifest['best_model']
        model_info = manifest['models'][target_model]
        
        model_data = joblib.load(model_dir / model_info['model_file'])
        
        explainer = None
        explainer_path = model_dir / f"{manifest['timestamp']}_explainer.joblib"
        if explainer_path.exists():
            try:
                explainer_data = joblib.load(explainer_path)
                explainer = explainer_data
            except Exception as e:
                print(f"Warning: ç„¡æ³•è¼‰å…¥ explainer: {e}")
        
        return {
            'target_id': manifest['target_id'],
            'model_data': model_data,
            'manifest': manifest,
            'explainer': explainer,
            'loaded_model': target_model
        }
    
    def predict_with_explanation(self, X: np.ndarray) -> Dict[str, Any]:
        """
        é æ¸¬ä¸¦æä¾›è§£é‡‹ï¼ˆv1.2 ä¾¿åˆ©æ–¹æ³•ï¼‰
        """
        if self.best_model_name not in self.trainers:
            raise RuntimeError("æœ€ä½³æ¨¡å‹æœªè¨“ç·´")
        
        trainer = self.trainers[self.best_model_name]
        prediction = trainer.predict(X)
        
        result = {
            'target_id': self.target_id,
            'prediction': prediction,
            'model_used': self.best_model_name,
            'explanation': None
        }
        
        if self.explainer is not None:
            try:
                explanation = self.explainer.explain_local(X)
                result['explanation'] = explanation
                result['top_drivers'] = explanation['top_positive']
            except Exception as e:
                result['explanation_error'] = str(e)
        
        return result
```

---

### Phase 5: å¤šç›®æ¨™æ‰¹æ¬¡è¨“ç·´å”èª¿å™¨ (Day 9-10) - v1.2 æ–°å¢

#### Step 5.1: BatchTrainingCoordinator å¯¦ä½œ

**æª”æ¡ˆ**: `src/modeling/coordinators/batch_coordinator.py`

**å¯¦ä½œå…§å®¹**:
```python
from typing import Dict, List, Optional, Literal
import logging
from datetime import datetime
from pathlib import Path
import json

from src.modeling.training_pipeline import TrainingPipeline
from src.modeling.config_models import ModelTrainingConfig
from src.modeling.artifacts import MultiModelArtifact

class BatchTrainingCoordinator:
    """
    å¤šç›®æ¨™æ‰¹æ¬¡è¨“ç·´å”èª¿å™¨ (v1.2 æ–°å¢)
    
    è² è²¬å”èª¿å¤šå€‹ç›®æ¨™è®Šæ•¸ï¼ˆå¦‚ system_total_kw, chiller_1_kw, chiller_2_kw...ï¼‰çš„æ‰¹æ¬¡è¨“ç·´ï¼Œ
    ç¢ºä¿ï¼š
    1. æ‰€æœ‰ç›®æ¨™ä½¿ç”¨ç›¸åŒçš„ Annotation Contextï¼ˆç‰ˆæœ¬ä¸€è‡´æ€§ï¼‰
    2. è¨˜æ†¶é«”ç®¡ç†ï¼šé™åˆ¶åŒæ™‚è¨“ç·´çš„ç›®æ¨™æ•¸ï¼Œé˜²æ­¢ OOM
    3. ç”¢å‡ºçµ±ä¸€çš„ Model Registry Indexï¼ˆä¾› Optimization Engine ä½¿ç”¨ï¼‰
    4. æ”¯æ´ Hybrid æ¨¡å¼çš„ä¸€è‡´æ€§æª¢æŸ¥ï¼ˆComponent Models åŠ ç¸½ â‰ˆ System Modelï¼‰
    """
    
    def __init__(self, config: ModelTrainingConfig, site_id: str):
        self.config = config
        self.site_id = site_id
        self.logger = logging.getLogger(__name__)
        self.artifacts: Dict[str, MultiModelArtifact] = {}
        self.training_logs: List[Dict] = []
        
    def train_multiple_targets(
        self,
        data: TrainingInputContract,
        targets: List[str],
        strategy: Literal["sequential", "parallel_safe"] = "sequential"
    ) -> Dict[str, MultiModelArtifact]:
        """
        æ‰¹æ¬¡è¨“ç·´å¤šå€‹ç›®æ¨™è®Šæ•¸
        
        Args:
            data: TrainingInputContractï¼ˆåŒ…å« feature_matrixï¼‰
            targets: ç›®æ¨™è®Šæ•¸åç¨±åˆ—è¡¨ï¼Œå¦‚ ["system_total_kw", "chiller_1_kw", "chiller_2_kw"]
            strategy: 
                - "sequential": ä¾åºè¨“ç·´ï¼Œæœ€å®‰å…¨ï¼ˆé è¨­ï¼‰
                - "parallel_safe": æœ‰é™åº¦å¹³è¡Œï¼ˆå—é™æ–¼ ResourceConfig.max_concurrent_targetsï¼‰
        
        Returns:
            Dict[target_name, MultiModelArtifact]: å„ç›®æ¨™çš„è¨“ç·´ç”¢å‡ºç‰©
        """
        self.logger.info(f"ğŸ¯ é–‹å§‹æ‰¹æ¬¡è¨“ç·´: site={self.site_id}, targets={targets}, strategy={strategy}")
        
        # é©—è­‰æ‰€æœ‰ targets å­˜åœ¨æ–¼è³‡æ–™ä¸­
        available_cols = data['feature_matrix'].columns
        missing_targets = [t for t in targets if t not in available_cols]
        if missing_targets:
            raise ValueError(f"E902: ä»¥ä¸‹ç›®æ¨™è®Šæ•¸ä¸å­˜åœ¨æ–¼è³‡æ–™ä¸­: {missing_targets}")
        
        # é©—è­‰ Annotation Context ä¸€è‡´æ€§ï¼ˆæ‰€æœ‰ target å¿…é ˆç›¸åŒï¼‰
        base_annotation = data['annotation_context']
        
        # ä¾åºè¨“ç·´
        if strategy == "sequential":
            for target in targets:
                self.logger.info(f"ğŸš€ è¨“ç·´ç›®æ¨™: {target}")
                
                # æ›´æ–° Input Contract ç‚ºå–®ä¸€ç›®æ¨™
                single_target_data = data.copy()
                single_target_data['target_variable'] = target
                single_target_data['training_mode'] = 'single_target'
                
                # å»ºç«‹ Pipeline ä¸¦è¨“ç·´
                pipeline = TrainingPipeline(
                    config=self.config,
                    site_id=self.site_id,
                    target_id=target
                )
                
                try:
                    artifact = pipeline.train(single_target_data)
                    self.artifacts[target] = artifact
                    
                    # å„²å­˜
                    saved_files = artifact.save(self.config.model_output_dir)
                    self.training_logs.append({
                        'target': target,
                        'status': 'success',
                        'best_model': artifact.best_model_name,
                        'test_r2': artifact.test_metrics['r2'],
                        'files': [str(p) for p in saved_files.values()]
                    })
                    
                except Exception as e:
                    self.logger.error(f"âŒ ç›®æ¨™ {target} è¨“ç·´å¤±æ•—: {e}")
                    self.training_logs.append({
                        'target': target,
                        'status': 'failed',
                        'error': str(e)
                    })
                    # ä¾æ“šè¨­å®šæ±ºå®šæ˜¯å¦ç¹¼çºŒ
                    if not getattr(self.config, 'continue_on_error', True):
                        raise
        
        # ç”¢å‡º Model Registry Index
        self._generate_registry_index(targets)
        
        # Hybrid æ¨¡å¼ä¸€è‡´æ€§æª¢æŸ¥
        if self.config.training_mode == 'hybrid' and 'system_total_kw' in self.artifacts:
            self._validate_hybrid_consistency()
        
        return self.artifacts
    
    def _generate_registry_index(self, targets: List[str]):
        """
        ç”¢ç”Ÿ Model Registry Indexï¼ˆOptimization Engine çš„å…¥å£æª”æ¡ˆï¼‰
        """
        index_data = {
            'schema_version': '1.2',
            'site_id': self.site_id,
            'training_timestamp': datetime.now().isoformat(),
            'annotation_checksum': self.config.annotation_context.get('yaml_checksum', 'unknown'),
            'training_mode': self.config.training_mode,
            'available_models': {},
            'compatibility': {
                'optimization_engine_min_version': '1.0',
                'feature_annotation_version': '1.2',
                'python_version': '3.10+',
                'required_packages': ['xgboost>=1.7', 'lightgbm>=4.0', 'scikit-learn>=1.3']
            }
        }
        
        for target in targets:
            if target not in self.artifacts:
                continue
            
            artifact = self.artifacts[target]
            model_entry = {
                'type': 'system_level' if target == 'system_total_kw' else 'component_level',
                'path': f"{target}/{artifact.training_stats['start_time']}_ensemble_manifest.json",
                'target_variable': target,
                'feature_count': len(artifact.feature_names),
                'best_algorithm': artifact.best_model_name,
                'metrics': {
                    'val_r2': artifact.results[artifact.best_model_name]['metrics']['val']['r2'],
                    'test_r2': artifact.test_metrics['r2'],
                    'rmse': artifact.test_metrics['rmse'],
                    'mape': artifact.test_metrics['mape']
                },
                'checksum': 'pending',  # å¯¦éš›å„²å­˜æ™‚è¨ˆç®—
                'optional': target != 'system_total_kw'  # System Model ç‚ºå¿…é ˆï¼ŒComponent ç‚ºå¯é¸
            }
            
            if self.config.training_mode == 'hybrid':
                model_entry['parent_system_model'] = 'system_total_kw' if target != 'system_total_kw' else None
            
            index_data['available_models'][target] = model_entry
        
        # å„²å­˜ Index
        index_path = Path(self.config.model_output_dir) / self.site_id / 'model_registry_index.json'
        index_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(index_path, 'w') as f:
            json.dump(index_data, f, indent=2, default=str)
        
        self.logger.info(f"ğŸ“‹ Model Registry Index å·²ç”¢ç”Ÿ: {index_path}")
    
    def _validate_hybrid_consistency(self, tolerance: float = 0.05):
        """
        é©—è­‰ Hybrid æ¨¡å¼ä¸€è‡´æ€§ï¼š
        Component Models çš„åŠ ç¸½æ‡‰èˆ‡ System Model é æ¸¬ç›¸è¿‘
        ï¼ˆå®¹å·®é è¨­ 5%ï¼‰
        """
        if 'system_total_kw' not in self.artifacts:
            return
        
        system_artifact = self.artifacts['system_total_kw']
        # å–å¾— System Model çš„é©—è­‰é›†é æ¸¬ï¼ˆå‡è¨­å·²å„²å­˜ï¼‰
        
        component_sum = None
        component_targets = [t for t in self.artifacts.keys() if t != 'system_total_kw']
        
        if not component_targets:
            return
        
        # ç°¡åŒ–é©—è­‰ï¼šæ¯”è¼ƒç‰¹å¾µé‡è¦æ€§åˆ†ä½ˆï¼ˆé€²éšç‰ˆå¯æ¯”è¼ƒå¯¦éš›é æ¸¬å€¼ï¼‰
        self.logger.info("ğŸ” åŸ·è¡Œ Hybrid æ¨¡å¼ä¸€è‡´æ€§æª¢æŸ¥...")
        
        # é€™è£¡æ‡‰è¼‰å…¥é©—è­‰é›†è³‡æ–™é€²è¡Œå¯¦éš›é æ¸¬æ¯”è¼ƒ
        # ç°¡åŒ–ç¤ºä¾‹ï¼š
        system_importance = set(system_artifact.trainers[system_artifact.best_model_name].get_feature_importance().keys())
        
        for comp_target in component_targets:
            comp_artifact = self.artifacts[comp_target]
            comp_importance = set(comp_artifact.trainers[comp_artifact.best_model_name].get_feature_importance().keys())
            
            # æª¢æŸ¥ç‰¹å¾µé‡ç–Šåº¦
            overlap = len(system_importance & comp_importance) / len(system_importance)
            if overlap < 0.8:
                self.logger.warning(
                    f"âš ï¸ {comp_target} èˆ‡ System Model ç‰¹å¾µé‡ç–Šåº¦åƒ… {overlap:.1%}ï¼Œ"
                    "å¯èƒ½å°è‡´ä¸€è‡´æ€§å•é¡Œ"
                )
        
        self.logger.info("âœ… Hybrid ä¸€è‡´æ€§æª¢æŸ¥å®Œæˆ")
    
    def get_registry_index_path(self) -> Path:
        """å–å¾— Model Registry Index è·¯å¾‘ï¼ˆä¾› Optimization Engine ä½¿ç”¨ï¼‰"""
        return Path(self.config.model_output_dir) / self.site_id / 'model_registry_index.json'
```

---

## 4. éŒ¯èª¤ä»£ç¢¼å°ç…§è¡¨ (Error Codes) - v1.2 æ›´æ–°

| éŒ¯èª¤ä»£ç¢¼ | åç¨± | ç™¼ç”Ÿéšæ®µ | èªªæ˜ | è™•ç†å»ºè­° |
|:---|:---|:---:|:---|:---|
| **E601** | `ANNOTATION_CONTEXT_MISSING` | Step 1.1 | ç¼ºå°‘ annotation_context | ç¢ºèª Feature Engineer v1.3+ |
| **E602** | `SCHEMA_VERSION_MISMATCH` | Step 1.1 | Annotation ç‰ˆæœ¬ä¸ç¬¦ | é‡æ–°è¨“ç·´æˆ–é™ç´š Annotation |
| **E603** | `TARGET_VARIABLE_MISSING` | Step 1.1 | ç›®æ¨™è®Šæ•¸ä¸å­˜åœ¨ | æª¢æŸ¥ç‰¹å¾µå·¥ç¨‹è¼¸å‡º |
| **E604** | `TIMESTAMP_INVALID` | Step 1.1 | æ™‚é–“æˆ³æ ¼å¼éŒ¯èª¤ | æª¢æŸ¥ Feature Engineer |
| **E607** | `INSUFFICIENT_SAMPLES` | Step 3 | æ¨£æœ¬ä¸è¶³ï¼ˆ<100ï¼‰ | æª¢æŸ¥è³‡æ–™é®ç½©é‚è¼¯ |
| **E701** | `DEVICE_ROLE_AS_FEATURE` | Step 0.1 | è¨­å®šéŒ¯èª¤å˜—è©¦å°‡ device_role ä½œç‚ºç‰¹å¾µ | ä¿®æ”¹è¨­å®š |
| **E702** | `MODEL_NOT_FITTED` | Prediction | é æ¸¬å‰æœªè¨“ç·´ | ç¢ºä¿å·²åŸ·è¡Œ train() |
| **E703** | `ALL_MODELS_FAILED` | Step 5 | ä¸‰æ¨¡å‹å…¨éƒ¨è¨“ç·´å¤±æ•— | æª¢æŸ¥è³‡æ–™å“è³ªæˆ–ç‰¹å¾µå·¥ç¨‹ |
| **E704** | `XGBOOST_IMPORT_ERROR` | Import | XGBoost æœªå®‰è£ | `pip install xgboost` |
| **E705** | `LIGHTGBM_IMPORT_ERROR` | Import | LightGBM æœªå®‰è£ | `pip install lightgbm` |
| **E706** | `SELECTION_NOT_EXECUTED` | Step 6 | å°šæœªåŸ·è¡Œæ¨¡å‹é¸æ“‡ | å…ˆåŸ·è¡Œ train_all_models() |
| **E707** | `ENSEMBLE_NO_VALID_MODEL` | Ensemble | ç„¡å¯ç”¨æ¨¡å‹é€²è¡Œ Ensemble | æª¢æŸ¥è¨“ç·´çµæœ |
| **E801** | `MEMORY_SAFETY_TRIGGERED` | Step 5 | è¨˜æ†¶é«”ä¸è¶³è‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´ | æ­£å¸¸è¡Œç‚ºï¼Œæˆ–å¢åŠ è¨˜æ†¶é«” |
| **E802** | `OPTUNA_PRUNING_EXCESSIVE` | Hyperparam | éå¤š trials è¢«å‰ªæ | æç¤ºæœå°‹ç©ºé–“å¯èƒ½éå¤§ |
| **E803** | `SHAP_BACKGROUND_TOO_LARGE` | Explain | SHAP èƒŒæ™¯è³‡æ–™éå¤§ | å·²è‡ªå‹•å–æ¨£ï¼Œå¯å¿½ç•¥ |
| **E804** | `EXPLAINER_NOT_FITTED` | Explain | æœªå…ˆåŸ·è¡Œ fit_background | å…ˆå‘¼å« fit_background() |
| **E805** | `SHAP_NOT_INSTALLED` | Import | æœªå®‰è£ shap å¥—ä»¶ | `pip install shap` |
| **E901** | `MULTI_TARGET_ANNOTATION_MISMATCH` | Phase 5 | å¤šç›®æ¨™è¨“ç·´æ™‚ Annotation Context ä¸ä¸€è‡´ | ç¢ºä¿æ‰€æœ‰ targets ä½¿ç”¨ç›¸åŒ Feature Annotation |
| **E902** | `TARGET_VARIABLE_NOT_FOUND` | Phase 5 | æŒ‡å®šçš„ target ä¸å­˜åœ¨æ–¼è³‡æ–™é›†ä¸­ | æª¢æŸ¥ target åç¨±æ˜¯å¦æ­£ç¢º |
| **E903** | `HYBRID_CONSISTENCY_VIOLATION` | Phase 5 | Hybrid æ¨¡å¼ä¸‹ Component åŠ ç¸½èˆ‡ System é æ¸¬å·®ç•°éå¤§ | æª¢æŸ¥ç‰¹å¾µå·¥ç¨‹æˆ–æ”¹ç”¨ç´” System-Level |

---

## 5. èˆ‡ Optimization Engine çš„ä»‹é¢å¥‘ç´„ (v1.2 æ–°å¢ç« ç¯€)

### 5.1 æ¨¡å‹è¼‰å…¥è¦ç¯„

Optimization Engine v1.0+ æ‡‰é€éä»¥ä¸‹æ–¹å¼è¼‰å…¥æ¨¡å‹ï¼š

```python
# Optimization Engine è¼‰å…¥ç¯„ä¾‹ï¼ˆä¾›åƒè€ƒï¼‰
class OptimizationModelLoader:
    def load_from_registry(self, site_id: str, target: Optional[str] = None):
        """
        å¾ Model Registry Index è¼‰å…¥æ¨¡å‹
        è‹¥ target ç‚º Noneï¼Œé è¨­è¼‰å…¥ 'system_total_kw'
        """
        index_path = f"models/{site_id}/model_registry_index.json"
        
        with open(index_path, 'r') as f:
            index = json.load(f)
        
        # é©—è­‰ç›¸å®¹æ€§
        if index['schema_version'] != '1.2':
            warnings.warn(f"Model Registry ç‰ˆæœ¬ {index['schema_version']} èˆ‡é æœŸ 1.2 ä¸åŒ")
        
        target = target or 'system_total_kw'
        if target not in index['available_models']:
            raise ValueError(f"ç›®æ¨™ {target} ä¸å¯ç”¨ï¼Œå¯ç”¨ç›®æ¨™: {list(index['available_models'].keys())}")
        
        model_entry = index['available_models'][target]
        
        # é©—è­‰ Annotation Checksumï¼ˆç¢ºä¿èˆ‡ç•¶å‰ Feature Annotation ç›¸å®¹ï¼‰
        current_checksum = self.get_current_annotation_checksum()
        if model_entry.get('annotation_checksum') != current_checksum:
            warnings.warn("E802: æ¨¡å‹è¨“ç·´æ™‚çš„ Annotation ç‰ˆæœ¬èˆ‡ç•¶å‰ä¸åŒ")
        
        # è¼‰å…¥æ¨¡å‹
        manifest_path = f"models/{site_id}/{model_entry['path']}"
        return MultiModelArtifact.load(manifest_path)
```

### 5.2 ç‰ˆæœ¬ç›¸å®¹æ€§çŸ©é™£

| Training PRD | Optimization PRD | ç›¸å®¹æ€§ | èªªæ˜ |
|:---:|:---:|:---:|:---|
| v1.2 | v1.0+ | âœ… **å®Œå…¨ç›¸å®¹** | æ¨è–¦é…ç½®ï¼Œæ”¯æ´å¤šç›®æ¨™èˆ‡ Model Registry Index |
| v1.1 | v1.0+ | âš ï¸ **éƒ¨åˆ†ç›¸å®¹** | éœ€æ‰‹å‹•æŒ‡å®šæ¨¡å‹è·¯å¾‘ï¼Œç„¡ Registry Index |
| v1.0 | v1.0+ | âŒ **ä¸ç›¸å®¹** | è¼¸å‡ºæ ¼å¼ä¸åŒ |

---

## 6. æ¸¬è©¦èˆ‡é©—è­‰è¨ˆç•« (Test Plan) - v1.2 æ›´æ–°

### 6.1 å–®å…ƒæ¸¬è©¦ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼‰

### 6.2 æ•´åˆæ¸¬è©¦ï¼ˆv1.2 æ–°å¢å¤šç›®æ¨™æ¸¬è©¦ï¼‰

| æ¸¬è©¦æ¡ˆä¾‹ ID | æè¿° | é©—è­‰ç›®æ¨™ |
|:---|:---|:---|
| INT-MT-008 | æ‰¹æ¬¡è¨“ç·´å”èª¿å™¨ | BatchTrainingCoordinator æ­£ç¢ºä¾åºè¨“ç·´ 3 å€‹ targets |
| INT-MT-009 | Model Registry Index ç”¢å‡º | é©—è­‰ index.json æ ¼å¼æ­£ç¢ºï¼ŒOptimization Engine å¯è§£æ |
| INT-MT-010 | Hybrid ä¸€è‡´æ€§æª¢æŸ¥ | Component Models åŠ ç¸½èˆ‡ System Model å·®ç•° < 5% |
| INT-MT-011 | è¨˜æ†¶é«”é™åˆ¶æ‰¹æ¬¡è¨“ç·´ | é™åˆ¶è¨˜æ†¶é«”ä¸‹ï¼Œå”èª¿å™¨è‡ªå‹•é™ç‚ºå–®ç›®æ¨™åºåˆ—è¨“ç·´ |
| INT-MT-012 | èˆ‡ Optimization Engine E2E | Training ç”¢å‡º â†’ Optimization è¼‰å…¥ â†’ é æ¸¬é©—è­‰ |

---

## 7. é©—æ”¶ç°½æ ¸ (Sign-off Checklist) - v1.2 æ›´æ–°

- [ ] **ä¸‰æ¨¡å‹å¯¦ä½œ**: XGBoostã€LightGBMã€Random Forest çš†å¯ç¨ç«‹è¨“ç·´
- [ ] **å‹•æ…‹è³‡æ ¼æª¢æŸ¥**: æ¨£æœ¬æ•¸ 300 æ™‚åƒ…å•Ÿç”¨ RF èˆ‡ XGBï¼ˆé™åˆ¶æ·±åº¦ï¼‰
- [ ] **è¨˜æ†¶é«”ä¿è­·**: åœ¨ 4GB é™åˆ¶ä¸‹è‡ªå‹•é™ç´šç‚ºåºåˆ—è¨“ç·´ï¼Œç„¡ OOM
- [ ] **æ¨£æœ¬æ¬Šé‡**: ä¸‰æ¨¡å‹çš†æ­£ç¢ºè™•ç† Device Role æ¬Šé‡ï¼ˆBackup=0.3ï¼‰
- [ ] **ç‰¹å¾µé‡è¦æ€§**: æ¯å€‹æ¨¡å‹è¼¸å‡ºæ¨™æº–åŒ–é‡è¦æ€§ï¼ˆç¸½å’Œç‚º1ï¼‰
- [ ] **RF å€é–“é æ¸¬**: Random Forest æ”¯æ´ `predict_with_interval()` è¼¸å‡º Q10/Q90
- [ ] **è‡ªå‹•æ¨¡å‹é¸æ“‡**: ä¾ Val RÂ² èˆ‡ OOB å·®è·ç¶œåˆè©•åˆ†é¸æ“‡æœ€ä½³æ¨¡å‹
- [ ] **éŒ¯èª¤éš”é›¢**: å–®ä¸€æ¨¡å‹å¤±æ•—ä¸å½±éŸ¿å…¶ä»–æ¨¡å‹è¨“ç·´èˆ‡æœ€çµ‚ç”¢å‡º
- [ ] **ç‰ˆæœ¬ç¶å®š**: å„²å­˜çš„ Manifest åŒ…å« Annotation yaml_checksum
- [ ] **å¤œé–“å„ªåŒ–å™¨**: OvernightOptimizer æ”¯æ´æ–·é»çºŒå‚³èˆ‡ Trial Pruning
- [ ] **å¯è§£é‡‹æ€§é ç•™**: MultiModelArtifact æ”¯æ´ `predict_with_explanation()`ï¼ˆè‹¥å•Ÿç”¨ SHAPï¼‰
- [ ] **å¢é‡å­¸ç¿’é ç•™**: BaseModelTrainer åŒ…å« `partial_fit()` ä»‹é¢ï¼ˆRF å·²å¯¦ä½œï¼‰
- [ ] **v1.2 æ–°å¢**: BatchTrainingCoordinator æ”¯æ´å¤šç›®æ¨™æ‰¹æ¬¡è¨“ç·´
- [ ] **v1.2 æ–°å¢**: Model Registry Index è‡ªå‹•ç”¢ç”Ÿï¼Œæ ¼å¼ç¬¦åˆ Optimization Engine è¦ç¯„
- [ ] **v1.2 æ–°å¢**: System/Component/Hybrid ä¸‰ç¨®æ¨¡å¼çš†å¯æ­£å¸¸é‹ä½œ

---

## 8. é™„éŒ„

### Appendix A: è³‡æºç®¡ç†æ±ºç­–æµç¨‹åœ–ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼‰

### Appendix B: è¶…åƒæ•¸æœå°‹ä½¿ç”¨æŒ‡å—ï¼ˆv1.1 å…§å®¹ä¿ç•™ï¼‰

### Appendix C: Model Registry Index ç¯„ä¾‹ï¼ˆv1.2 æ–°å¢ï¼‰

```json
{
  "schema_version": "1.2",
  "site_id": "cgmh_ty",
  "training_timestamp": "2026-02-13T10:00:00Z",
  "annotation_checksum": "sha256:abc123...",
  "training_mode": "hybrid",
  "available_models": {
    "system_total_kw": {
      "type": "system_level",
      "path": "system_total_kw/20260213_100000_ensemble_manifest.json",
      "target_variable": "system_total_kw",
      "feature_count": 42,
      "best_algorithm": "xgboost",
      "metrics": {
        "val_r2": 0.92,
        "test_r2": 0.89,
        "rmse": 15.3,
        "mape": 3.2
      },
      "checksum": "sha256:def456...",
      "optional": false
    },
    "chiller_1_kw": {
      "type": "component_level",
      "path": "chiller_1_kw/20260213_100500_ensemble_manifest.json",
      "target_variable": "chiller_1_kw",
      "feature_count": 25,
      "best_algorithm": "lightgbm",
      "metrics": {
        "val_r2": 0.88,
        "test_r2": 0.85,
        "rmse": 8.5,
        "mape": 4.1
      },
      "checksum": "sha256:ghi789...",
      "optional": true,
      "parent_system_model": "system_total_kw"
    }
  },
  "compatibility": {
    "optimization_engine_min_version": "1.0",
    "feature_annotation_version": "1.2",
    "python_version": "3.10+",
    "required_packages": ["xgboost>=1.7", "lightgbm>=4.0", "scikit-learn>=1.3"]
  }
}
```

---

**é—œéµè¨­è¨ˆç¢ºèª (v1.2)**:
1. **é›™æ¨¡å¼æ¶æ§‹**: æ˜ç¢ºå€åˆ† System-Levelï¼ˆå„ªåŒ–ç”¨ï¼‰èˆ‡ Component-Levelï¼ˆè¨ºæ–·ç”¨ï¼‰ï¼ŒHybrid æ¨¡å¼æä¾›ä¸€è‡´æ€§æª¢æŸ¥
2. **æ‰¹æ¬¡å”èª¿**: BatchTrainingCoordinator çµ±ä¸€ç®¡ç†å¤šç›®æ¨™è¨“ç·´ï¼Œç¢ºä¿ç‰ˆæœ¬ä¸€è‡´æ€§èˆ‡è¨˜æ†¶é«”å®‰å…¨
3. **æ¨™æº–åŒ–ä»‹é¢**: Model Registry Index ä½œç‚º Training èˆ‡ Optimization çš„å–®ä¸€çœŸç›¸ä¾†æºï¼ˆSingle Source of Truthï¼‰
4. **å‘ä¸‹ç›¸å®¹**: ä¿ç•™æ‰€æœ‰ v1.1 åŠŸèƒ½ï¼ˆResourceManagerã€SHAPã€OvernightOptimizerï¼‰ï¼Œåƒ…å¢åŠ éŠœæ¥å±¤
5. **å®¹éŒ¯è¨­è¨ˆ**: Component Models æ¨™è¨˜ç‚º optionalï¼Œå³ä½¿è¨“ç·´å¤±æ•—ä¹Ÿä¸å½±éŸ¿ System Model ä½¿ç”¨